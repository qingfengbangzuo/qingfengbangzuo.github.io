<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Qingfengbangzuo</title>
  
  <subtitle>私人博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://qingfengbangzuo.github.io/"/>
  <updated>2020-06-28T07:37:24.846Z</updated>
  <id>https://qingfengbangzuo.github.io/</id>
  
  <author>
    <name>qingfengbangzuo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>从词嵌入到CNN</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/20/NLP/%E4%BB%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%88%B0CNN/%E4%BB%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%88%B0CNN/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/20/NLP/%E4%BB%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%88%B0CNN/%E4%BB%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%88%B0CNN/</id>
    <published>2020-06-19T16:00:00.000Z</published>
    <updated>2020-06-28T07:37:24.846Z</updated>
    
    <content type="html"><![CDATA[<p>内容：</p><p>1、介绍了为什么需要引进CNN，CNN解决了那些问题。</p><p>2、介绍了CNN在NLP中的基本结构。</p><p>3、介绍了层次卷积的基本结构</p><h3 id="为什么需要CNN？"><a href="#为什么需要CNN？" class="headerlink" title="为什么需要CNN？"></a>为什么需要CNN？</h3><p>传统的词嵌入算法word2vec、Glove等等训练得到的向量都是基于“词”的。虽然它在训练的过程中使用到了上下文的语义信息或者统计方面的信息，但是依然面临着一些问题。、</p><p><strong>问题1：</strong>比如，在包含主观情感的句子中，形容词往往拥有比其他词性的单词包含更多的信息。在主题分类任务中，特殊的名词、代词相比其他词性的词语往往包含跟多的信息。这就产生了新的需求，我们希望找到某种“方法”能够根据不同的任务对一些关键词进行区别对待，或者说我们希望挖掘出那些包含更多信息量的词。</p><p><strong>问题2：</strong>在基于“词”的level上来训练任务往往会遇到一些问题，因为带有关键信息的可能不仅仅是单个词，而往往是一些词组（k-grams)，虽然CBOW考虑到了n-grams的信息，但是它的一个比较大的缺点是忽略了词序，从而造成一个比较大的问题：“it was not good, it was actually quite bad” and “it was not bad, it was actually quite good ”会给予一个相同的表示。但是这两句尽管很相似，但是在情感上完全是相反的。这意味着ngrams相比于bag-of-words可能包含了更多的信息。</p><p>一个很自然的解决方法是，扩充Embedding矩阵，给kgrams和word相同的表示，效果就是嵌入矩阵中不仅包含单个词的表示向量，同样包含词组（kgrams）的表示向量。然后就可以使用传统的词嵌入训练方法来进行训练。不过这样做的缺点有这样几点：1、扩充后的词嵌入矩阵可能会发生维度爆炸，因为对于一个$10^5$到$10^6$的语料库来讲，扩充带来的后果是词嵌入矩阵维度的指数级增长，同时带来了更大的稀疏性。2、由于矩阵的扩充会导致存储的消耗变得巨大。3、对(k-grams)的伸缩性不好。4、不同享统计信息，对于词组”very good”和“quite good”，它们两个词在嵌入矩阵中是独立的两个”词“，尽管它们拥有一个相同的单词“good”，但是它们在训练过程中被视为是不相关的，因此给定其中一个无法推断另一个。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">the embedding of “quite good” and “very good” are completely independent of one another, so if the learner saw only one of them during training, it will not be able to deduce anything about the other based on its component words .</span><br></pre></td></tr></table></figure><p>CNN被发现能够很好的缓解以上问题。无论是在CV领域还是NLP领域，CNN结构都可以被视为是一种特征抽取结构。Convolution  + Pooling 能够有效地从句子中抽出关键信息，这个关键信息是一个k-grams。因此CNN能够带来的几点好处是：1、不需要对词嵌入矩阵进行修改，从而避免了扩张带来的存储消耗。2、可以抽取k-grams信息，并且使得其中的统计信息可以被共享。3、伸缩性好，可以将k从1扩张到N（句子长度），只需要增加线性复杂度。4、输出维度可控，可以指定输出维度为任意大小。</p><h3 id="CNN结构-使用1D卷积"><a href="#CNN结构-使用1D卷积" class="headerlink" title="CNN结构(使用1D卷积)"></a>CNN结构(使用1D卷积)</h3><p><img src="/2020/06/20/NLP/%E4%BB%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%88%B0CNN/%E4%BB%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%88%B0CNN/image-20200626143733720.png" alt="image-20200626143733720"></p><p>如图所示是k=2，nfilter = 1时的CNN结构，可以看出卷积层就做了一件事儿，就是对一个大小为2的窗口滚动操作。这个操作如下：</p><script type="math/tex; mode=display">\begin{align}&对于序列&W_{1:n} &= {w_1,w_2,w_3,...,w_n}\\&定义一个concatenation操作：&x_i &= C(w_i:w_{i+k-1}); \quad x_i\in R^{k·d_{emd}}\\&g是一个非线性函数(tanh) &p^k_i &= g(x_i^T·u)\quad p^k_i \in R \quad u\in R^{k·d_{emd}} \end{align}</script><p>式中的i表示窗口的index。对于<script type="math/tex">nfilter = l</script>的情况，可以将参数矩阵$u$扩展成$U \quad Dim_U = (k·d_{emd},l)$.</p><p>得到 结果为</p><script type="math/tex; mode=display">P^k_i  = g(x_i^TU+b) \quad P^k_i \in R^{(1,l)}</script><p>假设sentence的长度为N，有</p><script type="math/tex; mode=display">P^k = g(X^TU+b) \quad P^k\in R^{(N-k+1,l)}</script><h4 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h4><p>由于卷积操作会使得维度下降（N个词的句子,有N-k+1个长度为k的窗口），padding是指对句子的前后进行插入一定数量的空白词，使得维度变化在一个可控的范围。上述操作没有进行padding，称为narrow convolution.还有一种称为wide convolution，就是在两边各插入k-1个词。这样得到的维度为N+k-1。</p><p>padding还有一个作用是提高两边词的检测度。</p><h4 id="pooling"><a href="#pooling" class="headerlink" title="pooling"></a>pooling</h4><p>对于一个窗口大小来讲，池化操作是指对filter过后的$(1,l)$维向量进行一个伸缩操作。常用的两种方法是max-pooling和average-pooling。顾名思义，max-pooling就是取$(1,l)$维向量中最大的那个，作为结果。average-pooling就是去$(1,l)$维向量的平均值作为结果。</p><p>pooling操作背后的含义：网上有不少介绍pooling的作用的博客，这里就不展开了，浅谈自己的一些认识。</p><p>要想了解pooling干了什么需要先知道卷积层做了什么，从效果上来看，卷积层无非是把句子中所有的n-grams特征都提取了出来。提取出来的这些特征经过一个concatenation操作和一个非线性函数映射，变为了一个值。这种操作类似于特征变换，将多个特征进行了一个非线性组合，然后得到了一个新的表示。这种思想应用到n-gram提取上显得再正常不过，也就是说我们可以将这个值看做是n-gram的一个表示，至于是哪方面的表示，这个是非线性变化的参数决定的，可能是词性可能是频率，也可能是其他。那么我们通过$l$个的filter得到了$l$个n-grams的不同表示，我们当然可以将这些表示作为一个向量直接扔进后面的训练过程，但是为了简化训练，我们总是希望根据这$l$个中总结出一个最好的表示来进行后续的训练，这样一来可以减少训练的复杂度，二来可以使得表示更加的鲁棒。那么常用的两种方法是max和average。这两种表示方法效果因人而异，不同任务表现出来的效果也不尽相同。</p><p>还有一种取法是k-max取法。就是取max最大的前k个表示最为最终的表示，但是在取值的过程中需要注意各个对应值的相对位置不变。</p><p><img src="/2020/06/20/NLP/%E4%BB%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%88%B0CNN/%E4%BB%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%88%B0CNN/k-max.PNG" alt="k-max"></p><p>max-pooling的值为[9,8,5].2-max的值为[[9,6,3],[7,8,5]].</p><h3 id="HIERARCHICAL-CONVOLUTIONS"><a href="#HIERARCHICAL-CONVOLUTIONS" class="headerlink" title="HIERARCHICAL CONVOLUTIONS"></a>HIERARCHICAL CONVOLUTIONS</h3><p>hierarchical convolutions是对CNN机构的一种扩展。目的和对图像进行多重卷积操作一样，都是为了能够提取更有效的表示。</p><script type="math/tex; mode=display">p_{1:m} = CONV^k_{U,b}(w_{1:n})\\p_i = g(C(w_{i:i+k-1})·U+b)\\m = n-k+1 \quad or \quad n+k-1\\--------------\\p^1_{1:m_1} = CONV^{k_1}_{U^1,b^1}(w_{1:n})\\p^2_{1:m_2} = CONV^{K_2}_{U^2,b^2}(p^1_{1:m_1})\\...\\p^r_{1:m_r} = CONV^{k_r}_{U^r,b^r}(p^{r-1}_{1:m_{r-1}})</script><p>效果 是$p_{1:m_r}^r$捕捉了一个递增的窗口。</p><p><img src="/2020/06/20/NLP/%E4%BB%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%88%B0CNN/%E4%BB%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%88%B0CNN/层次卷积.PNG" alt="层次卷积"></p><p>这个和CV中多层卷积目的一致，都是为了提取更有效的特征。我们假设窗口为k=2,经过第一层卷积提取出的特征表示的是2个相邻词的词组表示，再经过一层卷积之后，变为了三个相邻词的词组表示。</p><p>当然，也可以直接初始化窗口大小为3使用一层卷积来获得类似的结果，但是从效果来看，多层卷积的效果总是要好过使用单层卷积。</p><h4 id="Stride"><a href="#Stride" class="headerlink" title="Stride"></a>Stride</h4><p>步长是指在窗口滑动的过程中的滑动间隔，不做修改时默认为1，当然也可以为设为2。不过增加步长的效果是会得到一个更小的卷积层输出（行变少了）。</p><h4 id="dilated-convolution"><a href="#dilated-convolution" class="headerlink" title="dilated convolution"></a>dilated convolution</h4><p>是指在层次卷积的基础上，每一层卷积层的步长都设为k-1.这样会使得窗口大小变为一个关于layer的指数增长的值。</p><h4 id="Parameter-Tying"><a href="#Parameter-Tying" class="headerlink" title="Parameter Tying"></a>Parameter Tying</h4><p>指的是每一层卷积层都使用相同的参数集U，b。这样会造成更多的参数共享，并且不需要预先设定卷积层的大小，最终的结果是经过多次卷积之后，一个sequence就会收敛为一个向量表示。</p><h4 id="skip-connection"><a href="#skip-connection" class="headerlink" title="skip-connection"></a>skip-connection</h4><p>指的是对于第i层卷积层，不止使用第i-1层卷积层得到的向量表示，还要使用第i-2层卷积层得到的表示。</p><p>卷积层数是一个<strong>超参数</strong>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;内容：&lt;/p&gt;
&lt;p&gt;1、介绍了为什么需要引进CNN，CNN解决了那些问题。&lt;/p&gt;
&lt;p&gt;2、介绍了CNN在NLP中的基本结构。&lt;/p&gt;
&lt;p&gt;3、介绍了层次卷积的基本结构&lt;/p&gt;
&lt;h3 id=&quot;为什么需要CNN？&quot;&gt;&lt;a href=&quot;#为什么需要CNN？&quot; class
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/categories/NLP/"/>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Attention Mechanism</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/20/NLP/Seq2Seq/Attention/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/20/NLP/Seq2Seq/Attention/</id>
    <published>2020-06-19T16:00:00.000Z</published>
    <updated>2020-06-29T09:29:27.915Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Attention-Mechanism"><a href="#Attention-Mechanism" class="headerlink" title="Attention Mechanism"></a>Attention Mechanism</h2><p>思想：人眼观察事物时，有一个聚焦机制，即只注意和目标物相关的部分，而忽略其他和目标物弱相关的部分。这种机制可以被引进Encoder-Decoder框架。</p><p>经典的encoder-decoder模型，编码器和解码器中间的耦合靠上下文向量$C$. 前面讨论过仅依靠上下文向量$C$维持的耦合关系是很弱的。Attention机制带的一个重大改变就是，编码-解码器之间的耦合不再使用单向量$C$. 而是使用编码器在每一个时间步产生的上下文$c_{i:n}$. </p><script type="math/tex; mode=display">c_{1:n} = ENC(x_{1:n}) = biRNN(x_{1:n})</script><p>这里的编码器使用的是双向RNN，因为要对时间步t进行编码，因此，考虑时间步t过去和未来是有必要的。</p><p>编码器产生上下文$c_i$的数学过程：</p><script type="math/tex; mode=display">s^f_i = R(s^f_{i-1},x_t)\\s^b_i = R(s^b_{n-i+1},x_t)\\c_i  = O([s^f_i,s^b_i])</script><p>得到输入序列每一个时间步的上下文编码，接下来考虑解码过程，Attention带来的第二个改变是，解码过程中每一个时间步所使用的上下文向量$c_j$不再是固定的，而是依据当前状态和前面得到的$c_{1:n}$构造出来的。构造过程如下：</p><script type="math/tex; mode=display">c_j = attend(c_{1:n},\hat{t}_{1:j})\\</script><p>式中$c_j$表示解码过程的第$j$个时间步所需要使用的上下文信息，这信息由$c_{1;n}$和$\hat{t}_{i:j}$（状态）构造， attend()是构造函数，是一个可训练(可以做梯度)的带参函数。下面是原版的soft attention机制：</p><script type="math/tex; mode=display">c_j = \sum_{i=1}^n a^{j}_{[i]}·c_i\\</script><p>$c_i$表示的是原序列中关于时间步$i$的上下文，$a^j_{[i]}$是该时间步上下文对应的权重，也就是说，解码过程中使用的上下文是原序列对应上下文的加权和。那么这个权重是如何得到的呢？原版的soft attention机制是经过一个MLP层训练：</p><script type="math/tex; mode=display">\bar{\alpha}_j = \bar{\alpha}^j_{[1]}...\bar{\alpha}^j_{[n]} = MLP([s_j;c_1]),...MLP([s_j;c_n])</script><p>式中的$s_j$是指解码过程中，时间步$j$对应的状态，$c_i$仍然是原序列对应的编码后的上下文，经过MLP层训练之后，我们可以得到一组非规范化的向量$\bar{\alpha}_j = \bar{\alpha}^j_{[1]}…\bar{\alpha}^j_{[n]}$, 然后通过softmax可以将其转化为和为1的概率分布。</p><script type="math/tex; mode=display">a_j = softmax(\bar{\alpha}^j_{[1]}...\bar{\alpha}^j_{[n]})</script><p>如何解释上面获得权重的过程呢？</p><p>对于机器翻译来说，MLP过程可以认为是在当前解码状态$s_i$（捕捉近期生成的词）和每一个原序列对应的编码后的上下文$c_i$之间软对齐（关联度）的计算过程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">In the context of machine translation, one can think of MLPatt as computing a soft alignment between the current decoder state sj (capturing the recently produced foreign words) and each of the source sentence components ci.</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><p>完整的Attention机制的计算过程如下：</p><script type="math/tex; mode=display">\begin{align}&attend(c_{1:n},\hat{t}_{1:j}) = c_j\\&c_j = \sum_{i=1}^n \alpha^j_{[i]}·c_i\\&\alpha^j =softmax(\bar{\alpha}^j_{[1]},...,\bar{\alpha^j_{[n]}})\\&\bar{\alpha}^j_{[i]} = MLP([s_j;c_i])\end{align}</script><p>完整的基于attention的encoder-decoder模型数学表达如下：</p><script type="math/tex; mode=display">\begin{align}&p(t_{j+1}= k|\hat{t}_{1:j},x_{1:n}) = f(O_{dec}(s_{j+1})\\&s_{j+1} = R_{dec}(s_j,[\hat{t}_j;c^j])\\&c^j = \sum_{i=1}^n \alpha^j_{[i]}·c_i\\&c_{1:n} = biRNN_{enc}(x_{1:n})\\&\alpha^j =softmax(\bar{\alpha}^j_{[1]},...,\hat{\alpha}^j_{[n]})\\&\bar{\alpha}^j_{[i]} = MLP([s_j;c_i])\\&\hat{t}_j \approx p(t_j|\hat{t}_{1:j-1},x_{1:n})\\&f(z) = softmax(MLP^{out}(z))\\& MLP([s_j;c_i]) = v· tanh([s_j;c_i]U+b)\end{align}</script><p><img src="/2020/06/20/NLP/Seq2Seq/Attention/Attention.PNG" alt="Attention"></p><h2 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h2><p>为什么要使用BiRNN来训练得到一个上下文$c_{1:n}$而不直接使用原文$x_{1:n}$呢？</p><p>其实是可以使用原文来进行attention机制的计算的，但是我们可以从$c_{1:n}$中得到更多 , 受限BiRNN训练得到的$c_i$不仅对应了序列中对应的$x_i$，它还包含了$x_i$ 的上下文。其次，通过使用一个经过训练的表示$c_i$，可以将编码和解码过程绑定在一起（训练），这样可以使得网络去学习那些对解码过程有用的编码方式，而这种信息一般不会直接体现在原文里。</p><p>这里说的有点绕，其实意思很简单，通过将编码和解码参数绑定在一起训练，使得编码得到的上下文$c_{1:n}$对解码过程是有用的，原始的输入向量表达的信息是有限且固定的，通过一层特征提取，可以使得训练效果更好。</p><p>例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">For example, the biRNN encoder may learn to encode the position of xi within the sequence, and the decoder could use this information to access the elements in order, or learn to pay more attention to elements in the beginning of the sequence then to elements at its end.</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h2 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h2><p>当不采用Attention的时候，训练的复杂度取决于编码的长度和解码的长度，（不考虑softmax的计算）$O(m+n)$。</p><p>当采用Attention的时候，由于针对每一个解码过程都需要训练一个上下文$c_j$，训练的复杂度为$O(m \times n)$。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Attention-Mechanism&quot;&gt;&lt;a href=&quot;#Attention-Mechanism&quot; class=&quot;headerlink&quot; title=&quot;Attention Mechanism&quot;&gt;&lt;/a&gt;Attention Mechanism&lt;/h2&gt;&lt;p&gt;思想
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/categories/NLP/"/>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Seq2Seq</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/18/NLP/Seq2Seq/Seq2Seq/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/18/NLP/Seq2Seq/Seq2Seq/</id>
    <published>2020-06-17T16:00:00.000Z</published>
    <updated>2020-06-29T09:30:00.473Z</updated>
    
    <content type="html"><![CDATA[<h2 id="序列生成模型"><a href="#序列生成模型" class="headerlink" title="序列生成模型"></a>序列生成模型</h2><p>一个序列生成模型一般要满足这样的假设：</p><p>当前值$t_i$的分布依赖于之前$1:t_{i-1}$个词。即$P(t_i|t_{1:i-1})$,在每一步中，得到当前值得分布，即得到$P(t_i=k|t_{1:i-1})$的概率值，然后将当前值作为预测下一个值得已知条件。</p><p>RNN满足序列生成模型的形式：</p><p><img src="/2020/06/18/NLP/Seq2Seq/Seq2Seq/RNN_seqgenerate.PNG" alt="RNN_seqgenerate"></p><p>当RNN作为transducer时，只需将时间步t时刻的输出连接到时间步t+1时的输入即可。在训练过程中，每轮训练开始都给予一个初始字符$<s>$,遇到结束字符$</s>$时结束。在时间步$t$时，输入有$s_{t-1}$和$y_{t-1}$，$s_{t-1}$是之前$t-1$个词的编码，$y_{t-1}$是上一个时间步的预测值，$P(y_t|s_{t-1},y_{t-1})$近似于使用前$t-1$个词作为条件，等同于假设$P(t_i|t_{1:t-1})$。$y_i$的结果一般为一个词分布，大小为字典长度，采用softmax来转换概率。$s_0$初始化为0，但是decoder模型中，该值被初始化为$s_0 = \delta({VC})$.</p><p>注：当$y_{t-1}$被当做下一时刻的输入时，该值选用$y_{t-1}$分布中概率值最大的那个值。</p><p><strong>teacher-forcing: </strong>是另外一种训练方法，这种训练方法和上述最大的不同在于每个时间步输入$y_{t-1}$不再是模型上一个时间步的预测结果，而是训练序列中上一个时间步对应的值，是标签。这样会导致一个现象，就是对于时间步t，它的输入$y_{t-1}$（真是的标签）在上一个时间步的预测概率很小，但是由于它是真实的标签，因此在下一时间步被作为输入。这种方式导致的后果就是，在测试集中，会出现不可预知的结果。</p><h2 id="Conditioned-generation-framework"><a href="#Conditioned-generation-framework" class="headerlink" title="Conditioned generation framework"></a>Conditioned generation framework</h2><p>在条件生成框架下，下一个token的产生依赖于两个，一个是过去生成的token，另一个是上下文。</p><script type="math/tex; mode=display">\tilde{t}_{j+1} \approx p(t_{j+1} = k|\tilde{t}_{1:j},c)</script><p>用RNN形式表示就是：</p><script type="math/tex; mode=display">p(t_{j+1}=k|\tilde{t}_{1:j},c) = f(O(s_{j+1}))\\s_{j+1} = R{s_j,[\tilde{t_j};c]}\\\tilde{t}_j\approx p(t_i|\tilde{t}_{1:j-1},c)</script><p>这就是条件生成框架：</p><p><img src="/2020/06/18/NLP/Seq2Seq/Seq2Seq/条件生成框架.PNG" alt="条件生成框架"></p><p>关于上下文c的解释如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">What kind of information can be encoded in the context c? Pretty much any data we can put our hands on during training, and that we find useful. For example, if we have a large corpus of news items categorized into different topics, we can treat the topic as a conditioning context. Our language model will then be able to generate texts conditioned on the topic. If we are interested in movie reviews, we can condition the generation on the genre of</span></span><br><span class="line"><span class="string">the movie, the rating of the review, and perhaps the geographic region of the author. We can then control these aspects when generating text. We can also condition on inferred properties, that we automatically extract from the text. For example, we can derive heuristics to tell us if a given sentence is written in first person, if it contains a passive-voice construction, and the level of vocabulary used in it. We can then use these aspects as conditioning context for training, and, later, for text generation.</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><p>大体意思就是说，上下文C可以是一个类别信息，比方说电影的类别，文本的话题。或者我们抽象出来的内容，比如机器翻译中输入序列的编码。</p><h2 id="Encoder-Decoder"><a href="#Encoder-Decoder" class="headerlink" title="Encoder-Decoder"></a>Encoder-Decoder</h2><p>encode-decoder框架是针对Seq2Seq问题提出来的,Seq2Seq是指在机器翻译、语音识别等领域需要将任意长度的输入序列转换为任意长度的输出序列。</p><p>RNN（LSTM\GRU）的trasnducer模式本身是符合编码解码模式的，它的输入就是一段序列，输出也是一段序列，只不过在该框架下的输入输出是对称的。</p><p>为了解决输入输出不对称的问题，诞生了encode-decoder框架，这个框架依托于上述描述的条件生成框架。观察上述条件生成框架，我们发现该框架本质是一个序列生成模型，而解码器的功能就是产生一个基于输入序列的转换编码。因此，基于此框架作为解码器是合理的，而条件生成框架中存在一个关于上下文的输入，这个东西可以由输入序列的编码来代替。这样逻辑上是自恰的，给定一个输入序列，编码器将其转换为合适的编码，这个编码后信息可能是句子的主题、句子的语态等等（深度学习的不可知论），依据此编码作为上下文（也可以理解为这个编码内部包含了我们需要预测的句子的指示信息或者上下文，它用于指示我们的解码器需要生成的句子需要在什么样的上下文中）可以作为生成句子的条件（约束）。</p><p><img src="/2020/06/18/NLP/Seq2Seq/Seq2Seq/encoder-decoder.PNG" alt="encoder-decoder"></p><p>编码器和解码器被绑定在一起训练，但是标签只作用于解码器，但是梯度可以经过解码器被传播回编码器。</p><p><img src="/2020/06/18/NLP/Seq2Seq/Seq2Seq/encoder-decoder_loss.PNG" alt="encoder-decoder_loss"></p><p>基本的训练框架就是上图表示的这样，编码器为一个RNN网络比如说LSTM或者GRU。</p><p>解码器也为一个RNN网络（LSTM、GRU、BiRNN、CNN）。</p><h2 id="数学解释"><a href="#数学解释" class="headerlink" title="数学解释"></a>数学解释</h2><p>对Seq2Seq建模：</p><script type="math/tex; mode=display">P(Y|X) = P(y_1,y_2,y_3,...y_t|X)</script><p>$X$为输入序列，$Y$为输出序列。问题的表述为给定任意长度的输入序列，预测出一个概率最大的输出序列。</p><script type="math/tex; mode=display">argmax_Y log(P(Y|X)) = argmax_Ylog(\prod_{i=1}^tP(y_i|y_{i-1},y_{i-2},...,y_1;X))\\=argmax_Y\sum_{i=1}^tlog(P(y_i|y_{i-1},y_{i-2},...,y_1;X))</script><p>观察$P(y_i|y_{i-1},y_{i-2},…,y_1;X)$,$X$为原文输入序列，对于encoder-decoder来说，$X$可以被编码器转化为全局编码$C$.</p><script type="math/tex; mode=display">C = ENC(X)</script><p>ENC为编码器，假设编码器采用LSTM，那么编码流程：</p><script type="math/tex; mode=display">\begin{align}&s_{t-1} = [c_{t-1};h_{t-1}]\\&i_t = \delta(w^{hi}h_{t-1}+w^{x_i}x_{t})\\&f_t = \delta(w^{hf}h_{t-1}+w^{xf}x_t)\\&o_t = \delta(w^{ho}h_{t-1}+w^{xo}x_t)\\&g_t = tanh(w^{hg}h_{t-1}+w^{xg}x_t)\\& c_t = f_t \odot c_{t-1}+i_t \odot g_t\\&h_t = o_t \odot tanh(c_t)\end{align}</script><p>注意上面过程中的两个tanh函数的位置。</p><p>当遍历完整个输入序列后，得到全局编码$h_T$.此时不能将全局编码$H_T$直接扔进解码器，需要做一步转换。</p><script type="math/tex; mode=display">C  = tanh(V·h_T+b_c)</script><p>这里的激活函数是tanh，有几个作用，一个作用是激活，另一个作用是将编码的值映射到x轴的两侧，这样做可以加速梯度下降，还有一个作用就是维度变换，将向量$h_T$变换成我们需要的维度。</p><p>此时得到的$C$可以作为上下文输入解码器了。对于解码过程</p><script type="math/tex; mode=display">h_t = R(h_{t-1},y_{t-1},C)\\y_t = softmax(O(h_t,y_{t-1},C))</script><p>另外，对于$h_0$的初始化：</p><script type="math/tex; mode=display">h_0 = tanh(V^{ch}C+b_h)</script><p>这样就可以将解码过程与序列生成模型连接起来了。</p><p>局限性：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">encoder-decoder模型虽然非常经典，但是局限性也非常大。最大的局限性就在于编码和解码之间的唯一联系就是一个固定长度的语义向量C。也就是说，编码器要将整个序列的信息压缩进一个固定长度的向量中去。但是这样做有两个弊端，一是语义向量无法完全表示整个序列的信息，还有就是先输入的内容携带的信息会被后输入的信息稀释掉，或者说，被覆盖了。输入序列越长，这个现象就越严重。这就使得在解码的时候一开始就没有获得输入序列足够的信息， 那么解码的准确度自然也就要打个折扣了.</span></span><br><span class="line"><span class="string">https://zhuanlan.zhihu.com/p/48648001</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h3 id="一个值得思考的问题"><a href="#一个值得思考的问题" class="headerlink" title="一个值得思考的问题"></a>一个值得思考的问题</h3><p>面对不同语言之间的语义不同的问题，模型是如何解决的？模型真的可以自动学到不同语言之间的特性么？直到目前为止，所有基于词向量的模型的特征抽取本质上都是对token统计特征的抽取，这是否是最好的词表示方式？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;序列生成模型&quot;&gt;&lt;a href=&quot;#序列生成模型&quot; class=&quot;headerlink&quot; title=&quot;序列生成模型&quot;&gt;&lt;/a&gt;序列生成模型&lt;/h2&gt;&lt;p&gt;一个序列生成模型一般要满足这样的假设：&lt;/p&gt;
&lt;p&gt;当前值$t_i$的分布依赖于之前$1:t_{i-1}$
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/categories/NLP/"/>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>RNN的基本结构</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/</id>
    <published>2020-06-15T16:00:00.000Z</published>
    <updated>2020-06-28T07:54:34.849Z</updated>
    
    <content type="html"><![CDATA[<h3 id="RNN的基本结构"><a href="#RNN的基本结构" class="headerlink" title="RNN的基本结构"></a>RNN的基本结构</h3><p><img src="/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN的基本结构1.PNG" alt="RNN的基本结构1"></p><p>上图是RNN的基本单元和基本结构。</p><p>可以看出RNN（Recurrent Neuron Network）是递归神经网络的一种。不过，RNN还有一种表示形式如下，这种形式和上述形式是等价的，是按时间步长展开的表示。</p><p><img src="/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN基本结构2.PNG" alt="RNN基本结构2"></p><hr><h3 id="循环神经网络or递归神经网络"><a href="#循环神经网络or递归神经网络" class="headerlink" title="循环神经网络or递归神经网络"></a>循环神经网络or递归神经网络</h3><p>引用博客：<a href="https://blog.csdn.net/zhangjiali12011/article/details/90045978" target="_blank" rel="noopener">https://blog.csdn.net/zhangjiali12011/article/details/90045978</a></p><p>很明显，它俩名字就是不一样的，循环神经网络是Recurrent Neural Network，递归神经网络是Recursive Neural Network。</p><p>当然循环神经网络也确实可以归类到递归神经网络，从广义上说，递归神经网络分为结构递归神经网络和时间递归神经网络。从狭义上说，递归神经网络通常指结构递归神经网络，而时间递归神经网络则称为循环神经网络。</p><p>两者最主要的差别就在于Recurrent Neural Network是在时间维度展开，Recursive Neural Network在空间维度展开。一个很重要的改型LSTM也是基于Recurrent Neural Network改进的。</p><hr><p>图中为$x_i$代表时间步$i$的输入，即序列中第$i$个词。$s_i$代表时间步$i$的状态，$s_{i-1}$代表上一个时间步的状态，$s_0$是 一个初始状态，一般被设置为0. 状态更新函数为$s_i = R(s_{i-1},x_i|\theta)$,也称作激活函数。输出函数为$y_i$是时间步$i$的输出，这个输出不是必须的。输出函数$y_i = O(s_i|\theta)$,$\theta$是整个RNN网络的参数，包括了$\theta_R$和$\theta_O$.</p><p>下面对应一下各个变量和参数的维度：</p><script type="math/tex; mode=display">\begin{align}&s_i = tanh(\theta_ss_{i-1}+\theta_xx_i+b_a)\\&y_i = softmax(\theta_ys_i+b_y) \\&x_i: (n_x,m)\\&s_i: (n_a,m)\\&\theta_x:(n_a,n_x)\\&\theta_s:(n_a,n_a)\\&\theta_y:(n_y,n_a)\\&b_a:(n_a,1)\\&b_y:(n_y,1)\end{align}</script><h3 id="RNN解决了什么？"><a href="#RNN解决了什么？" class="headerlink" title="RNN解决了什么？"></a>RNN解决了什么？</h3><p>回答这个问题其实挺难，因为截至到目前为止，人们依然无法很好地解释RNN为何能取得优异地表现。但是RNN的一些特性是明显的，比如说，它的每一步都继承了上一步的状态，这使得它的当前状态对过去状态产生了依赖，这个性质是符合语言特征的。其次它对位置十分敏感，不同的位置导致了不同的更新过程，这个主要体现在非线性激活函数的作用上。对比语法的特征，可以发现RNN的这个性质也是符合语言特征的，因为对于主流语言英语、汉语，词性决定了单词出现的相对位置，尽管这个位置有时候是捉摸不定的，但是其仍然具有一定的规律可循。</p><p>那么RNN到底解决了什么？</p><p>要想回答这个需要先看一下CNN解决了什么，CNN解决的问题很直接，就是CBOW严重忽略了词序，导致在进行一些分类预测任务的时候出现了问题。而CNN可以通过卷积+池化的操作使得模型对局部的顺序变得敏感。通俗一点说就是，CBOW只能捕捉到单个词的特征，而CNN可以捕捉词组的特征，这个特征包含了统计特征和语义方面的特征。CNN是不完美的，因为它更多的是对局部的序列顺序敏感，而不是整个句子。比方说“not good”不能说成是”good not”，但是至于”not good”放在什么句子的什么地方，CNN是对此是较疲软的。RNN解决了这个问题。</p><p>RNN是对CNN的扩展，因为RNN可以捕捉全局（整个句子）的特征，原因是它整个句子的词序都是敏感的，更因为它的每一个状态都是建立在前一个状态之上的。这就使得当前词对它之前出现过的所有词都构成了隐形的依赖。</p><p>看两个最基本的RNN结构。</p><h4 id="CBOW-RNN"><a href="#CBOW-RNN" class="headerlink" title="CBOW-RNN"></a>CBOW-RNN</h4><script type="math/tex; mode=display">s_i = R_{CBOW}(x_i,s_{i-1}) = s_{i-1}+x_i\\y_i = O_{CBOW}(s_i) = s_i</script><p>对应一下个参数维度：</p><script type="math/tex; mode=display">\begin{align}&x_i: (n_x,m)\\&s_i: (n_x,m)\\&y_i:(n_x,m)\end{align}</script><p>这是CBOW的RNN版本，可以看到这个网络对于序列顺序是不敏感的，因为顺序的变换不会导致更新过程的变换（忽略$y_i$无论怎么加结果都不变）。</p><h4 id="Simple-RNN-S-RNN"><a href="#Simple-RNN-S-RNN" class="headerlink" title="Simple RNN(S-RNN)"></a>Simple RNN(S-RNN)</h4><script type="math/tex; mode=display">s_i  = R_{SRNN}(x_i,s_{i-1}) = g(\theta_ss_{i-1}+\theta_xx_i+b_a)\\y_i = O_{SRNN}(s_i) = s_i</script><p>对应一下个参数维度：</p><script type="math/tex; mode=display">\begin{align}&x_i: (n_x,m)\\&s_i: (n_a,m)\\&\theta_x:(n_a,n_x)\\&\theta_s:(n_a,n_a)\\&b_a:(n_a,1)\\&y_i:(n_a,m)\end{align}</script><p>激活函数g一般使用tanh或者Relu。这个网络是可能是最简单的循环神经网络之一了，我们可以拿这个网络作为一个Baseline来学习。SRNN相较于CBOW，只多了一层非线性激活层，但就是这一层可以使得网络对于输入顺序变得极为敏感，因为不同的输入顺序会导致参数的更新过程不同。</p><h3 id="Acceptor、Encoder、Transducer"><a href="#Acceptor、Encoder、Transducer" class="headerlink" title="Acceptor、Encoder、Transducer"></a>Acceptor、Encoder、Transducer</h3><p>以上是RNN三种形式的使用类比。</p><p>对于第一种”Acceptor”，RNN只关注最后一个状态的输出，那么整个RNN结构就相当于一个训练器，它的输出结果就是最后一个时间步对应的$y_i$。倘若我们可以对每一个输出进行标签化，那么就可以将其视为一个有监督的学习过程。</p><p>对于第二种“Encoder”,顾名思义这种方式就是将RNN视为一种编码器，将RNN的最后一个时间步对应的输出视为编码结果，由于输出的维度是可定制的，因此，我们可以将RNN对我们的sample进行了重新编码。之后，可以将编码结果伙同其他特征一起送到更深层的网络进行训练。</p><p>一个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">an extractive document summarization system may first run over the document with an RNN, resulting in a vector yn summarizing the entire document. Then, yn will be used together with other features in order to select the sentences to be included in the summarization.</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><p>对于第三种”Transducer”,形式更为我们熟知，它是指在训练过程中存储每一个时间步对应的输出求损失，最后将所有的损失综合到一起反馈给网络。一个熟知的模型就是RNN可以作为语言模型，因为它的第i个时间步的输出可以被视为给定前i-1个上下文得到的概率分布。</p><p><img src="/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/transducer.PNG" alt="transducer"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Using RNNs as transducers allows us to relax the Markov assumption</span></span><br><span class="line"><span class="string">that is traditionally taken in language models and HMM taggers, and</span></span><br><span class="line"><span class="string">condition on the entire prediction history.</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><p>到这里可以稍微总结一些RNN的特性：</p><p><strong>1、对序列顺序敏感</strong></p><p><strong>2、训练采用后向传播</strong></p><p><strong>3、输出维度可定制化，输入维度不敏感</strong></p><p><strong>4、由于结构是循环(递归)的，因此所有的单元共用一套参数。</strong></p><p><strong>5、RNN的输入可以是One-hot</strong></p><h3 id="Bidirection-RNN（BI-RNN）"><a href="#Bidirection-RNN（BI-RNN）" class="headerlink" title="Bidirection RNN（BI-RNN）"></a>Bidirection RNN（BI-RNN）</h3><p>双向RNN解决的问题是什么？</p><p>在n-grma模型里面，我们为了捕捉词向量的语义上的特征，因此使用了滑动窗口，既捕捉目标词前k个单词，也捕捉目标词的后k个单词。但在RNN的基础结构中，我们可以看到模型只捕捉到了时间步i的历史依赖，对于未来可能出现的依赖是乏力的。因此，使用双向RNN可以缓解这个问题，顾名思义双向RNN就是使用两个RNN来从不同的方向对时间步i进行扫描。这样，使得得到到的时间步i的状态既依赖于过去也依赖于未来。</p><p>就像RNN放宽了马尔科夫假设，使得模型可以捕捉过去任意长度的词与目标词的依赖关系（马尔科夫是前k个词），biRNN放宽了窗口长度的假设，使得模型可以捕捉任意窗口大小的词与目标词的依赖关系。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Much like the RNN relaxes the Markov assumption and allows looking arbitrarily back into the past, the biRNN relaxes the fixed window size assumption, allowing to look arbitrarily far at both the past and the futurewithin the sequence.</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><p><img src="/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/BIRNN.PNG" alt="BIRNN"></p><p>由于采用了双向的RNN扫描，因此在时间步状态的表示上会进行一些更改。$S_i = [s^f_i,s^b_i]$, $y_i = [O^f(s_i^f);O^b(s_i^b)]$.</p><p>定义biRNN的形式为：</p><script type="math/tex; mode=display">biRNN(x_{1:n},i) = y_i = [RNN^f(x_{1:n});RNN^b(x_{n:i})]</script><p>这里可以是一个合并操作。使用sum的话，没有concat更能反映编码捕捉到的信息。</p><p>另一种形式的BIRNN</p><p><img src="/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/biRNN2.PNG" alt="biRNN2"></p><p>biRNN被广泛应用在各种任务中，其中在sequence tagging中表现优异。</p><h3 id="Multi-layer-RNN"><a href="#Multi-layer-RNN" class="headerlink" title="Multi-layer RNN"></a>Multi-layer RNN</h3><p>和CNN一样，RNN也是可以堆叠的，称为深度RNN或者多层RNN。研究发现，多层RNN在效果上好于单层RNN，但是理论支撑的工作还没有完成。</p><p><img src="/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/Multi-layerRNN.PNG" alt="Multi-layerRNN"></p><p><strong>开下脑洞：</strong>为甚么2层的会比一层的有效？</p><p>要回答这个问题需要知道RNN干了一件什么事。</p><script type="math/tex; mode=display">s_i = tanh(\theta_ss_{i-1}+\theta_xx_i+b_a)\\y_i = softmax(\theta_ys_i+b_y) \\</script><p>对于非线性激活函数，我一直将其视为是一种特征抽取方式，就是将一个简单的特征变位一个比较复杂但是更好地特征，或者说对原始特征进行了重新解决，解读过后变得更容易被接受了。这可能是所有表示学习的一种特性，比如神经网络就是通过一轮又一轮地非线性变换然后得到一个比较不错的表达。那么对于RNN来讲，单层的RNN相当于对特征$(s_i,x_i)$进行了一次解读，多层的RNN相当于对特征进行了多次的解读。那么多次的解读一定比单次或者原始特征更好么，这个也不是一概而论的，比如核变换将数据映射到不同的维度观察到的分布特性也是不同的，至于映射到哪一维更好，或许是个超参数。我将这个对比用于非线性变换，因为非线性变换与核映射有异曲同工之妙。</p><p>如果将RNN视为对时间步特征的非线性解读，那么解读后的特征就是对时间步对应词的一个特征变换。通常来说通过这样的变化带来的收益是正的，因为原始的词特征表示没有考虑到全局依赖的问题。而变换后的特征是一种目标词和上下文(全局)的混合表示，更强更壮。多层RNN是对这个混合过程进行了更多次的抽取，按照上面的解释，结果一般总能表现地更好。</p><h3 id="门控结构"><a href="#门控结构" class="headerlink" title="门控结构"></a>门控结构</h3><p>S-RNN在训练时遭遇了梯度消失的问题，导致了实际应用时效果大打折扣。</p><p>梯度消失会导致参数更新无法传播到前面几层，就是越靠近输入端越难以被更新，或者更新速度很慢。这样还附带了一个现象，就是由于梯度传播不过来，导致RNN很难去捕捉long-range的依赖。（前面分析的是RNN有能力捕捉过去和未来的全局依赖，这里提出的门控结构更像是为了解决工程问题）</p><p>门控结构可以缓解这个问题。门控结构的基本思想：</p><p>如果将RNN视为一种有着有限大小资源计算硬件，计算单元R读进输入$x_{i+1}$,和当前状态$s_i$,然后对他们进行某种计算操作。并且将计算结果写入内存，替换掉旧的状态$s_i$。从这个角度看SRNN的问题是，内存的介入是不受控制的，也就是说在每一步计算中全部内存状态被读入，然后又被更新。通俗来讲，就是在计算时间步i的时候，我们是将先前所有的状态信息都读入进去了，那些读进去的状态信息只有一部分是真正对目标有依赖关系的，其余的相当于噪声。很自然的一个想法就是能不能将那些对目标词没有关系的状态不读入目标词时间步的计算过程，只读入那些有依赖关系的状态。如果能够只读入有依赖关系的状态，那么在反向传播的过程就意味着不需要每个状态依次更新，而只更新那些被读入的状态，这可以大大缓解梯度消失的问题。想要达到这样的目的，可以采取一种门控机制：</p><p><img src="/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/gate.PNG" alt="gate"></p><p>就是在每一步读入的时候或者是说在计算时间步$s’$的时候，由一个门控单元控制读入的状态。</p><p>这种机制的一个特点是，假设状态变量$s_i$有$n_a$维，每次更新并不是对所有的维度进行更新，而是根据门控单元g选择一些维度进行更新。可以暂且认为这些被更新的维度是与当前状态有关的。</p><p>接下来的问题变为了如何设计门控单元g。很显然，门控单元是时间步的函数g = f(t)。它所时间步的不同而改变，且不应该由人来指定。典型的硬编码门控单元：$g \in \{0,1\}$无法进行梯度下降，因此可以采用一种软门控单元来既达到门控的效果，又与时间步联系起来。</p><p>一种方法是放宽g的取值范围，令$g\in R^n$,且对$g$施加一sigmod函数$\delta(g)$。这里的$\delta$函数有一个好处，就是当g趋于均匀分布时，它对于大部分g值都能映射为一个接近$\{0,1\}$的值，只有当g取接近于0的数时，才会被映射为0到1之间的值，因此，为了避免这种现象，在实际使用时，可以将接近于0的g值舍去，只留下那些绝对值较大的g值。这样，采用软门控，可以使得求梯度了。</p><p><strong>现在只留下如何构造g了。</strong></p><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>LSTM的全拼是 The Long Short-Term Memory architecture.被 Hochreiter and Schmidhuber 于1997年提出。是一种门控结构的神经网络。</p><p>LSTM将状态向量$s_i$分为了两部分，一部分被称为“memory cell”。另一部分被称为”working memory”。”memory cell”用于存贮状态和”error gradients”.可以通过”dierentiable gating components”控制。在整个模型框架下有三个门控i,f,o，分别对应输入，隐含层的更新和输出。</p><script type="math/tex; mode=display">\begin{align}&s_i = R_{LSTM}(s_{i-1},x_j) = [c_j;h_j]\\&c_j = f\odot c_{j-1}+i\odot z\\&h_j = o \odot tanh(c_j)\\&i = \delta(x_j W^{xi}+h_{j-1}W^{hi})\\&f = \delta(x_j W^{xf}+h_{j-1}W^{hf})\\&o = \delta(x_jW^{x0}+h_{j-1}W^{h0})\\&z  = tanh(x_jW^{xz}+h_{j-1}W^{hz})\\&y_i = O_{LSTM}(s_j) = h_j\\&s_j \in R^{2·d_h},x_i\in R^{d_x},c_j,h_j,i,f,o,z\in R^{dh},W^{xo}\in R^{d_x,d_h},W^{ho}\in R^{d_h,d_h}\end{align}</script><p>$c_j$表示”memory cell”，$h_j$表示working memory。两个合并到一块表示状态$s_j$。</p><p>注意这里关于g的构造，</p><script type="math/tex; mode=display">g_i = x_jW^{xi}+h_{j-1}W^{hi}</script><p><img src="/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/LSTM结构图.PNG" alt="LSTM结构图"></p><p>水平线是状态。</p><p>关于LSTM的变种，一种是Gers和Schmidhuber于2000年提出的增加了窥视孔连接。</p><p><img src="/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/peephole_conenction.PNG" alt="peephole_conenction"></p><p>另一种变种是使用了配对遗忘门和输入门，与之前分别决定遗忘与添加信息不同，我们同事决定两只。只有当我们需要输入一些内容的时候我们才选择忘记。只有当早前信息系被忘记之后我们才会输入。</p><p><img src="/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/variant2.PNG" alt="variant2"></p><h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><p>GRU没有将状态分割成两部分。</p><script type="math/tex; mode=display">\begin{align}&s_j = R_{GRU}(s_{j-1},x_j) = (1-z)\odot s_{j-1}+z \odot \tilde{s_j}\\&z = \delta(x_jW^{xz}+s_{j-1}W^{sz})\\&r = \delta(x_jW^{xr}+s_{j-1}W^{sr})\\&\tilde{s_j} = tanh(x_jW^{xs}+(r\odot s_{j-1})W^{sg})\\&y_j = O_{GRU}(s_j) = s_j\end{align}</script><p>这里只使用了两个门，一个门r用来控制介入的先前状态$s_{j-1}$并且计算$\tilde{s_j}$。状态更新使用到了先前的状态$s_{j-1}$和计算值$\tilde{s_j}$，使用门$z$来控制比例。</p><p><img src="/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/GRU.PNG" alt="GRU"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;RNN的基本结构&quot;&gt;&lt;a href=&quot;#RNN的基本结构&quot; class=&quot;headerlink&quot; title=&quot;RNN的基本结构&quot;&gt;&lt;/a&gt;RNN的基本结构&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%B
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/categories/NLP/"/>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Word GloVe</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/16/NLP/Glove/GloVe/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/16/NLP/Glove/GloVe/</id>
    <published>2020-06-15T16:00:00.000Z</published>
    <updated>2020-06-22T12:56:07.254Z</updated>
    
    <content type="html"><![CDATA[<h2 id="GloVe-Global-Vectors-for-Word-Representation"><a href="#GloVe-Global-Vectors-for-Word-Representation" class="headerlink" title="GloVe: Global Vectors for Word Representation"></a>GloVe: Global Vectors for Word Representation</h2><p>​        这篇文章基于论文《GloVe: Global Vectors for Word Representation  》进行总结学习，如有疑惑，以原文为主。</p><h3 id="什么是Matrix-Factorization-和Local-Context-Window？以及各自的不足？"><a href="#什么是Matrix-Factorization-和Local-Context-Window？以及各自的不足？" class="headerlink" title="什么是Matrix Factorization 和Local Context Window？以及各自的不足？"></a>什么是Matrix Factorization 和Local Context Window？以及各自的不足？</h3><p>​        关于如何表示词向量有两种流派：一种是利用Distributional Hypothesis，另一种被称为“Distributed Representation”。两种流派在另一篇文章<a href="词嵌入算法.md">《词嵌入算法》</a>中被讨论过。</p><p>​        关于如何挖掘语言信息也有两种方向，一种是基于统计概率的，依据的假设是“不同phrase的分布不同”，方法是统计不同目标对的出现频率，借助统计意义表达信息。另一种是在频率统计的基础上加入了语境信息，是一种较为高级的挖掘方向，依据的假设是“不同语境携带了不同的信息”，方法是利用目标词的语境作为输入信息的一部分。这两种方向都有各自的依据，都能得到部分预料信息。        </p><p>​        Matrix Factorization的意思是Matrix指的是”共现矩阵“，关于共现矩阵，有几种形式，一种是”term-term”，矩阵的行列对应相应的words,矩阵的值为word-pair共同出现的次数。一种是“term-document”,矩阵的行代表words，列对应不同的document(我更愿意理解为context)，矩阵值对应word-document共同出现的次数。前者的代表是HAL(Hyperspace Analogue to Language)。后者的代表是LSA(Latent Semantic Analysis)。</p><p>​        利用共现矩阵统计的”全局信息“（global）来存储语料中的信息，然后对共现矩阵进行降维。降维的原因是共现矩阵是一个巨大的稀疏矩阵，处理起来不是很友好。这一步叫做“Factorization”。这种表示方法称为“distributional representation”，本质是利用了语料库的统计信息。</p><p>​        由于只用到了统计信息，因此该中表示方法存在的缺陷是明显的：</p><ul><li>无法表达词向量之间的关系(相似性)</li><li>共现矩阵随着语料库的扩增而扩增，而扩增的程度是指数的。</li><li>有很强的稀疏性，不符合语言的特性。</li><li>复杂度是O($|V|^2$)</li></ul><p>​        Local Context Window的典型代表是word2vec，是指利用滑动窗口遍历语料库，经过神经网络训练得到一种词向量表示方法，窗口的大小对于训练结果有影响。这种方法的缺点是</p><ul><li>没有利用语料库的统计信息、</li></ul><p>​        两种表示方法的共同点是最终的得到词向量的维度都不具备可解释性，虽然共现矩阵的每个维度都有意义，但是经过SVD之后，每个维度的含义也都变得混乱了。</p><p>​        GloVe的想法是既然从这两种角度都可以挖掘到词向量的部分信息，但是显然都挖掘到的信息都是不完整的，那么将这两种方式结合起来或许可以挖掘到更强的word representation.</p><h3 id="构建共现矩阵"><a href="#构建共现矩阵" class="headerlink" title="构建共现矩阵"></a>构建共现矩阵</h3><p>​        根据语料库（corpus）构建一个共现矩阵（Co-ocurrence Matrix）XX（什么是<a href="http://www.fanyeong.com/2017/10/10/word2vec/" target="_blank" rel="noopener">共现矩阵</a>？），<strong>矩阵中的每一个元素XijXij代表单词ii和上下文单词jj在特定大小的上下文窗口（context window）内共同出现的次数。</strong>一般而言，这个次数的最小单位是1，但是GloVe不这么认为：它根据两个单词在上下文窗口的距离dd，提出了一个衰减函数（decreasing weighting）：decay=1/ddecay=1/d用于计算权重，也就是说<strong>距离越远的两个单词所占总计数（total count）的权重越小</strong>。</p><blockquote><p>In all cases we use a decreasing weighting function, so that word pairs that are d words apart contribute 1/d to the total count.</p></blockquote><p>摘自：<a href="http://www.fanyeong.com/2018/02/19/glove-in-detail/" target="_blank" rel="noopener">http://www.fanyeong.com/2018/02/19/glove-in-detail/</a></p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>定义notation:</p><p>$X_{i,j}:$ 单词j出现在语境i下的频次。</p><p>$X_i=\sum_kX_{i,k} :$ 所有在语境i下出现的目标单词的总个数。</p><p>$P_{i,j} = P(j|i) = \frac{X_{i,j}}{X_i}:$单词j出现在语境i中的概率。</p><p> 作者定义了一个等式：</p><script type="math/tex; mode=display">F(w_i,w_j,w_k) = \frac{P_{i,k}}{P_{j,k}}</script><p>​        首先谈一下对这个等式的理解。我想作者的目的是希望通过一个函数将词向量和共现矩阵里的统计信息建立联系。因为从某种角度来说，soft-max也是通过某种方法将词向量与概率联系起来，两者具有相似的思想。或者说，作者认为一个比较好的向量表示应该能够反映其在预料库中的统计信息。</p><p>​        如果上式能够成立，那么要做的有两件事，一件是找到一个映射函数F,另一件是训练词向量的表示方式，等式右边的值可以通过共现矩阵得到，因此可以作为一个标签。</p><p>​        首先是确定函数F。下面的解释是借鉴了网上的一篇博客<a href="（十五）通俗易懂理解——Glove算法原理 - 梦里寻梦的文章 - 知乎 https://zhuanlan.zhihu.com/p/42073620">GloVe</a>：</p><p>​        1、$\frac{P_{i,k}}{P_{j,k}}$反映了词向量$(w_i,w_j,w_k)$之间的相似关系，如果单独考虑两个词向量之间的相似关系，那么可以用$|w_i-w_j|$，因此F的形式可以是：$F(w_i-w_j,w_k) = \frac{P_{i,k}}{P_{j,k}}$.</p><p>​        2、$\frac{P_{i,k}}{P_{j,k}}$是一个标量，而自变量是两个同维度的向量，因此可以将自变量进行内积，将自变量转为标量$F((w_i-w_j)^Tw_k) = \frac{P_{i,k}}{P_{j,k}}$,再做一步变换：$F(w_i^Tw_k-w_j^Tw_k) = \frac{P_{i,k}}{P_{j,k}}$.</p><p>​        3、到此为止，等式作为是差右边是商，可以将F取exp变换将差和商联系起来。</p><script type="math/tex; mode=display">exp(w_i^Tw_k-w_j^Tw_k) = \frac{exp(w_i^Tw_k)}{exp(w_j^Tw_k)} = \frac{P_{i,k}}{P_{j,k}}</script><p>​        4、现在只要让分子和分母分别相等就可以了</p><script type="math/tex; mode=display">exp(w_i^Tw_k) = P_{i,k}\\w_i^Tw_k = log(P_{i,k}) = log(X_{i,k})-log(X_i)\\w_j^Tw_k = P_{j,k} = log(X_{j,k})-log({X_i})</script><p>​        5、作为向量，交换$w_i$和$w_k$的顺序值是不变得，但是等式右边显然不适用这个性质，因此将模型引入两个偏置项：</p><script type="math/tex; mode=display">log(X_{i,k}) = w_i^Tw_k+b_i+b_k</script><p>这里是$log(X_i)$消失了？   其实是将$log(X_i)$放到了偏置项$b_i$内。</p><p>​        6、上面的等式在实际中只能近似，因此就有了代价函数(cost function):</p><script type="math/tex; mode=display">J = \sum_{ik}(w_i^Tw_k +b_i+b_k-logX_{ik})^2</script><p>​        7、最后为了提高高频词对损失函数的贡献程度，可以根据两个词共同出现的次数设计一个权重想来对代价函数每一项进行加权：</p><script type="math/tex; mode=display">J = \sum_{ik}f(X_{ik})(w_i^Tx_k+b_i+b_k-log(X_{i,k}))^2</script><p>​        8、权重函数f(x)</p><script type="math/tex; mode=display">\begin{align}f(x) = \{ \begin{array}{ll}(\frac{x}{x_{max}})^\alpha, if\quad x<x_{max}\\1, \quad otherwise\end{array}\end{align}</script><p>这里$\alpha$和word2vec一样取$\frac{3}{4}$</p><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>​        虽然很多人声称GloVe是一种无监督（unsupervised learing）的学习方式（因为它确实不需要人工标注label），但其实它还是有label的，这个label就是公式2中的log(Xij)log⁡(Xij)，而公式2中的向量ww和~ww~就是要不断更新/学习的参数，所以本质上它的训练方式跟监督学习的训练方法没什么不一样，都是基于梯度下降的。具体地，这篇论文里的实验是这么做的：<strong>采用了AdaGrad的梯度下降算法，对矩阵XX中的所有非零元素进行随机采样，学习曲率（learning rate）设为0.05，在vector size小于300的情况下迭代了50次，其他大小的vectors上迭代了100次，直至收敛。</strong>最终学习得到的是两个vector是ww和~ww~，因为XX是对称的（symmetric），所以从原理上讲ww和~ww~是也是对称的，他们唯一的区别是初始化的值不一样，而导致最终的值不一样。所以这两者其实是等价的，都可以当成最终的结果来使用。<strong>但是为了提高鲁棒性，我们最终会选择两者之和w+~ww+w~作为最终的vector（两者的初始化不同相当于加了不同的随机噪声，所以能提高鲁棒性）。</strong>在训练了400亿个token组成的语料后，得到的实验结果如下图所示：</p><p><img src="/2020/06/16/NLP/Glove/GloVe/glove.jpg" alt="glove"></p><p>这个图一共采用了三个指标：语义准确度，语法准确度以及总体准确度。那么我们不难发现Vector Dimension在300时能达到最佳，而context Windows size大致在6到10之间。</p><p>摘自：<a href="http://www.fanyeong.com/2018/02/19/glove-in-detail/" target="_blank" rel="noopener">http://www.fanyeong.com/2018/02/19/glove-in-detail/</a></p><h3 id="网上关于GloVe的一个问题："><a href="#网上关于GloVe的一个问题：" class="headerlink" title="网上关于GloVe的一个问题："></a>网上关于GloVe的一个问题：</h3><p> <a href="https://www.zhihu.com/question/292482891/answer/492247284" target="_blank" rel="noopener">https://www.zhihu.com/question/292482891/answer/492247284</a></p><p>GloVe的损失函数：</p><script type="math/tex; mode=display">loss = \sum_{w_i,w_j}(<v_i,\hat{v_j}>+b_i+\hat{b_j}-logX_{i,j})^2</script><p>在glove模型中，对目标词向量和上下文向量做了区分，并且最后将两组向量求和，得到词向量。模型中最大的问题在于参数$b_i,b_j$也是可训练的参数，这会带来一些问题：</p><script type="math/tex; mode=display">\sum_{w_i,w_j}(<v_i,\hat{v_j}>+b_i+b_j-logX_{i,j})^2 \\=\sum_{w_i,w_j}[<v_i+c,\hat{v_j}+c>+(b_i-<v_i,c>-\frac{|c|^2}{2})\\+(\hat{b_j}-<\hat{v_j},c>-\frac{|c|^2}{2})-logX_{i,j}]^2</script><p>就是说这个方程的解不止一个，对与一个解向量加上任意一个常数向量后，它还是这个损失函数的解，原因是偏置因子$b_i$和$\hat{b_j}$的存在。</p><p>有人在评论里提出使用正则化来解决这个问题。</p><p>也有人说对一次更新都使用标注化，把词向量的模限制在1.</p><h3 id="GloVe和其他模型-的联系"><a href="#GloVe和其他模型-的联系" class="headerlink" title="GloVe和其他模型 的联系"></a>GloVe和其他模型 的联系</h3><p>作者在论文中指出，soft-max模型也可以转换成Glove的形式。</p><script type="math/tex; mode=display">soft-max : Q_{ij} = \frac{exp(w_i^Tw_j)}{\sum_{k=1}^Vexp(w_i^Tw_k)}</script><p>那么损失函数可以写成：</p><script type="math/tex; mode=display">J = -\sum_{i\in corpus,j\in context(i)} logQ_{ij}</script><p>由于根据经验，高频词对于损失的贡献程度更大，因此：</p><script type="math/tex; mode=display">J = -\sum_{i=1}^V\sum_{j=1}^V X_{i,j} logQ_{i,j}</script><p>注意，这里将j的取值范围定义为了整个语料库，并且加上了权重$X_{ij}$，也就是说对于没有出现过的词对$X_{ij}$，这一项被置为了0。作者在原文说这样近似更有效率。</p><p>根据定义</p><script type="math/tex; mode=display">X_i = \sum_{k}X_{ik}\\P_{ij} = X_{ij}/X_i</script><script type="math/tex; mode=display">J = -\sum_{i=1}^VX_i\sum_{j=1}^VP_{ij}logQ_{ij} = \sum_{i=1}^VX_iH(P_i,Q_i)</script><p>这里的$H(P_i,Q_i)$是交叉熵。这个损失也就变为了某种形式的交叉熵损失。</p><p>交叉熵是 一种概率分布之间的距离衡量方式，但是它有一个不好的性质就是会对poorly events 分配不小的权重，因此为了解决这个问题，需要Q采用合适的标准化手段。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;GloVe-Global-Vectors-for-Word-Representation&quot;&gt;&lt;a href=&quot;#GloVe-Global-Vectors-for-Word-Representation&quot; class=&quot;headerlink&quot; title=&quot;GloV
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/categories/NLP/"/>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>语言模型</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/16/NLP/%E4%BB%80%E4%B9%88%E6%98%AF%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E4%BB%80%E4%B9%88%E6%98%AF%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/16/NLP/%E4%BB%80%E4%B9%88%E6%98%AF%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E4%BB%80%E4%B9%88%E6%98%AF%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</id>
    <published>2020-06-15T16:00:00.000Z</published>
    <updated>2020-06-16T11:28:37.972Z</updated>
    
    <content type="html"><![CDATA[<h3 id="当我们在讨论语言模型的时候，我们讨论的是什么？"><a href="#当我们在讨论语言模型的时候，我们讨论的是什么？" class="headerlink" title="当我们在讨论语言模型的时候，我们讨论的是什么？"></a>当我们在讨论语言模型的时候，我们讨论的是什么？</h3><p>​      从字面意思上理解，语言模型（language model）无非是对语言的一种建模。那么对语言建模的目的是什么？为什么要对语言进行建模呢？</p><p>​    回答这个不难，因为无论是机器翻译还是语音识别，所有的NLP领域都绕不开一个问题，那就是“到底什么是人话？”。一段文本，一段音频，我们将其称之为“信号”，是否符合人类语言特征，是否能够让人看得懂，听得懂？这个是所有NLP任务的基本问题，能够很好地回答了这个问题，才能够继续做下一步。</p><h3 id="为什么语言模型很重要？"><a href="#为什么语言模型很重要？" class="headerlink" title="为什么语言模型很重要？"></a>为什么语言模型很重要？</h3><p>有一个概念是这样讲的：</p><p> Noisy Channel Model:</p><p>机器翻译，语音识别，拼写纠错，OCR，密码破解等NLP任务都有一个相似之处，那就是问题的形式都是给定一段信号，然后预测在给定信号下的正确的输出。形式化描述：</p><script type="math/tex; mode=display">P(text|source) \propto P(source|text)P(text)</script><p>分母上的$P(source)$被省略了，因为对于给定的source，$P(source)$是固定的，我们只讨论在给定source情况下的text正确性的问题。</p><p>例如：</p><p>​    机器翻译： 假设英文翻译成中文。</p><script type="math/tex; mode=display">obj =argmax_{中文} P(中文|英文)</script><p>根据上面的NCM模型，可以有：</p><script type="math/tex; mode=display">obj = argmax P(英文|中文)P(中文)</script><p>​    模型$P(英文|中文)$负责中英文间的映射，这个最简单的情况下可以由一个字典完成，模型$P(中文)$就是语言模型， 用来控制输出符合语言特征。</p><p>​    比方说，对于“The brown fox skip over the lazy dog.”映射模型可以完成单词间的逐一映射，但是如何组合才符合中文的说法习性，就需要语言模型来控制。</p><h3 id="如何解决？"><a href="#如何解决？" class="headerlink" title="如何解决？"></a>如何解决？</h3><p>​    然而要解决这个问题并不简单，原因是多方面的：</p><ul><li><p>1、语言天生的歧义和多变性。多变性是指一种含义可以有很多种方式来说，也可以指一种说法可以有很多种含义。</p></li><li><p>2、语言的规则不好定义。(ill-defined).很难有一套规则把某种语言给定义好，所谓的定义好就是指语言的表达模式完全遵从某种规则。对于中文来讲，尽管我们有标准的语法，但是在现实中一句话可能是语法的各种组合，或者我们讲话写作不用按照标准的语法也可以表达意思。</p></li><li><p>3、语义是无穷尽的，不同的单词可以组成不同的句子，不同的句子又可以表达不同的意思，这个组合没有上限。更何况人类的语言库一直在更新。因此，训练样本无法穷尽所有的情况。</p></li><li><p>4、解析语义是一个组合问题。单词-&gt;句子-&gt;文章/新闻/事件。复杂度骤增。</p></li><li>5、最后一个没有理解到位，NLP问题具有sparseness(稀疏性)?</li></ul><p>业界对语言模型的一个定义是：</p><p>Assigning a probability to sentences or sequence of words in a language.</p><p>不仅要能够给一句话的出现概率，还要能够给出，给定语境下的目标单词的条件概率。</p><p>上述两个问题等价于一个问题。根据条件概率公式：</p><script type="math/tex; mode=display">p(w_{1:n}) = p(w_1)p(w_2|w_1)p(w_3|w_{1:2})...p(w_n|w_{1:n-1})\\p(w_{1:n-1}) = p(w_1)p(w_2|w_1)p(w_3|w_{1:2})...p(w_{n-1}|w_{1:n-2})\\p(w_n|w_{1:n-1}) = \frac{p(w_{1:n})}{p(w_{1:n-1})}</script><p>假设我们知道每个句子的概率，那我们也可以知道给定序列下每个词的出现概率。</p><h4 id="传统的方法是采用马尔科夫假设。"><a href="#传统的方法是采用马尔科夫假设。" class="headerlink" title="传统的方法是采用马尔科夫假设。"></a>传统的方法是采用马尔科夫假设。</h4><p>我们对后面一个问题应用马尔科夫假设，准确地说是kth order markov-assumption。</p><p>即目标单词的出现概率仅与之前出现的前k个单词有关。</p><script type="math/tex; mode=display">P(w_{i+1}|w_{1:i}) \approx P(w_{i+1}|w_{i-k:i})</script><p>根据上面的公式：</p><script type="math/tex; mode=display">P_{MLE} (w_{i+1} = m|w_{i-k:i}) = \frac{\#(w_{i-k:i+1})}{\#(w_{i-k:i})}</script><p>至此，我们就得到了一个baseline模型。</p><p>但是这个baseline模型有一个缺点，就是对于没有观察到的句子，这个概率是无穷大。因此，又有人在这个基础上做了平滑。</p><script type="math/tex; mode=display">p_{add-\alpha} (w_{i+1} =m|w_{i-k:i})=\frac{\#(w_{i-k:i+1})+\alpha}{\#(w_{i-k:i})+\alpha|V|}</script><p>但是传统的语言模型有很多问题：</p><p>​    最大的缺点是假设太强了，真实情况只能部分符合该假设，比如“喝水”，“吃饭”等等（k=1）。其它情况下则不符合，比如：“Tom喝了好几杯水，因为他太渴了。”，这里的“渴”明显与“喝水”这一动作相关，但是由于词序靠后，因此不能被模型很好的分辨出来。</p><p>​    另外，对于k的选择是含糊的，k=1好还是k=2好，k到底怎么选？这需要具体情况具体分析，并没有一个一劳永逸的方法。小的K值对于corpus训练是可以接受的，但是大的k值会导致内存不够用，对于一个含有V个单词的词典，可能的kgrams有$|V|^{k}$种，k每增加一都会导致指数级的增长（尽管有些kgram的组合在现实不会出现或者不符合语法）。</p><p>但是从历史的发展来看，应用这个假设诞生的模型，在某些场景下，还是可以得到不错的效果。</p><h4 id="业界目前比较火的构造方法是采用神经网络"><a href="#业界目前比较火的构造方法是采用神经网络" class="headerlink" title="业界目前比较火的构造方法是采用神经网络"></a>业界目前比较火的构造方法是采用神经网络</h4><p>​    神经网络天生具有高效的学习能力，03年bengio提出使用神经网络构造语言模型，取得了不错的效果。</p><p>​    后来业界提出了使用RNN网络来对时间序列建模之后，将神经网络在NLP领域的运用推上了顶峰。</p><p>​    再后来出现了GRU和LSTM（复兴）等等。</p><p>神经网络的优点：</p><p>​    非线性神经网络模型解决了传统模型的缺点，主要是k值的限制。在神经网络中，k值增加是线性的，而非指数的。所谓的线性是指用于参数数量成线性关系。通俗来讲就是，为了能够使用更多的前缀内容，我可以通过增加参数来达到这个目的。也避免了手动设置”bakkoff order”(这个概念理解的不是很好，)</p><p>​    其实神经网络不止这一个优点，神经网络代替传统模型的几个方面：</p><p>​    上述是一个方面。二是，神经网络不要手动的combine特征，模型会帮我们自动提取出有用的特征，这也是表示学习的一大特点。三是，神经网络解决了上下文的问题，传统的模型假设限制了模型利用下文的信息，而双向神经网络即可以利用上文信息，也可以利用下文信息。这使得模型预测更加符合实际情况。第四点是，门控神经网络的诞生解决了模型对单词出现位置（时间序列）的依赖问题，更容易挖掘关联信息。</p><p>​    这些技术总体来说都是逐步放宽模型的假设，使得模型更贴近现实。</p><p>神经网络的限制：</p><p>​    神经网络对于预测context中的某个词的出现概率成本相对传统模型比较高。但是泛化效果不错，但是某种场景下，这种泛化效果会带来不好的影响，书中给出了一个例子，比如预测“red house”的出现概率，传统模型可能会给一个比较低的概率，因为不常见。但是神经网络可能观察到了“black house,blue house”等等，因为基于它的泛化能力反而会给出一个比较高的概率，这是不希望看到的。因为在显示中，红房子确实不多见，但是白房子，黑色城堡可能比较多一点。</p><p>​    语言模型从传统过渡到神经网络经历了一个漫长的过程，而且并不是传统的一定就是不好的，在某些场景下，传统语言模型反而比神经网络表现地更好。</p><p>​    有没有更好地建模方法？不知道。神经网络说到底是基于统计概率的，不具备良好的可解释性。而基于规则的方法虽然具备良好的可解释性，但是效果却不尽人意。有没有能够兼顾两者的模型可能还需要一个数年的探索。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;当我们在讨论语言模型的时候，我们讨论的是什么？&quot;&gt;&lt;a href=&quot;#当我们在讨论语言模型的时候，我们讨论的是什么？&quot; class=&quot;headerlink&quot; title=&quot;当我们在讨论语言模型的时候，我们讨论的是什么？&quot;&gt;&lt;/a&gt;当我们在讨论语言模型的时候，我们讨
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/categories/NLP/"/>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Unigram,Bigram,Ngram</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/16/NLP/k-gram/Unigram,Bigram,Ngram/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/16/NLP/k-gram/Unigram,Bigram,Ngram/</id>
    <published>2020-06-15T16:00:00.000Z</published>
    <updated>2020-06-22T12:52:15.571Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Unigram-Bigram和N-gram"><a href="#Unigram-Bigram和N-gram" class="headerlink" title="Unigram, Bigram和N-gram"></a>Unigram, Bigram和N-gram</h2><p>​        这三种模型都是基于kth order markov-assumption下k分别取1,2,n时的情况，是传统模型中最基本的模型。下面主要分析一下这三种模型的不足，同时也是传统模型的不足。</p><h3 id="Unigram"><a href="#Unigram" class="headerlink" title="Unigram"></a>Unigram</h3><p>核心：将每个单词视为独立的个体.</p><p>那么：</p><script type="math/tex; mode=display">P(w_1,w_2,w_3,...,w_n) = p(w_1)p(w_2)p(w_3)...p(w_n)</script><p>上面就是我们的模型，训练过程就是统计每个单词$p(w_i)$的出现概率。</p><p>至于怎么得到每个单词的概率，就需要给定一个语料库，在语料库中计算每个单词的频率。</p><p>预测过程：</p><p>将需要预测的样本带到模型中，得到每个单词频率的乘积，即为句子出现的概率。</p><p>可以看出这种方法虽然简单，但是假设太强，它的假设是每个单词之间相互独立，即一句话中的单词A出现的概率是完全随机的，因为单词之间都彼此独立。显然这不合理。</p><h3 id="Bi-gram"><a href="#Bi-gram" class="headerlink" title="Bi-gram:"></a>Bi-gram:</h3><p>核心：每个单词的出现依赖前一个单词。</p><p>模型表示:</p><script type="math/tex; mode=display">P(w_1,w_2,w_3,...,w_n) = p(w_1)p(w_2|w_1)p(w_3|w_2)...p(w_{n-1}|w_n)</script><p>模型的训练过程就是统计如下概率：</p><script type="math/tex; mode=display">p(w_i|w_{i-1}) = \frac{p(w_i,w_{i-1})}{p(w_{i-1})} = \frac{$(w_{i-1},w_i)}{$w_{i-1}}</script><p>同样是在语料库中统计。</p><p>预测过程：</p><p>将需要预测的样本带到模型中，各个条件概率的的乘积，即为句子出现的概率。</p><p>该模型虽然在Unigram的基础上放宽了部分假设，即假设下一个单词的出现与上一个单词有相关性。但是假设依然很强，因为没有考虑语义上的相关，比方说”the man”，这两个单词之间的相关性可能并不像他表现出来的那么强。其次，模型也没有考虑超过2个词距的单词对目标词的影响。这些都是限制模型表现地因素。</p><h3 id="n-gram：假设n-3"><a href="#n-gram：假设n-3" class="headerlink" title="n-gram：假设n =3"></a>n-gram：假设n =3</h3><p>核心：每个目标词的出现都依赖于前N个出现的单词。</p><p>模型表示：</p><script type="math/tex; mode=display">P(w_1,w_2,w_3,...w_n) = P(w_1)P(w_2|w_1)P(w_3|w_1,w_2)P(w_4|w_2,w_3)...P(w_n|w_{n-1},w_{n-2})</script><p>模型训练过程就是统计如下概率：</p><script type="math/tex; mode=display">P(w_i|w_{i-k:i}) = \frac{P(w_i,w_{i-k:i})}{P(w_{i-k:i})} = \frac{$(w_i,w_{i-k:i})}{$w_{i-k:i}}</script><p>预测过程：</p><p>将需要预测的样本带到模型中，各个条件概率的的乘积，即为句子出现的概率。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>​        可以看出Bi-gram和N-gram模型都是在Unigram的基础上逐渐放宽假设的结果。下面主要讨论三种模型的共同的一些问题：</p><p><strong>问题1</strong>：</p><p>​        一个显著的问题就是对于语料库中没有出现，而预测样本中出现了的单词，模型会表现出糟糕的预测结果。即对于语料库中没有出现的单词，模型的预测结果会取0。这显然是不符合实际情况的。</p><p>一个因此普遍的做法是对模型进行平滑处理。</p><p>additive smoothing ：</p><script type="math/tex; mode=display">P_{add-\alpha} (w_{i+1 }=m|w_{i-k:i}) = \frac{$(w_{i-k:i+1})+\alpha}{$(w_{i-k:i})+\alpha|V|}</script><p>$\alpha$取（0,1]之间的值。</p><hr><p>back-off smothing:</p><script type="math/tex; mode=display">P_{int}(w_{i+1} = m|w_{i-k:i}) = \lambda_{w_{i-k:i}}\frac{$(w_{i-k:i+1})}{$(w_{i-k:i})}+(1-\lambda_{w_{i-k:i}})p(w_{i+1}=m|w_{i-(k-i):i})</script><p>​        该平滑原理是利用其backoff进行退步统计，就是说对于$P(w_{i+1}|w_{i-k:i})$如果语料库中没有出现$w_{i-k:i}$，那么就使用$w_{i-k:i-1}$来代替。</p><p><strong>问题2：</strong></p><p>​        没有利用到下文的信息。有些目标词是依赖下文的，对上文依赖反而不强，但是马尔科夫假设限制了这一点。这也是限制传统模型表现的一个重要因素。</p><p><strong>问题3：</strong></p><p>​        无法衡量序列之间的相似性。比方说“我今天喝了很多水。”与“我今天喝水快喝饱了。”这两个句子都是在说“喝了很多水”。但是模型却没有衡量这两个序列相似性的能力。</p><p>​        一个解决方法是引入词向量。这个话题可以单独写一篇，关于如何衡量序列之间相似性。</p><p><strong>问题4：</strong></p><p>​        对于n的选择是一个trade-off问题。（当采用线性模型时，这个问题尤为严重。因为K每增加1，相应的假设空间就要增大$|V|^{k+1}$-$|V|^{k}$。这说明，参数也要增加这么多。）当然，这里是基于统计的方法来训练的，这样的训练方式对应于一个大的n，就可能会出现大量的0，因为要统计的序列越长，相当于统计n个词同时出现的频次，这个概率一般较小。相反n较小，最好是一个单词，在语料库中出现的频次会越大。</p><p><strong>问题5：</strong></p><p>​        对于统计的模型的一个天然的问题是缺乏泛化能力。比方说“我喝了杯水”和“我喝了一杯水”这两个序列的出现概率是不同的，而且很可能是很不相同的，因为单词$P(“一”|w_{i-k:i})$的概率可能很小也可能很大，总之一字之差，甚至意思上也没有变化，然而却可能得到相差很大的出现概率。</p><p><strong>问题6：</strong></p><p>​        对于有些文本，目标词的出现可能只依赖于它前面出现的第i-k个单词，像is,was等等。而对其他单词都没有依赖，这种情况下对它前面出现的连续n个单词建模可能是不如人意的。这种情况，传统模型也束手无策。</p><p>​        总结来说，基于马尔科夫假设的传统模型本质上是基于概率统计的，甚至没有真正意义上的训练过程。这种基于统计的模型具有各种各样的缺点，直到神经网络的引入，部分问题才得到了相应地改善。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Unigram-Bigram和N-gram&quot;&gt;&lt;a href=&quot;#Unigram-Bigram和N-gram&quot; class=&quot;headerlink&quot; title=&quot;Unigram, Bigram和N-gram&quot;&gt;&lt;/a&gt;Unigram, Bigram和N-gram
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/categories/NLP/"/>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Word Representation</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/16/NLP/%E7%89%B9%E5%BE%81%E8%A1%A8%E7%A4%BA/Word%20Representation/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/16/NLP/%E7%89%B9%E5%BE%81%E8%A1%A8%E7%A4%BA/Word%20Representation/</id>
    <published>2020-06-15T16:00:00.000Z</published>
    <updated>2020-06-22T12:53:57.555Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Word-Representation？"><a href="#Word-Representation？" class="headerlink" title="Word Representation？"></a>Word Representation？</h3><p>​        传统的基于概率统计的语言模型，Unigram,Bigram,N-gram没有涉及到word representation,因为他们是基于统计训练的，因此在输入端可以不做textual feature 到input feature的转换。</p><p>​        但对于神经网络，训练过程需要有明确的数学形式的输入，而不是文本，这就引发了一个新的问题，如何实现textual feature 到neural feature的转换？</p><p><strong>One-hot和Eembedding</strong></p><p>一种是One-hot表示方法，一种是Embedding表示方法.</p><p>​        One-hot表示是一种稀疏表示，是将整个词典做为 一个向量，对应位置上的单词为1，其余为0。Embedding是运用分布式假设，将词向量在高维空间嵌入(映射)到低维空间。使其在每个维度上的表示都不至于为0。（即由所有嵌入后的维度共同表出，相比One-hot信息由单一维度表出变为了信息分布在了各个维度上）</p><p>分布式假设：在相似的语境中的目标词，具有相似性，具有相似性的单词，word representation形式相似度应该较高。</p><p><strong>Unigram：</strong></p><p>​        传统的Word representation方法是One-hot,目前流行的表示方法是词嵌入。当然这个只是对单词（最小意义单位）而言。</p><p><strong>N-gram:</strong></p><p>​        我们将N-gram（n&gt;=2）引入，可以发现，输入变为了多个单词（上下文+目标词）。解决方法是combination，combination的方法其实有很多，比较常见的有两种，一种是直接相加，一种是直接叠加。前者的代表是CBOW和WCBOW.</p><script type="math/tex; mode=display">CBOW(w_1,w_2,w_3,...w_k) = \frac{1}{k}\sum_{i}v(w_i)\\WCBOW(w_1,w_2,w_3,...w_k) = \frac{1}{\sum_{i=1}^ka_i}\sum_{i}a_iv(w_i)</script><p>两种叠加方式对两种word representation方法都是适用的。</p><p>​        当使用One-hot表示方法时，一个句子的表示可以由该句子中所有单词的One-hot表示方法相加，即One-hot的CBOW版本。</p><p>比方说：“I like sweat candy.”</p><p>以上句子的表示方法为：$V(S) = O(“I”)+O(“like”)+O(“sweat”)+O(“candy”)$</p><p>O(w)是单词的One-hot表示。</p><p>​        但是这样的表示方法不能够很好地衡量句子之间的相似性，因为它忽略了单词位置（词序）的影响。</p><p>另一种combination方法是叠加法。</p><p>​        当采用window-based时，即考虑窗口内的目标单词的前后文。输入变为了2c个单词。那么叠加法的方法就是将目标词前后各c个单词叠加在一起。</p><p>比方说$\mathbf{(w-2;w-1;w+1;w+2)}$.也可以$\mathbf{(w_{-2}+w_{-1});(w_{+1}+w_{+2})}$.这种在输入到神经网络的时候一般通过一个投射层将特征叠加起来。</p><h3 id="One-hot为什么失败？"><a href="#One-hot为什么失败？" class="headerlink" title="One-hot为什么失败？"></a>One-hot为什么失败？</h3><p>One-hot表示方法在与词嵌入表示方法竞争时失败了。至于原因是多方面的：</p><p>问题1：One-hot表示方法虽然简单，但不够优雅。它的维度是整个字典的长度，因此限制了输入的维度也必须是字典的长度。但是字典的长度一般在10的5次方到10的6次方左右，这也意味输入向量的维度在10的5次到6次方左右，会引入大量的稀疏性，尽管计算机对稀疏矩阵的运算比较快，显然这种表示方法不够好。</p><p>问题2：One-hot是一种硬编码，它只在对应的位置上有信息，而在其他位置上没有信息，这就造成当计算两个词向量之间相似性的时候，会出现问题。因为彼此都是正交的。</p><p>问题3：One-hot抛弃了位置信息，当输入需要引入前后文的时候，One-hot的做法是词向量直接相加或者叠加，相加的后果是对句子中出现的词进行了统计，可以表达一部分频率上的相似性，但是无法表达语义上的相似性。叠加的后果是进一步引入了稀疏性。</p><p>分布式表示方法没有上述的种种缺陷，因此更容易被业界接受。</p><h3 id="Embedding算法"><a href="#Embedding算法" class="headerlink" title="Embedding算法"></a>Embedding算法</h3><p><strong>关于如何实现词嵌入有两个流派：</strong></p><h4 id="Distributional-Hypothesis"><a href="#Distributional-Hypothesis" class="headerlink" title="Distributional Hypothesis"></a>Distributional Hypothesis</h4><p>​        NLP community 认为出现在相同语境中的单词具有相同的意思。（这个被称为<strong>Distributional Hypothesis。</strong>）基于此，可以根据单词在不同语境中的分布作为词向量来表示单词。这样出现在相同语境中的单词就会有相似的表示了。具体的操作如下：</p><p>​        假设存在一个词典集合和一个”语境集合“，这两个集合都是可索引的，$w_i$表示第i个单词，$c_j$表示第j种语境。（这里的词典集合和语境集合可以从一个大的语料库中得到，可以想象两个集合都会比较大。)存在一个矩阵实体$M_{[i,j]}]$，它的每一行代表字典集合中的一个单词，每一列代表一个语境集合中的语境，每一个元素$f(i,j)$代表单词$w_i$和语境$c_j$的association，这种association一般是通过统计$\mathbf{$}(w_i,c_j)$在语料库中的出现频次，或者标准化以后的形式$\frac{\mathbf{$}(w_i,c_j)}{|D|}$.|D|表示语料库的大小，即：</p><script type="math/tex; mode=display">f(i,j) =\frac{$(w_i,c_j)}{|D|}</script><p>​        但是这种表示存在一个问题，就是对于更常出现的word-context具有更高的权重（频次），比如：假设语境为目标词的前一个单词，那么”the cat”和”a cat”就要比”cute cat”和”small cat”的权重高的多，尽管后面的事件携带了更多的信息。也就是说对于出现不是那么频繁但是更有用的word-context，这种表示方法会比加的不公平。为了克服这种缺陷，提出了Pointwise Mutual Information(PMI)：</p><script type="math/tex; mode=display">PMI(x,y) = log\frac{P(x,y)}{P(x),p(y)}</script><p>在word-contex场景下，PMI测量的是他们共同出现的频率除以他们各自单独出现的频率。</p><script type="math/tex; mode=display">f(w,c) = PMI(w,c) = log\frac{$(w,c)·|D|}{$(w)·$(c)}</script><p>​        PMI和TF-IDF的思想相似，采用PMI可以避免给出现频次大的word-context更多的权重，给出现频次小的word-context的更小的权重。但是引入PMI表示仍然有些问题，对于没有出现在语料库中的word-context对，在计算PMI是会出现log(0)的现象。</p><p>因此对PMI加以改进，提出PPMI(positive PMI):</p><script type="math/tex; mode=display">PPMI(w,c) = max(PMI(w,c),0)</script><p>将低频出现的word-context给忽略掉（赋值为0）。</p><p> PMI在实际运行中表现良好，但是也存在一个比较明显的缺点：</p><p><strong>那就是容易对rare event赋予比较高的权重，尤其是当两个事件发生的频次都很低，又恰好发生在了一起的时候。</strong></p><p>​        采用Distributional Hypothesis假设的一个问题是，字典集合和语境集合都很大，他们都是从一个大的语料库中得到的，因此造成实体矩阵M很大。并且由于很多word-context对不会出现在语料库中，这又会造成矩阵很稀疏。解决方法是对实体矩阵进行降维。可以采用经典的降维方法比如SVD.这样，通过降维后的实体矩阵维度会变得比较容易让人接受，同时每个词向量又可以被表出。通过SVD降维后的词向量维度大约在50&lt;d&lt;300之间。</p><p>​        到此为止，经典的采用Distributional Hypothesis假设的方法介绍完毕。由于向量的表示是基于统计，准确地说是基于word-context数量的表示，因此也被成为count-based method.</p><p>问题：语境集合如何构造？是选取目标的前一个词还是前n个词，还是用目标词的上下文？</p><h4 id="Distributed-Representation"><a href="#Distributed-Representation" class="headerlink" title="Distributed Representation"></a>Distributed Representation</h4><p>​        相对于NLP派推崇的Distributional Hypothesis，神经网络派则比较推崇Distributed Representations。那么什么是Distributed representation?和Distributional Hypothesis的不同是什么？</p><p>​        在分布式表示（Distributed representation）中，一个单词的意思被多个维度共同表出。每个维度没有具体的含义，即不具可解释性（对比count-based可见，每个维度对应一个确定的语境）。分布式表示（Distributed）的本质是给定一个meaning（word）,它可以被多个维度的combination捕捉（表示），或者给定一个维度，它捕捉了meaning的一个aspect。</p><p>​        打个比方：”国王”。“国王”的属性有哪些呢？首先国王是个人，而且一般是个男人，“男人”可以作为“国王”的一个属性。其次，“国王”一般是个成年人，因此“成年人”也可以作为“国王”的一个属性，再来，从词性的角度来讲，“国王”是一个名词，因此“名词”也可以作为“国王”的一个属性。这么表示出来“国王”可以由[“男人”，“成年人”，‘名词“]来表示，每个属性都是一个维度，每个维度对应一个数值，用数值表示出来就是”国王“的词向量。</p><p>​        但是对于分布式表示来说，每个维度不具有可解释性，即给定一个分布式表示的词向量，每个维度所表示的含义无法获知。但是这个并不影响我们使用它们，即使不知道它们每个维度的所代表的的含义，一旦给出两个词向量表示，我们仍然可以用标准的相似度计算方法来计算。</p><p>​        分布式表示的另一个特点是需要训练。先让我们来看一下词嵌入在神经网络中的形式。</p><script type="math/tex; mode=display">\hat{y} = P(w_i|w_{1:k}) = LM(w_{1:k}) = softmax(hW^2+b^2)\\h = g(xW^1+b^1)\\x = [v(w_1);v(w_2);...;v(w_k)]\\v(w) = \mathbf{E}_{[w]}\\w_i \in V ,\mathbf{E}\in R^{(|V|,d_w)},W^1 \in R^{k·d_w,d_{hid}},b^1 \in R^{d_{hid}},W^2 \in R^{d_{hid},V},b^2 \in R^{|V|}</script><p>​        在这个模型中一共有两套参数，一个是$\mathbf{E}$,另外一个是$\mathbf{[W^1,W^2]}$.其中$\mathbf{E}$是词嵌入矩阵，因此我们可以通过训练模型来得到词嵌入矩阵。可以看到$\mathbf{W^2}$的列和$\mathbf{E}$的行都是一种distributed representation表示。训练过程保证了词嵌入矩阵的值足够好，因为对于一个有着k-gram的输入，他们产生了正确的预测概率（对于指定的预测目标）。通过网络的训练过程，我们可以得到最终的词嵌入矩阵。这是大多数distributed representation的生成方式。</p><p>语言模型有两个功能需求，给定一个语境，推测目标词的分布。另一种：</p><p>the need to condition on contexts that can be combined using the chain-rule of probability to produce sentence level probability estimates  </p><p>这个我怕翻译不准，个人理解是给定一个词向量，利用链式法则去预测句子的生成概率。如下图所示（摘自word2vec论文）：</p><p><img src="/2020/06/16/NLP/%E7%89%B9%E5%BE%81%E8%A1%A8%E7%A4%BA/Word%20Representation/distributed_representation.PNG" alt="distributed_representation"></p><p>以上是distributed representation的一个框架，具体的训练方法有几种。</p><p><strong>Collobert and Weston</strong></p><p>这两个人做了两点创新：</p><p>​        一个是改变了传统的使用k-gram的假设，引入了word-window，将使用前k个gram改为了使用目标词的上下文（这个贡献是他们俩人做的）。使用$P(w_3|w_1,w_2,w_4,w_5)$代替了$P(w_5|w_1,w_2,w_3,w_4)$。</p><p>​        另一个是改变了输出的形式，传统的softmax方案（语言模型的输出）是输出字典中每个单词作为目标词的概率。而如果只是注重representation的生成，那么可以适当对输出进行更改，不是输出每个目标词的概率分布，而是输出一个分数（score）。</p><p>​        具体的实现方式如下：对于一个目标单词w, $c_{i:k}$为它的上下文的序列。$V_w(w)$为词嵌入函数，$V_c(c)$为context嵌入函数。这两个函数将目标词和context映射到一个相同的维度$d_{emb}$.Collorbert 和Weston对模型输入一个$（w,c_{1:k}）$对，然后将这个word-context对结合成一个输入$\mathbf{x}$作为神经网络的输入，通过单隐含层，输出一个word-context的分数s。</p><script type="math/tex; mode=display">S(w,c_{1:k}) = g(\mathbf{xU})·\mathbf{v}\\\mathbf{x} = [V_c(c_1);....;V_c(c_k);V_w(w)]\\\mathbf{U} \in R^{(k+1)d_{emb},d_h}, \mathbf{v}\in R^{d_h}.</script><p>损失函数为：</p><script type="math/tex; mode=display">L(w,c,w') = max(0,1-(s(w,c_{1:k})-s(w',c_{1:k})))</script><p>​        w’是一个从字典中随机抽出来的单词。训练过程轮循地遍历word-context对，并且对于每一word-context对，随机采样一个单词w’,使用w’计算损失L(w,c,w’)，并且更新$\mathbf{U,v}$和词向量对去最小化损失。这就是随机负采样的思想。</p><p><strong>word2vec</strong></p><p><strong>NCE</strong></p><p><strong>Glove</strong></p><p>等等。每个都够写一章了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Word-Representation？&quot;&gt;&lt;a href=&quot;#Word-Representation？&quot; class=&quot;headerlink&quot; title=&quot;Word Representation？&quot;&gt;&lt;/a&gt;Word Representation？&lt;/h3&gt;&lt;
      
    
    </summary>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/categories/NLP/"/>
    
    
      <category term="NLP" scheme="https://qingfengbangzuo.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow2.0以上cpu版本安装方法</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/15/%E5%85%B6%E4%BB%96/tensorflow2.0%E4%BB%A5%E4%B8%8Acpu%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/15/%E5%85%B6%E4%BB%96/tensorflow2.0%E4%BB%A5%E4%B8%8Acpu%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/</id>
    <published>2020-06-15T01:27:15.080Z</published>
    <updated>2020-06-22T12:05:53.610Z</updated>
    
    <content type="html"><![CDATA[<p>安装tensorflow cpu 2.0以上版本。</p><p>python2.0已经支持python3.7了。不过我装的还是3.6的pyhon。</p><p>Anaconda的安装教程就不说了，按照网上来就OK了。这里只简单记录下如何安装tensorflow-cpu版本。</p><p>安装命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">0: conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free&#x2F;</span><br><span class="line">0: conda config --set show_channel_urls yes  &#x2F;&#x2F;清华镜像 </span><br><span class="line">1: pip install tensorflow-cpu</span><br><span class="line">2: pip install tensorflow-cpu&#x3D;&#x3D;2.1.0 -i https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple</span><br><span class="line"></span><br><span class="line">3: pip install --ignore-installed --upgrade tensorflow  &#x2F;&#x2F;这个是老方法，已经不行了，最新的tensorflow是将cpu-gpu版本绑定在一起的，使用这条命令下载大概率会报错。推荐使用上面两条</span><br></pre></td></tr></table></figure><p>安装完成，测试一下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"> </span><br><span class="line">version = tf.__version__</span><br><span class="line"><span class="comment"># pu_ok = tf.test.is_gpu_available()</span></span><br><span class="line">gpu_ok = tf.config.list_physical_devices(<span class="string">"GPU"</span>)</span><br><span class="line">print(<span class="string">"tf version:"</span>, version, <span class="string">"\nGPU number"</span>, gpu_ok)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">tf version: <span class="number">2.1</span><span class="number">.0</span> </span><br><span class="line">GPU number[]</span><br></pre></td></tr></table></figure><p>可能会报错，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"</span>, line <span class="number">58</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> tensorflow.python.pywrap_tensorflow_internal <span class="keyword">import</span> * </span><br><span class="line">File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"</span>, line <span class="number">28</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    _pywrap_tensorflow_internal = swig_import_helper()</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"</span>, line <span class="number">24</span>, <span class="keyword">in</span> swig_import_helper</span><br><span class="line">    _mod = imp.load_module(<span class="string">'_pywrap_tensorflow_internal'</span>, fp, pathname, description)</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\imp.py"</span>, line <span class="number">242</span>, <span class="keyword">in</span> load_module</span><br><span class="line">    <span class="keyword">return</span> load_dynamic(name, filename, file)</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\imp.py"</span>, line <span class="number">342</span>, <span class="keyword">in</span> load_dynamic</span><br><span class="line">    <span class="keyword">return</span> _load(spec)</span><br><span class="line">ImportError: DLL load failed: 找不到指定的模块。</span><br><span class="line"> </span><br><span class="line">During handling of the above exception, another exception occurred:</span><br><span class="line"> </span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\site-packages\tensorflow\__init__.py"</span>, line <span class="number">101</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> tensorflow_core <span class="keyword">import</span> *</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\site-packages\tensorflow_core\__init__.py"</span>, line <span class="number">40</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> tensorflow.python.tools <span class="keyword">import</span> module_util <span class="keyword">as</span> _module_util</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\site-packages\tensorflow\__init__.py"</span>, line <span class="number">50</span>, <span class="keyword">in</span> __getattr__</span><br><span class="line">    module = self._load()</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\site-packages\tensorflow\__init__.py"</span>, line <span class="number">44</span>, <span class="keyword">in</span> _load</span><br><span class="line">    module = _importlib.import_module(self.__name__)</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\importlib\__init__.py"</span>, line <span class="number">127</span>, <span class="keyword">in</span> import_module</span><br><span class="line">    <span class="keyword">return</span> _bootstrap._gcd_import(name[level:], package, level)</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\site-packages\tensorflow_core\python\__init__.py"</span>, line <span class="number">49</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> tensorflow.python <span class="keyword">import</span> pywrap_tensorflow</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"</span>, line <span class="number">74</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">raise</span> ImportError(msg)</span><br><span class="line">ImportError: Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"</span>, line <span class="number">58</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> tensorflow.python.pywrap_tensorflow_internal <span class="keyword">import</span> *</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"</span>, line <span class="number">28</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    _pywrap_tensorflow_internal = swig_import_helper()</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"</span>, line <span class="number">24</span>, <span class="keyword">in</span> swig_import_helper</span><br><span class="line">    _mod = imp.load_module(<span class="string">'_pywrap_tensorflow_internal'</span>, fp, pathname, description)</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\imp.py"</span>, line <span class="number">242</span>, <span class="keyword">in</span> load_module</span><br><span class="line">    <span class="keyword">return</span> load_dynamic(name, filename, file)</span><br><span class="line">  File <span class="string">"C:\Programs\Python\tensorflow210_cpu\lib\imp.py"</span>, line <span class="number">342</span>, <span class="keyword">in</span> load_dynamic</span><br><span class="line">    <span class="keyword">return</span> _load(spec)</span><br><span class="line">ImportError: DLL load failed: 找不到指定的模块</span><br><span class="line">————————————————</span><br></pre></td></tr></table></figure><p>原因说不清楚，不过有人给出了解决方法:</p><p><strong>到微<a href="https://visualstudio.microsoft.com/zh-hans/downloads/?q=Microsoft+Visual+C%2B%2B+Redistributable" target="_blank" rel="noopener">软官方网</a>下载最新的Visual C++库的运行组件（链接下方），然后更新，重启，问题解决。</strong></p><p>再把上面的测试代码写一遍就会显示正确信息了。</p><p><img src="/2020/06/15/%E5%85%B6%E4%BB%96/tensorflow2.0%E4%BB%A5%E4%B8%8Acpu%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/捕获.png" alt="测试结果"></p><p>然后去Anaconda用户页面选中需要的库安装，基本的比如ipython,jupyter notebook,spyder这些是要用到的，装一下。</p><p>done!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;安装tensorflow cpu 2.0以上版本。&lt;/p&gt;
&lt;p&gt;python2.0已经支持python3.7了。不过我装的还是3.6的pyhon。&lt;/p&gt;
&lt;p&gt;Anaconda的安装教程就不说了，按照网上来就OK了。这里只简单记录下如何安装tensorflow-cpu版
      
    
    </summary>
    
    
      <category term="疑难杂症" scheme="https://qingfengbangzuo.github.io/categories/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"/>
    
    
      <category term="其他" scheme="https://qingfengbangzuo.github.io/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
  <entry>
    <title>层次聚类</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/Hierarchical/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/Hierarchical/</id>
    <published>2020-06-12T11:01:59.835Z</published>
    <updated>2020-06-12T11:02:55.502Z</updated>
    
    <content type="html"><![CDATA[<h1 id="层次聚类"><a href="#层次聚类" class="headerlink" title="　层次聚类"></a>　层次聚类</h1><p>聚类方法总体来说分为两类：一类是分割型的(partitioning)，另一种是层次型(hierarchical).</p><p>层次聚类从聚类的方式来看分为bottom-up自底向上(merge)，和top-down自上而下(split)。对于层次型聚类，我们可以选择聚类的个数作为停止条件，也可以选择一个距离threshold,当所有类之间的距离满足threshold之后，聚类停止。</p><p>自上而下的分类型算法大体如下：</p><ol><li>设置停止条件。</li><li>将所有的数据都视为一个大类，然后计算所有数据点之间的距离。(这个距离不只是指欧几里得距离)，在所有的类中，选择距离最大的两个点分别归入类c1和c2。且将这两个点作为类中心。</li><li>对所有数据点进行聚类，也就是计算所有数据点距离c1和c2中心点的距离，距离哪个近就归入哪一类。</li><li>重复步骤2,3，直到满足停止条件。</li></ol><p>自下而上的merge算法大体如下：</p><p>​    1.将所有的样本都当做一个类簇。</p><p>​    2.计算两个类的之间的距离，找到两个距离最小的两个簇c1和c2</p><p>​    3.合并类c1和c2为一个类簇。</p><p>​    4.重复步骤2,3，直到满足停止条件。</p><p>层次聚类的思想是简单的，主要是计算距离的方式：</p><p>1.单连接(single-link).找到两个簇之间距离最小的两个样本的距离最为两个集合的距离，也就是说，最近两个样本之间的距离越小，这两个类之间的相似度越大。</p><p>2.全连接.(complete-link).找到两个簇之间距离最大的两个样本的距离为两个集合的距离。</p><p>3.把两个集合中的点两两的距离全部放在一起求一个平均值，相当于也能得到合适一点的结果。</p><p>4.取两两距离的中值，与取平均值相比更能够解除个别偏离样本对结果的干扰。</p><p>5.把两个集合中的点两两的距离全部放在一起求和然后除以两个结合中的元素个数</p><p>6.求每个集合的中心点（也就是将集合中的所有元素对应维度相加然后除以元素个数得到一个向量），然后用中心点代替集合再去计算集合间的距离。</p><p>7.　ward距离（适用于merge），最小化被聚合的类的方差。<br>8.　余弦距离。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;层次聚类&quot;&gt;&lt;a href=&quot;#层次聚类&quot; class=&quot;headerlink&quot; title=&quot;　层次聚类&quot;&gt;&lt;/a&gt;　层次聚类&lt;/h1&gt;&lt;p&gt;聚类方法总体来说分为两类：一类是分割型的(partitioning)，另一种是层次型(hierarchical).&lt;/p
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/"/>
    
      <category term="聚类算法" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="ML" scheme="https://qingfengbangzuo.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>密度聚类(DBSCAN)</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/DBSCAN/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/DBSCAN/</id>
    <published>2020-06-12T10:59:57.087Z</published>
    <updated>2020-06-12T11:01:35.885Z</updated>
    
    <content type="html"><![CDATA[<p>聚类主要分为两种类型，一种是partitioning,另一种是hierarchical。层次聚类属于第一种，是为了解决大数据下的聚类参数不好设置和自动聚类的问题。</p><p>主要依据是利用类内的点密度大于类外噪声。</p><p>The key idea is that for each point of a cluster the neighbor-<br>hood of a given radius has to contain at least a minimum<br>number of points, i.e. the density in the neighborhood has to<br>exceed some threshold。</p><p>距离的定义决定了最后聚类的形状，因此合适的距离函数（相似性函数）对聚类效果有比较大的影响，在实际应用中可以根据实际需求定义合适的距离函数。</p><p>Definition 1: (Eps-neighborhood of a point) The Eps-<br>neighborhood of a point p, denoted by NEps(P), is defined<br>NEps(P) = {q E D I dist(p,q) _&lt; Eps}</p><p>定义２：(直接密度可达direct-density-reachable)一个点p对于点q是密度度可达的条件如下：</p><ol><li><p>$p \in N_{Eps}(q)$</p></li><li><p>$|N_{Eps}|&gt;= MinPts$(core point condition)</p></li></ol><p>定义３：(密度可达(density-reachable))：一个点Ｐ是密度可达点q wrt.Eps and MinPts，当存在一条链，该链满足p1,p2,…pn(pn=q)，$p_{i+1}$是直接密度可达from$p_i$。</p><p>Definition 4: (density-connected) A point p is density-<br>connected to a point q wrt. Eps and MinPts if there is a point<br>o such that both, p and q are density-reachable from o wrt.<br>Eps and MinPts.<img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/DBSCAN/2020-05-13 10-33-44屏幕截图.png" alt="2020-05-13 10-33-44屏幕截图"></p><p>简单解释一下，密度可达是对直接密度可达的扩展，直接密度可达是指，当点q满足核心点条件时，点p直接可达点q，要满足p在以点q为核心，以Eps为半径的园内。</p><p>密度可达对这个概念进行了扩展，密度可达是指当点q满足核心点条件时，p密度可达q，是指在以q为核心，以Eps为半径的园内存在至少一点o，该点也满足核心点条件，并且在以该点o为核心，以Eps为半径的园内存在一点p（包括边界点）。这是三点的情况，可以继续以o为核心继续扩展边界，只要满足p1,p2,…pn满足pn密度可达pn-1。这个概念也是不对称的，因为点p可能不满足核心点条件，因此不能说p密度可达q，而q也密度可达p。</p><p>密度连接性是对上述概念的进一步扩展，指的是，存在一核心点o,在以改点为核心，以Ｅps为半径的园内存在两点a和b。这两个点也满足核心点条件，且p在以a为核心，Eps为半径的圆内，q在以b为核心，以Eps为半径的圆内，那么就可以说p和q是密度连接的。</p><p>有了上述概念，就可以定义聚类标准了：</p><p>Definition 5: (cluster) Let D be a database of points. A<br>cluster C wrt. Eps and MinPts is a non-empty subset of D<br>satisfying the following conditions:<br>1) $All \quad p, q: ifp E C$ and q is density-reachable from p wrt.<br>Eps and MinPts, then $q \in C$. (Maximality)<br>2) V$All \quad p, q \in C$: p is density-connectedto q wrt. EPS and<br>MinPts. (Connectivity)</p><p>Definition 6: (noise) Let $C_t ….. C_k $be the clusters of the<br>database D wrt. parameters Epsi and MinPtsi, i = 1 ….. k.<br>Then we define the noise as the set of points in the database<br>D not belonging to any cluster Ci , i.e. noise = {$p \in D$ I $All\quad i: p \notin Ci$)</p><p>简单讲就是，对于$q \in C_i$，q满足核心点要求，对于所有密度可达q的点p，都有$p \in C_i$。而同一个类内的点p和q，都满足密度可链接。</p><p>道理是清晰的，这个是收敛的，收敛的条件是当聚类外侧的点都不满足核心点条件。</p><p>这里有一个判断是否聚类的标准：</p><p>Lemma1: Let p be a point in D and INEps(p)l &gt; MinPts.<br>Then the set O = {o I o E D and o is density-reachable from<br>p wrt. Eps and MinPts } is a cluster wrt. Eps and MinPts.</p><p>接下来的问题就转换成如何确定合适的Eps和MinPts了。作者给出了一个启发式的算法来自动确定在这两个值，</p><p><img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/DBSCAN/2020-05-13 11-01-45屏幕截图.png" alt="2020-05-13 11-01-45屏幕截图"></p><p>大概意思就是定义一个核心点到第k个最近距离的点p的距离k-dist。然后根据这个距离遍历所有的点，对于噪声有这样的特性，就是噪声的k-dist一般都比较大，因为他们是离群的，而一般聚类内部的点的k-dist都比较小。这样，取第一个峰谷，作为threshold。作者经过实验，发现对于2维数据，k取４就足够了，此时对应的threshold就可以作为Eps，MinPts取４．</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;聚类主要分为两种类型，一种是partitioning,另一种是hierarchical。层次聚类属于第一种，是为了解决大数据下的聚类参数不好设置和自动聚类的问题。&lt;/p&gt;
&lt;p&gt;主要依据是利用类内的点密度大于类外噪声。&lt;/p&gt;
&lt;p&gt;The key idea is that
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/"/>
    
      <category term="聚类算法" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="ML" scheme="https://qingfengbangzuo.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>Kmeans</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/kmeans/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/kmeans/</id>
    <published>2020-06-12T10:57:42.337Z</published>
    <updated>2020-06-12T10:59:49.658Z</updated>
    
    <content type="html"><![CDATA[<h3 id="kmeans算法数学原理"><a href="#kmeans算法数学原理" class="headerlink" title="kmeans算法数学原理"></a>kmeans算法数学原理</h3><p>目标函数：</p><script type="math/tex; mode=display">J = \sum_{j=1}^K\sum_{i=1}^N z_{i,j} dist(x_i,\hat{x_j})^2</script><p>初始的kmeans算法使用的是欧几里得距离(l2)。</p><p>K代表聚类的数目，N代表数据的个数，$z_j$是latent变量, $\hat{x_j}$表示聚类j内的所有数据点的均值。</p><p>那我们规定:</p><script type="math/tex; mode=display">z_{i,j} = 1, if  \quad j = argmin_j ||x_i-\hat{x_j}||^2\\0,ohters.</script><p>对$\hat{x_j}$求偏导：</p><script type="math/tex; mode=display">2\sum_{i=1}^Nz_{i,j}(x_i-\bar{x_j}) = 0</script><p>可得：</p><script type="math/tex; mode=display">\hat{x_{j}} = \frac{\sum_{i}r_{i,j}x_i}{\sum_{n}r_{i,j}}</script><p>当我们引入latent变量以后，我们发现，通过给定$\hat{x_j}$一个初值，我们可以计算出所有数据的$r_{i,j}$（E步），而后，根据偏导我们又可以得到$\hat{x_j}$，这个值从表面上看就是属于聚类j的所有点的均值(M步)。</p><p>要注意这个值是从偏导得来的。</p><p>因此，kmeans算法可以简单的归结为：</p><p>1.初始化聚类数目和初始的中心点$\hat{x_j}$.</p><p>2.根据最小化$dist(x_i,\hat{x_j})^2$，对隐含变量$z_{i,j}$赋值。</p><p>3.根据得到的$z_{i,j}$,更新中心点$\hat{x_j}$。</p><p>4.重复步骤２，３，直到算法满足停止条件，结束迭代。</p><p>5.输出中心点坐标。</p><p>对于$\hat{x_j}$的更新公式有一个在线版本：</p><script type="math/tex; mode=display">\mathbf{u_j}^{new} = \mathbf{u_j}^{old}+\eta_i(\mathbf{x_i}-\mathbf{u_j^{old}})</script><p><strong>算法不足</strong></p><p>１、对异常点敏感。主要原因是平均值对噪声比较敏感。</p><p>２、很难发现大小差别很大的簇，也就是说小簇很容易被归为大簇。</p><p>３、依赖于k值和初始质心的选择，不好的质心容易陷入局部最优。</p><p>４、对离散特征的处理不是很好。</p><p><strong>初始值</strong></p><p>SSE下降幅度越大，说明初始质心选择教好。</p><p>初始值选择会影响到kmeans最终的收敛效果。</p><h3 id="效果衡量指标"><a href="#效果衡量指标" class="headerlink" title="效果衡量指标"></a>效果衡量指标</h3><p><strong>SSE (sum of square error)：误差平方和</strong></p><script type="math/tex; mode=display">SSE = \sum_{i=1}^k\sum_{p\in C_i}|p-m_i|^2</script><p>$C_i$表示簇i。$m_i$表示簇i的簇质心。$p$属于簇内的样本点。</p><p>SSE表示簇内样本点到质心的距离之和，反应簇内的松散度。簇越紧密SSE越小，反之越大。</p><p>SSE受到初始质心位置的选择的影响，当质心选的不好的时候，SSE的变化教缓。而当质心选的好的时候，SSE的变化会先呈现剧烈下降，而后平缓下降。</p><p><strong>肘策略(Elbow method)</strong></p><p>SSE随着聚类的簇的数量增加会呈现出减小的趋向。当只有一类的时候，此时SSE为整个数据集上最大，当有n类（n是样本量）时，SSE为０．</p><p>从这个角度看，我们可以根据SSE随k变化的走向来选取合适的k。合适的k有这样的特征，小于k的SSE做急速下降，大于k的SSE做平缓下降。</p><p><strong>轮廓系数SC(Silhouette Coefficient)</strong></p><script type="math/tex; mode=display">S = \frac{(b-a)}{max(a,b)}</script><p>从公式可以看出$S \in [0,1]$. a表示样本i到同一簇内的其他点的不相似度（距离）的平均值。b表示样本i到其他簇的平均不相似（距离）度的最小值。a越小说明它更应该被分到该簇，反之相反。b越大说明改点离其他簇的距离越大，说明簇的离散度更好，反之则说明两个簇贴的比较近。</p><p><img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/kmeans/2020-05-09 12-19-07屏幕截图.png" alt="2020-05-09 12-19-07屏幕截图"></p><p>轮廓系数结合了凝聚度和离散度两个指标。每次聚类后每个样本都会有一个轮廓系数，当它为１时，说明这个聚类对于该样本点来说非常好，当它为０的时候，说明这个点可能处在边界上，当小于０时，暗示分类错误了。</p><p>但是仅仅使用sc这一个指标无法很好的衡量聚类效果，因为当一些小的聚类被聚合成了一个大类时，这个指标反应不出来这种情况。因此需要结合另一个指标，轮廓宽度。轮廓宽度即字面意思，表示单个簇的轮廓大小。在sc差不多的情况下，各簇的轮廓宽度越均匀越好。轮廓宽度指的是簇的样本数目大小。</p><p>轮廓宽度可以用平均SSE来衡量？</p><p><strong>ＣＨ(Calinski-Harabasz)</strong></p><p>类别内部数据的距离平方和越小越好，类别之间的距离平方和越大越好，CH的值越大说明聚类效果越好。</p><script type="math/tex; mode=display">CH(k) = \frac{SSB}{SSW}\frac{m-k}{k-1} \\SSW = \sum_{i=1}^m||x_i-C_{pi}||^2 \\SSB = \sum_{j=1}^kn_j||C_j-mean(X)||^2</script><p>m为训练集数目，k为类别数。<img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/kmeans/2020-05-09 12-50-28屏幕截图.png" alt="2020-05-09 12-50-28屏幕截图"></p><p>mean(X)表示训练集所有数据点的中心点。$n_j$表示第j个簇内样本点的个数。$C_j$表示簇内质心。</p><p>(m-k)/(k-1)的含义是希望使用尽可能少的类来聚合尽可能多的数据集。</p><p>还有一个和CH差不多的指标</p><p><strong>WB</strong></p><script type="math/tex; mode=display">WB = K\frac{SSW}{SSB}</script><p>这个指标是越小越好，表达的意思和上面CH差不多。</p><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>鉴于kmeans算法的缺点</p><p>1、对异常值敏感</p><p>解决方法：标准化</p><p>2、容易将小类数据归并为大类</p><p>３、容易收到初始参数的影响：k值和初始知心的选择。</p><p><strong>Canopy(树冠)算法帮助确定k值</strong></p><p>Canopy算法的大致思路为：</p><p>确定一个半径为$T_1$和一个半径为$T_2$的圆，$T_1&lt;T_2$。随机选定一个初始点Ｏ，然后以此为中心以$T_1$ 和$T_2$为半径画两个圆，那么数据集将会被$T_1，T_2$划分为三部分，第一部分为$T_1$内部，被标为初始质心的近点。其次为$T_1$　和$T_2$的截出来的空心圆，落在该区域内的点被标为模棱两可的点。最后是$T_2$外侧的点，被标记为远点。</p><p>然后在落在远点区域的数据点中，随机选出一个数据点E执行以上操作，$T_1$和$T_2$不变，会发现，原先落在空心圆内的一部分数据点现在被标为了E为质心的圆的近点。</p><p>在O和E的共同外点中随机选择一点Q执行以上操作，知道所有的外点都被标为了近点。</p><p>最终根据Canopy算法返回的k值(质心数目)作为kmeans算法k值选取的参考，可以大致确定k值的取值范围。</p><p><strong>评价：</strong>这种方法在一定程度上能够帮助确定kmeans算法k值的选择，但是有一个痛点就是$T_1$和$T_2$的选择不好确定。</p><p><strong>KMeans++</strong></p><p>该算法是对kmeans算法的改进，针对的是kmeans算法初始质心选择的问题。</p><p>kmeans++认为初始质心的选择相隔的越远越好，这个<strong>远</strong>通过公式</p><script type="math/tex; mode=display">P = \frac{D(x)^2}{\sum_{x\in X}D(x)^2}</script><p>来刻画。就是说先随机确定一个质心，然后根据上面的公式选取另Ｐ足够大的另一个数据点作为第二个质心。这里的p是一个概率值，选第二个质心的时候是依据概率Ｐ选的，p值越大，说明被选的概率越大。</p><p>但是这样做有几个地方没有解释清楚，１、这种方式明显受离群值的影响较大。２、到底多远算是合适，选择距离初始质心最远的点显然也不合适。3、多个质心的时候如何选择。</p><p><strong>二分KMeans</strong></p><p>二分kmeans算法遵循了一个原则，SSE越大的簇，聚类情况越不好，内部可能包含了多个小簇。因此对它进行二分。</p><p>算法流程：</p><p>１、对数据集选定两个初始质心，进行二分。</p><p>２、计算SSE，在当前所有的簇中，找出SSE较大的那个簇。</p><p>３、对２步骤中找出簇进行选点，二分。</p><p>４、重复2-3，知道簇的数量达到了k设定的数量。(这里个人认为也可以将SSE下限作为停止条件，或者两者结合使用)</p><p>二分kmeans的优点是算法原理清晰，效率高。且受初始质心的选择的影响小。因为即使一开始选择了一个不怎么好的质心，在接下来的分裂中也会把这个不好的簇再次划分开。但是，受影响小不代表不受影响，如果一开始就选择的质心不好，会使得后续的分裂过程增加，且容易使得某些簇过小。因此，结合kmeans的思想，初始质心的选择最好分的越开越好。</p><p>二分kmeans的另一个优点是，最后划分的簇中，每个簇的SSE都不会很大。</p><p><strong>Kernel KMeans</strong></p><p>原理：在低维线性不可分的数据集，映射到高维可能线性可分。(核函数的机制)</p><p>kernel kmeans对于低维线性不可分的数据相对传统的kmeans算法有较大的提升，但是随之而来的计算开销也陡然上升。</p><p>因此传统的kmeans适用于低维线性可分的情况，而kernel kmeas适用于低维线性不可分的情况。两者各有利弊。</p><p><strong>k-medoids(k-中心聚类)</strong></p><p>该算法针对kmeans算法对异常值敏感这一痛点进行优化。核心思想是利用数据点本身作为质心。这样可以避免异常值带来质心偏移。</p><p>算法流程：</p><p>１、选点，任意选取k个点作为初始质心。</p><p>２、聚类。距离使用的是曼哈顿距离。（sum of Absolute Differences）</p><script type="math/tex; mode=display">SAD = \sum_{m=1}^k\sum_{p_i \in C_i}dist(p_i,o_i)=\sum_{m=1}^k\sum_{p_i \in C_i}\sqrt{\sum_{j=1}^{n_{C_i}}(p_{i,j}-o_{i,j})^２}</script><p>３、遍历。对于第i类中的所有点，遍历第i类中除medoids外的所有点作为质心时的代价，选择代价最小的值作为新的质心。</p><p>４、迭代。重复２－３，直到medoids不再变化。</p><p>５、返回聚类结果。</p><p>k-medoisds算法的pors 和cons</p><p>优点是：对异常值不敏感，因为使用的是实际的数据点。其次，，每次运行的偏差小。最后，对初始的medoisds设置不敏感。<strong>对类别特征也适用。</strong></p><p>缺点是: 运算复杂度高，适合低维小数据量。而当数据量升高时，较少的异常值对kmeans算法的影响也有限，因此kmeans算法实际应用的频率要高于k-medoisds。(kmeans计算复杂度要低)<img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/kmeans/2020-05-09 19-20-14屏幕截图.png" alt="2020-05-09 19-20-14屏幕截图"></p><p><strong>ISODATA(Iterative Self Organizing Data Analysis Techniques Algorithm)</strong></p><p>该算法的一个显著特点就是类别数目会随着聚类的过程而变化，比方说初始设定的k值为２０,那么最终的聚类结果会在[k/2, 2k]之间。</p><p>对类别数的“合并”：当聚类结果的某一类中的样本数目太少，或两个类间的距离太近。</p><p>对类别数的“分裂”：当聚类结果中的某一类的类内方差太大，将该类进行分裂。</p><p>ISODATA算法应用于卫星图像聚类。</p><p><strong>Mini-Batch K-Means</strong>（适合大数据量）</p><p>mini-batch kmeans算法是针对大数据量而设计的一个优化算法，当数据量大于１万的时候，就要考虑使用mini-batch kmeans了。</p><p>顾名思义，mini-batch(分批处理)的方法对数据点之间的距离进行计算。</p><p><img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/kmeans/2020-05-12 11-08-48屏幕截图.png" alt="2020-05-12 11-08-48屏幕截图"></p><p>计算过程不必使用所有样本数据，而是从不同类别的样本数据中抽取一部分出来代表各自类型进行计算。由于样本量少，所以相应的运行时间会减小。</p><p>mini-batch是聚类精度和运行效率之间的一个折中，当使用所有样本进行聚类时，聚类精度会达到最高，当使用随机样本进行聚类时，效率最高，但是精度较差，mini-batch在两者之间取得了一个很好的折中，当batch值选择好的情况下，min-batch kmeans的聚类精度不会很差。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><div class="table-container"><table><thead><tr><th>-</th><th style="text-align:center">-</th></tr></thead><tbody><tr><td>Canopy+kmeans</td><td style="text-align:center">粗聚类选择大致的Ｋ值范围</td></tr><tr><td>kmeans++</td><td style="text-align:center">优化了初始质心的选择问题，初始质心距离越远越好</td></tr><tr><td>二分kmeans</td><td style="text-align:center">解决聚类小类容易归入大类的问题</td></tr><tr><td>ISODATA</td><td style="text-align:center">动态聚类</td></tr><tr><td>k-medoids</td><td style="text-align:center">解决对异常值敏感问题</td></tr><tr><td>mini-batch kmeans</td><td style="text-align:center">解决大数据量样本效率低下问题，分批进行聚类，损失小部分精度换取计算速度</td></tr><tr><td>kernel kmeans</td><td style="text-align:center">解决线性低维现行不可分的问题</td></tr></tbody></table></div><p>各类算法都各有优劣，要明确使用的场景。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;kmeans算法数学原理&quot;&gt;&lt;a href=&quot;#kmeans算法数学原理&quot; class=&quot;headerlink&quot; title=&quot;kmeans算法数学原理&quot;&gt;&lt;/a&gt;kmeans算法数学原理&lt;/h3&gt;&lt;p&gt;目标函数：&lt;/p&gt;
&lt;script type=&quot;math/t
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/"/>
    
      <category term="聚类算法" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="ML" scheme="https://qingfengbangzuo.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>高斯过程</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/</id>
    <published>2020-06-12T00:42:16.850Z</published>
    <updated>2020-06-12T10:56:30.999Z</updated>
    
    <content type="html"><![CDATA[<p>如果不懂高斯过程的话，就假设$f(x) = w^Tx$这个函数为一个变量，而这个变量服从一维高斯分布。换句话理解，假设w先验服从一个高斯分布，那么给定一个确定值x，$w^Tx$是一个服从一维高斯分布的变量。所以说，高斯过程的假设与参数先验分布的假设是等价的。</p><p>高斯过程的假设是：</p><p>对于回归模型$y = f(X)+\epsilon$，若函数$f(X)$的形式不是固定的，则其为潜函数（可理解为一个变量），即它的每个取值都是函数空间的一个测度。GPR假设该函数的先验分布服从均值为0的高斯分布：</p><script type="math/tex; mode=display">f(X) \sim N(0,K(X,X'))</script><p>假设有N个样本，样本空间为$R_d$维度，对于所有的$n\in N,X = \{X_1,X_2…,X_n\}\in R_d$有</p><script type="math/tex; mode=display">P([f(X_1),...,f(X_t)]) \sim N([0,k(X,X')])</script><p>式中k(X,X’)为核函数，0均值高斯过程由其核函数完全决定,高斯过程就是假设这个联合分布服从均值为0，方差为K的高斯分布：</p><script type="math/tex; mode=display">k(X,X') = E[f(X)f(X')]</script><p>该核函数本质是一个关于x的函数，反应的是相应随机变量$f(x_1)$和$f(x_2)$之间的相关程度。</p><h4 id="从线性回归推高斯过程"><a href="#从线性回归推高斯过程" class="headerlink" title="从线性回归推高斯过程"></a>从线性回归推高斯过程</h4><p>从线性回归出发推高斯过程也称作从参数空间的角度出发理解高斯过程。</p><p>考虑一个线性函数</p><script type="math/tex; mode=display">y = w^T\phi (x)+\epsilon</script><p>假设$p(\epsilon)\sim N(0,\delta^2)$，那么</p><script type="math/tex; mode=display">P(\mathbf{y}|X,w,\delta^2) \sim \prod_{n=1}^NN(y_n|w^T\phi(x_n),\delta^2)</script><p>在此基础上，假设模型的权重w服从先验分布$p(w) \sim N(w|0,\alpha I)$.由贝叶斯定理可知</p><script type="math/tex; mode=display">p(\mathbf{w}|\mathbf{y},X)\propto p(\mathbf{y}|\mathbf{w},X)p(\mathbf{w})</script><p>由高斯分布的共轭性可知，对于正太分布的似然函数和方差已知的正太先验分布，其后验分布也为正太分布，因此参数后验分布如下</p><script type="math/tex; mode=display">p(w|y,X) \sim N(w|\frac{1}{\delta^2}S_N\Phi y,S_N)\\S_N^{-1} = \alpha I + \frac{1}{\delta^2}\Phi^T\Phi</script><p>对这个参数后验分布取log可得</p><script type="math/tex; mode=display">lnp(\mathbf{w|y}) = -\frac{1}{2\delta^2}\sum_{n=1}^N\{y_n-\mathbf{w^T}\phi(x_n)\}^2 - \frac{\alpha}{2}\mathbf{w^Tw}+const</script><p>通过这个式子，我们知道所谓的正则化从贝叶斯角度来解释就是对参数做假设先验分布为均值为0的高斯分布。</p><p>对于给定的测试样本X，贝叶斯线性回归可通过边缘化模型权重，即按照其后验积分得到测试结果$f_<em> = f(x_</em>)$的概率分布</p><script type="math/tex; mode=display">p(f_*|\mathbf{X,y.X_*},\delta_n^2) = \int p(f_*|\mathbf{X_*,w},\delta_n^2)p(\mathbf{w|X,y})dw = N（f_*|\mathbf{m_N^T\phi(X_*)},\delta_N^2(X)） \\  \\  \delta^2_N(x) = \delta^2 + \Phi^T S_N \Phi</script><p>方差解释了一个现象，预测值的分布情况受噪声和参数分布的双重影响，<strong>但是随着样本的增多，参数分布带来的影响逐渐趋于0.</strong></p><script type="math/tex; mode=display">f(x_*) = \mathbf{m_N^T}\phi(X_*) = \frac{1}{\delta^2} \phi(x)^TS_N \Phi^T \mathbf{y} = \sum_{n=1}^N \frac{1}{\delta^2}\phi(x)^TS_N\phi(x_n)t_n</script><p>定义核函数</p><script type="math/tex; mode=display">k(x,x') = \frac{1}{\delta^2}\phi(x)^TS_N\phi(x')</script><p>当定义的核函数为一个线性核的时候</p><script type="math/tex; mode=display">k(x,x') = \alpha \phi(x)^T\phi(x')</script><p>上式可改写成</p><script type="math/tex; mode=display">p(f_*|\mathbf{X,yX_*},\delta^2) = N(f_*|\bar{f_*},cov(f_*))\\\bar{f_*} = k(X_*,X)(K+\delta^2I)^{-1}\mathbf{y}\\cov(f_*) = k(X_*,X_*)+\delta^2 -K(X_*,X)(K+\delta^2I)^{-1}k(X,X_*)</script><p>无论哪个版本的核，我们都可以看到，所谓的预测结果都是相同的形式</p><script type="math/tex; mode=display">f_* = \sum_{n=1}^N a·k(x_*,x)</script><p>$a$是常数。</p><h4 id="表示定理"><a href="#表示定理" class="headerlink" title="表示定理"></a>表示定理</h4><p>事实上存在这样一个核<strong>表示定理</strong>：</p><p>令$\\H$为核函数$k$对应的再生希尔伯特空间，$||h||_{\\H}$表示$\H$中关于h的范数，对于任意单调递增函数$\Omega:[0,\infty]\rarr {\\R}$和任意非负损失函数$l:{\\R}^m\rarr[0,\infty]$优化问题</p><script type="math/tex; mode=display">min_{h\in {\\H}} F(h) = \Omega(||h||_{\\H})+l(h(x_1),h(x_2),...,h(x_m))</script><p>的解总可以写成</p><script type="math/tex; mode=display">h^*(x) = \sum_{i=1}^ma_i k(x,x_i)</script><p>表示定理对于损失函数没有限制，对正则化项$\Omega$仅要求单调递增，甚至不要求$\Omega$是凸函数，意味着对于一般的损失函数和正则化项，优化问题的最优解都可以表示为核函数的线性组合。</p><h4 id="从函数空间推高斯过程"><a href="#从函数空间推高斯过程" class="headerlink" title="从函数空间推高斯过程"></a>从函数空间推高斯过程</h4><p>假设回归方程如下，注意这里已经不再涉及参数空间，所以形式上已经没有了w变量</p><script type="math/tex; mode=display">t_n = y_n +\epsilon</script><p>这里应用高斯过程的假设，可以把$y_n = y(x_n)$看成是一个随机变量。$\epsilon$服从均值为0，方差为$\beta^{-1}$,有</p><script type="math/tex; mode=display">p(t_n|y_n,\epsilon) = N(t_n|y_n,\beta^{-1})</script><p>由于噪声独立与样本点，因此考虑目标值$\mathbf{t} = \{t_1,t_2,,…,t_n\}$,和$\mathbf{y} = \{y_n,y_2,…,y_n\}$有</p><script type="math/tex; mode=display">p(\mathbf{t|y}) = N(\mathbf{t|y},\beta^{-1}I)</script><p>由高斯过程假设，</p><script type="math/tex; mode=display">p(\mathbf{y}) = p(t_1,t_2,...,t_n) = N(\mathbf{y}|0,K)</script><p>我们的目标是求得边缘分布$p(\mathbf{t})$</p><script type="math/tex; mode=display">p(\mathbf{t}) = \int p(\mathbf{t|y})p(\mathbf{y})d\mathbf{y} = N(\mathbf{t}|0,C)</script><p>这里的C的元素如下</p><script type="math/tex; mode=display">C(x_N,x_m) = k(x_n,x_m)+\beta^{-1}\delta_{nm}</script><p>可知，p(t)的分布受到p(y)和噪声的影响，这和上面的结论（预测值的分布情况受噪声和参数分布的双重影响）相似.</p><p>由高斯过程假设，对于测试样本有</p><script type="math/tex; mode=display">f_* \sim N(0,k(X_*,K_*)</script><p>那么联合分布</p><script type="math/tex; mode=display">p(\mathbf{t_{N+1}}) = [\begin{matrix}\mathbf{t}\\f_*\end{matrix}] \sim N(0,[\begin{matrix}k(X_N,X_N)+\beta^{-1}\delta_{nm}&k(X_N,X_*)\\k(X_*,X_N)& k(X_*,X_*)+\beta^{-1}\end{matrix}])</script><p>由边缘高斯分布的性质，可以由上面的联合分布，直接求得条件分布$p(f_*|\mathbf{t]})$.</p><script type="math/tex; mode=display">p(f_*|\mathbf{t}) \sim N(\mathbf{k^TC_N^{-1}t},c - \mathbf{k^TC_N^{-1}k})</script><p>换一种形式表示</p><script type="math/tex; mode=display">\mathbf{m_{new}} =  \mathbf{k^TC_N^{-1}t} = k(X_*,X)(K(X_n,X_N)+\beta^{-1}\delta_{nm})^{-1}t \\\mathbf{v_{new}} = c - \mathbf{k^TC_N^{-1}k} =k(X_*,X_*)+\beta^{-1} - k(X_*,X)(K(X_n,X_N)+\beta^{-1})K(X,X_*)</script><p>可见，和上面从参数空间推导的高斯过程结果一致。所以有人说，一般的线性回归是高斯过程的一种特例，它使用的核函数是线性核。</p><p>值得注意的是在GPR过程中，常使用的一种核函数是exponential of a quadratic form,</p><script type="math/tex; mode=display">k(x_n,x_m) = \theta_0 exp\{-\frac{\theta_1}{2}||x_n-x_m||^2\}+\theta_2+\theta_3x_n^Tx_m</script><h3 id="自动关联确定-Automatic-relevance-determination-ARD"><a href="#自动关联确定-Automatic-relevance-determination-ARD" class="headerlink" title="自动关联确定(Automatic relevance determination, ARD)"></a>自动关联确定(Automatic relevance determination, ARD)</h3><p>利用高斯过程可以做这样一件事儿，确定特征向量个元素与target之间的关联性大小。关联性越大，参数值越大，关联性越小，值越小。</p><p>具体原理也不难。假设我们采取这样的核函数</p><script type="math/tex; mode=display">k(x_n,x_m) = \theta_0 exp\{-\frac{1}{2}\sum_{i=1}^D\eta_i(x_{ni}-x_{mi})^2\}+\theta_2+\theta_3x_n^Tx_m</script><p>参数$\eta_i$反应了各特征元素与target之间的关联性。通过对$p(\mathbf{t|\eta})$进行最大似然估计，可以估计出参数向量的值。</p><script type="math/tex; mode=display">p(\mathbf{t}) = \int p(\mathbf{t|y})p(\mathbf{y})d\mathbf{y} = N(\mathbf{t}|0,C) \\ln p(t|θ) = -\frac{1}{2}ln|C_N| - \frac{1}{2}\mathbf{t^TC^{-1}_Nt}-\frac{N}{2}ln(2\pi)</script><p>这里的关联性指的是该特征对拟合target的贡献大小。由于核函数反应的是随机变量$y(x)$方差的变化，而核函数是关于x的函数，当我们对各特征赋予权重求表示随机变量的方差的 时候，权重的大小可以近似的表明该单一特征对随机变量$y(x)$方差的影响。</p><p>总结为一句，在高斯过程中我们可以通过ARD的策略确定特征向量中每个特征与target的关联程度，对于关联程度小的特征，我们可以抛弃。作用上类似于LDA降维。</p><h4 id="使用laplace近似来近似后验分布-p-w-t"><a href="#使用laplace近似来近似后验分布-p-w-t" class="headerlink" title="使用laplace近似来近似后验分布$p(w|t)$"></a>使用laplace近似来近似后验分布$p(w|t)$</h4><p>先弄清楚一个问题，为什么要使用laplace近似？</p><p>我们知道，$t = y = \delta(w^Tx)$，对于这样一个决策函数，参数的后验分布并不是高斯分布，因为引入了sigmod函数。但是我们希望得到一个高斯形式的参数后验分布，所以采用laplace近似策略将真实的参数后验分布近似为一个高斯分布。</p><p>具体近似流程</p><script type="math/tex; mode=display">p(\mathbf{w|t})\propto p(\mathbf{w})p(\mathbf{t|w})</script><p>由于真实的后验分布与似然函数与先验分布成正比，所以在实际使用时我们一般直接使用似然函数与先验分布的乘积。</p><script type="math/tex; mode=display">ln p(\mathbf{w|t}) = -\frac{1}{2}\mathbf{(w-m_0)S_0^{-1}(w-m_0)}+\sum_{n=1}^N\{t_nlny_n+(1-t_n)ln(1-y_n)\}+const</script><p>这里$y_n = \delta(w^T\phi_n)$</p><p>使用最大后验估计（MAP）可以通过上述的式子求出$\mathbf{w_{MAP}}$,求解的方法是求解上述对数似然的一阶导。根据laplace近似的原理，我们需要找到一个该最大后验分布的极值$\mathbf{W_{MAP}}$,常使用的方法是牛顿法。</p><script type="math/tex; mode=display">S_N = -\nabla\nabla lnp(\mathbf{w|t})  = \mathbf{S_0^{-1}} +\sum_{n=1}^Ny_n(1-y_n)\phi_n\phi_n^T</script><p>近似函数</p><script type="math/tex; mode=display">q(w) = N(\mathbf{w|w_{MAP},S_N})</script><h3 id="高斯过程用于分类"><a href="#高斯过程用于分类" class="headerlink" title="高斯过程用于分类"></a>高斯过程用于分类</h3><p>高斯过程可以用于分类。由于高斯过程的输出是整个坐标轴，因此同样需要一个激活函数将其映射到（0，1）范围内，常见的激活函数就是前面使用的sigmod函数。</p><script type="math/tex; mode=display">p(t|a) = \sigma(a)^t(1-\sigma(a))^{1-t}</script><p>高斯过程用于分类，假设随机变量$a（X）$服从高斯过程。假设是</p><script type="math/tex; mode=display">p(a_{N+1}) \sim N(a_{N+1}|0,C_{N+1})  \\C(x_n,x_m) = k(x_n,x_m)+v\delta_{nm}</script><p>目标是$p(t_{N+1}|\mathbf{t_N})$</p><script type="math/tex; mode=display">p(t_{N+1}=1|\mathbf{t_N}) = \int p(t_{N+1} = 1 |a_{N+1})p(a_{N+1}|\mathbf{t_N}) da_{N+1}</script><p>对于$p(t_{N+1}=1|a_{N+1})$有</p><script type="math/tex; mode=display">p(t_{N+1}=1|a_{N+1}) = \sigma(a_{N+1})</script><p>对于第二项</p><script type="math/tex; mode=display">p(a_{N+1}|\mathbf{t_N}) = \int p(a_{N+1}|\mathbf{a_N})p(\mathbf{a_N|t_N})d\mathbf{a_{N}}</script><p>利用高斯过程的结果</p><p>简单回顾一下高斯过程的结果,高斯过程的目标是$p(t_{N+1}|\mathbf{t_N)}$,这里有$p(a_{N+1}|\mathbf{a_N})$,而$t_n = a_n+\epsilon$</p><p>两个变量都服从高斯分布，相差一个噪声，当无燥情况下，两者是相等的。也就是说，当无燥情况下，两者的分布是一致的，所以这里可以使用高斯过程的结果。</p><script type="math/tex; mode=display">p(a_{N+1}|\mathbf{a_N}) \sim N(\mathbf{a_{N+1}|k^TC_N^{-1}t},c - \mathbf{k^TC_N^{-1}k})</script><p>对于第二项采用laplace近似</p><script type="math/tex; mode=display">p(\mathbf{t_N|a_N}) = \prod_{n=1}^N \sigma(a_n)^{t_n}(1-\sigma(a_n))^{1-t_n} = \prod_{n=1}^N e ^{a_nt_n}\sigma(-a_n)</script><p>对后验分布采用laplace近似</p><script type="math/tex; mode=display">\Phi(\mathbf{t_N|a_N}) = lnp(\mathbf{a_N})+lnp(\mathbf{t_N|a_N})</script><p>利用牛顿法求得它的极值点$a_N^*$ ,二阶海塞矩阵的形式为</p><script type="math/tex; mode=display">\mathbf{H} = -\nabla\nabla \Phi(\mathbf{a_N}) = \mathbf{W_n+C_N^{-1}}</script><p>可得</p><script type="math/tex; mode=display">q(\mathbf{a_N}) = N(\mathbf{a_N|a_N^*,H^{-1}})</script><p>逆推回去有</p><script type="math/tex; mode=display">E[a_{N+1}|\mathbf{t_N}] =  \mathbf{k^T(t_N-\sigma_N)}\\var[a_{N+1}|\mathbf{t_N}] =  c- \mathbf{k^T(W_n^{-1}+C_n)^{-1}k}</script><p>最后将上式代入边缘分布积分方程，可得最终结果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;如果不懂高斯过程的话，就假设$f(x) = w^Tx$这个函数为一个变量，而这个变量服从一维高斯分布。换句话理解，假设w先验服从一个高斯分布，那么给定一个确定值x，$w^Tx$是一个服从一维高斯分布的变量。所以说，高斯过程的假设与参数先验分布的假设是等价的。&lt;/p&gt;
&lt;p&gt;
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/"/>
    
      <category term="概率统计模型" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B/"/>
    
    
      <category term="ML" scheme="https://qingfengbangzuo.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>强化学习一些笔记</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-06-11T16:00:00.000Z</published>
    <updated>2020-06-22T12:16:44.189Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Incremental-Implementation"><a href="#Incremental-Implementation" class="headerlink" title="Incremental Implementation"></a>Incremental Implementation</h3><script type="math/tex; mode=display">Q_{n+1} = Q_n + \frac{1}{N(A)}[R_n - Q_n]</script><p>注意step_size $N(A)$，它随着时间步的累计而线性增长，但是通常，最近的奖赏相比过去很久的奖赏更有说服力，因此，我们希望给最近发生的奖赏一个稍大的权重。解决办法是将$N(A)$设置为固定值。</p><script type="math/tex; mode=display">\begin{align*}Q_{n+1}& = Q_n + \alpha[R_n - Q_n]\\ &=\alpha R_n +(1-\alpha)Q_n \\&=\alpha R_n +(1-\alpha)[\alpha R_{n-1}+(1-\alpha)Q_{n-1 }] \\&=\alpha R_n+(1-\alpha)\alpha R_{n-1}+(1-\alpha)^2\alpha R_{n-2}+...+(1-\alpha)^{n-1}\alpha R_1+(1-\alpha)^n Q_1 \\&=(1-\alpha)^n Q_1+\sum_{i=1}^n \alpha(1-\alpha)^{n-i}R_i\end{align*}</script><p>可以看到，当设置步长为一个固定值的时候，我们实现了如期的效果。原文称之为:<em>exponential<br>recency-weighted average.</em></p><p>对于采样平均策略中$a = N(A)$,由大数定理可知必会依概率1收敛。</p><script type="math/tex; mode=display">\sum_{n=1}^{\infty} a_n(a) = \infty \\\sum_{n=1}^{\infty}a_n^2(a) < \infty</script><p>第一个条件保证了步长足够大使得最终克服初始值或随机影响而收敛。第二个条件保证了最终，步长变得足够小从而保证收敛。</p><p>固定值$a$是不满足上述两个条件的，表明预测值不会完全收敛但是会继续随着最近接收到的reward而变化，这种属性适合nonstaionary 环境或者nonstationart问题。并且，满足上述条件的步长$a$需要调参来达到合适的收敛率，这在理论工作中比较常用，但是在实际问题中并不常用。</p><h3 id="optimistic-initial-values"><a href="#optimistic-initial-values" class="headerlink" title="optimistic initial values"></a>optimistic initial values</h3><p>书中提到了三种简单的method，一种是sample-average，一种是exponential recency-weighted average,最后一种是这块要介绍的optimistic initial values。</p><p>这种方案是聚焦在初始值上，因为大多数stationary问题都需要依赖初始的Q值，被称为偏差，如上一块公式所示，这个偏差随着时间并不会消失（虽然随着时间在减小）。显然我们不满足于将初始值设为0，乐观初始值是指将初始值设为 一个比奖赏大的数，比如+5，这样，因为所有的奖赏都小于这个预设值，因此，一轮更新过后，agent会竭尽所能的去探索。因此，它的最优率相对于sample-average收敛较快。</p><h3 id="Upper-Confidence-Bound-Action-Selection"><a href="#Upper-Confidence-Bound-Action-Selection" class="headerlink" title="Upper-Confidence-Bound Action Selection"></a>Upper-Confidence-Bound Action Selection</h3><script type="math/tex; mode=display">A_t = argmax_a[Q_t(a)+c\sqrt{\frac{lnt}{N_t(a)}}]</script><p>c是调节参数，$lnt$表示随着时间增大，不确定性的增长变缓。$N_t(a)$表示t之前动作a被选择的次数。整个公式的作用是随着时间的进行，那些Q值小的动作和那些被选过好多次的动作再次被选中的频率会下降，而那些未被选择过得动作则有越来越大的机会被选中。最终所有的动作都会被选中，实验效果表明，采用UCB的效果较$\epsilon$-greedy略好。</p><h3 id="贝尔曼最优方程"><a href="#贝尔曼最优方程" class="headerlink" title="贝尔曼最优方程"></a>贝尔曼最优方程</h3><script type="math/tex; mode=display">V_*(s) = max_a E[R_{t+1}+\gamma V_*(S_{t+1})|S_t = s,A_t =a]\\=max_a \sum_{s',r}p(s',r|s,a)[r+\gamma V_*(s')]\\q_*(s,a) = E[R_{t+1}+\gamma max_{a'}q_*(S_{t+1},a')|S_t=s,A_t=a]\\= \sum_{s',r}p(s',r|s,a)[r+\gamma max_{a'}q_*(s',a')]</script><p>贝尔曼最优方程有这样一个特性，即V（s） = $max_a$q(s,a),即它的状态值不断靠近当前状态下的最大动作值。</p><h3 id="policy-evaluation"><a href="#policy-evaluation" class="headerlink" title="policy evaluation"></a>policy evaluation</h3><script type="math/tex; mode=display">V_\pi(s)= \sum_a\pi(a|s)\sum_{s',r} p(s',r|s,a)[r+\gamma V_\pi(s')]</script><p>给定一确定策略，通过Policy evaluation可以得到该策略下的值函数。（多次迭代，最终收敛于一个个确定值）</p><h3 id="policy-Increament"><a href="#policy-Increament" class="headerlink" title="policy Increament"></a>policy Increament</h3><script type="math/tex; mode=display">q_\pi (s,\pi'(s))\geq v_\pi(s)</script><p>对于所有的s满足上式，则$\pi’$优于$\pi$。</p><p>Greedy策略满足上述要求</p><script type="math/tex; mode=display">\pi'(s ) = argmax_a q_\pi(s,a)=argmax_a\sum_{s',r}p(s',r|s,a)[r+\gamma v_\pi(s')]</script><script type="math/tex; mode=display">v_{\pi'}(s) = max_a E[R_{t+1}+\gamma v_{\pi'}(S_{t+1})|S_t =s,A_t =a]\\= max_a \sum_{s',r}p(s',r|s,a)[r+\gamma v_{\pi'}(s')]</script><h3 id="policy-Iteration"><a href="#policy-Iteration" class="headerlink" title="policy Iteration"></a>policy Iteration</h3><script type="math/tex; mode=display">\pi_0 \rarr v_{\pi_0}\rarr\pi_1\rarr v_{\pi_1} \rarr \pi_2\rarr...\rarr\pi_*\rarr  v_{*}</script><p>给定一个策略，根据policy evaluation可以计算当前策略下的值函数，然后对当前策略进行提升，循环往复，最终收敛到最优策略和最优值函数。</p><h3 id="value-Iteration"><a href="#value-Iteration" class="headerlink" title="value Iteration"></a>value Iteration</h3><p>one update of each state is called value iteration.相比于策略迭代，需要迭代到该策略下的最优value值。</p><p>利用贝尔曼最优方程：</p><script type="math/tex; mode=display">V_{k+1}(s) = max_a E[R_{t+1}+\gamma V_k(S_{t+1})|S_t = s,A_t =a]\\=max_a \sum_{s',r}p(s',r|s,a)[r+\gamma V_k(s')]\\</script><p>对于任意$v_0$，序列{$v_k$}在相同的条件下能够收敛到$v_*$。</p><p>如何终止呢？</p><p>当值函数变化被压缩在一个阈值$\theta$内时，就可以强行进行终止了。</p><p>Value Iteration加快了收敛速度，因为不需要进行完整的evaluation,它是通过使用贝尔曼最优方程的特性，使得V(s)不断地靠地$max_a$ q(s,a)</p><h3 id="Asynchronous-Dynamic-Programming"><a href="#Asynchronous-Dynamic-Programming" class="headerlink" title="Asynchronous Dynamic Programming"></a>Asynchronous Dynamic Programming</h3><p>这里的非同步动态规划是指取消了更新轮数的限制，即并非在一轮更新中更新所有的状态，而是仅仅针对某些或者某个状态进行更新，这样就会出现，某些状态可能更新了n多次，但是某些状态仅仅只更新了一两次。</p><p>policy evaluation 、value Iteration、asynchronous dynamic programming三者的区别：</p><p>policy evaluation和value Iterationd的区别在于前者更新知道达到当前策略下的最优v值，而后者通过更新公式仅仅更新一次（轮）。非同步动态规划与前两者的区别是它没有更新轮次的概念，可能仅仅与最优行为有关，那些与最优行为无关的状态可能不会得到太大的关注。它的更新粒度最小。</p><h3 id="MOnte-carlo-methord"><a href="#MOnte-carlo-methord" class="headerlink" title="MOnte carlo methord"></a>MOnte carlo methord</h3><p>较DP优势：</p><p>1、没有用到bootstrap,且每个状态的estimate都是独立的，因为在估计状态值的时候没有用到其他状态值。</p><p>2、估计单个状态值的计算代价与状态的数量无关。只与采样有关。</p><p>3、我们可以从任何状态起开始采样，且状态值估计不受这个影响。</p><p>蒙特卡罗采样只与experience有关，这个experience可以是实际经历也可以是virtual experience，分为every-visit average 和 first-visit average。这两种平均都能收敛到$v_\pi$，前提是episodes的数量趋近于无穷。</p><p>在环境信息已知的情况下，通过v值就可以确定最优策略，但是在蒙特卡罗采样策略下，只通过v值确定最优策略是不充分的，我们还需要确定$q_\pi（s,a）$。</p><p>在蒙特卡罗采样策略下，因为v值和q值都是通过从experience中采样得到的，但是在stationary策略下，每个状态下的动作是确定的，也就是说experience中可能只有某个状态下的某个动作（或状态），其他动作不会出现，而他们相应的q值因为无法采样而为0.这会影响收敛，因为收敛需要遍历每个状态和动作。</p><p>解决这个问题有两种方法，一种是对初始状态进行随机化，每个状态以某个概率随机出现，这样，随着episodes数量趋于无穷，状态会得到遍历，最终会收敛，这被称作<strong>Exloration Starting</strong>。但是这种方法在实际场景中不能保证收敛性，也不实用。另一种是在每个状态下，给予其他动作以一定的出现概率。这样就会使得策略变成non-stationary。但是效果较好。</p><p>目前讨论的蒙特卡罗策略有两个假设。</p><p>One was that the episodes have exploring starts, and the other was that policy evaluation could be done with an infinite number of episodes.</p><p>下面的内容介绍了去除这两个假设的方法。</p><p>去掉假设2是相当对容易的，有两种思路，一种是在evaluation中保证足够多的迭代次数。另一种是引入Value Iteration的思想，不需要得到准确的$v_\pi$值，换成蒙特卡罗采样也就是，在策略$\pi$下，不需要大量采样，只需要一次采样，即一个episode（蒙特卡洛的采样数量对应了DP的更新迭代次数，因为DP下，更新次数越多，越接近$V_\pi$，但在蒙特卡罗策略下采样次数决定了靠近$V_\pi$的距离）。这样也就是变向的将evaluation和improvement交替进行，即下面Monte carlo ES所示。</p><h3 id="Monte-carlo-ES"><a href="#Monte-carlo-ES" class="headerlink" title="Monte carlo ES"></a>Monte carlo ES</h3><p>这个算法的特殊之处在于它将evaluation过程和improvement过程交替进行，这样依然会收敛于最优策略，但是似乎还未被证明。</p><p>可以使用Incremental Implementation来替代上述中维护return列表的做法。</p><p>而解决假设1的也有两种方案，即on-policy和off-policy。</p><p>终于找到了on-policy和off-policy的区别。这两种方法被用来解决Exploration Staring问题。</p><p>On-policy methods attempt to evaluate or improve the policy that is used to make decisions, whereas o↵-policy methods evaluate or improve a policy di↵erent from that used to generate the data.</p><h3 id="On-policy-and-Off-policy"><a href="#On-policy-and-Off-policy" class="headerlink" title="On-policy and Off-policy"></a>On-policy and Off-policy</h3><p>在继续介绍on-policy和off-policy之前，先给出两个概念：</p><p>所谓的off-policy是指使用生成数据的策略和要学习的策略是不同的两个策略，前者被称为<strong>behaivior policy</strong>后者被称为<strong>target policy</strong>，这两个策略是不同的，也就是说我们用来学习数据是通过其他的策略产生的，或者说这个数据本身就是一些经验数据，但是我们需要从这些经验数据中学习我们的最优策略。所谓的学习策略就是更新策略。on-policy就是将生成数据的策略与要学习的策略为同一策略，是off-policy的一种特例。</p><p>On - policy策略一般是soft的，即$\pi(a|s)&gt;0$，也就是每个动作的选择概率均大于0，将贪婪策略soft化，就是常见的$\epsilon-greedy$策略。</p><p>在off-policy control中，生成数据的策略通常也使用$\epsilon-greedy$ policy，因为behavior-policy需要是exporation policy。而学习策略一般是greedy policy。</p><p>注：off-policy的一个优点</p><p>‘’An advantage of this separation is that the target policy may be deterministic (e.g., greedy), while   the behavior policy can continue to sample all possible actions.‘’</p><p>由于我们使用的数据是经过behavior policy下产生的，所以我们得到的v值是behavior policy策略下的，而不是我们的学习策略下的v值。由于我们的最终目标是不断改善我们的target policy，得到最优v值和最优策略，因此我们需要得到的是target policy下的v值，这就产生了一个问题，如何转换？</p><h3 id="Importance-Sampling"><a href="#Importance-Sampling" class="headerlink" title="Importance Sampling"></a>Importance Sampling</h3><p>重要性采样用来解决上述问题。</p><p>假设有N个episodes，每个episodes在不同的策略下都对应这一个出现概率，计算方法如下：</p><script type="math/tex; mode=display">Pr = \prod_{k=t}^{T-1}\pi(A_k|S_k)p(S_{k+1}|S_k,A_k)</script><p>定义重要性采样率（importance-sampling ratio）</p><script type="math/tex; mode=display">p_{t:T-1} = \frac{\prod_{k=t}^{T-1}\pi(A_k|S_k)p(S_{k+1}|S_k,A_k)}{\prod_{k=t}^{T-1}b(A_k|S_k)p(S_{k+1}|S_k,A_k)}=\prod_{k=t}^{T-1}\frac{\pi(A_k|S_k)}{b(A_k|S_k)}</script><p>通过转换公式</p><script type="math/tex; mode=display">E[p_{t:T-1}G_t|S_t=s] = v_\pi(s)</script><p>以上就是重要性采样的思想。</p><p>那么计算$v_\pi（s）$有两种metrics（“初访” 情况下）。分别是</p><p>ordinary importance sample :</p><script type="math/tex; mode=display">V(s) = \frac{\sum_{t\in J(s)}p_{t:T-1}G_t}{|J(s)|}</script><p>the set of all time steps in which state s is visited, denoted J(s).</p><p>weighted importance sampling：</p><script type="math/tex; mode=display">V(s) = \frac{\sum_{t\in J(s)}p_{t:T-1}G_t}{\sum_{t\in J(s)}p_{t:T-1}}</script><p>可见weighted importance sampling对V（s）进行了方差处理，而ordinary importance sampling没有，实际上ordinary 的方差可以是无穷大的，但是它的biase很小，且随着samples数量趋近于无穷，它的方差也会随之下降，但是这是一个缓慢的过程，在例子中可以看到，millions steps后，它并没有准确收敛到1。而weighted效果要好一点，它始终是围绕着均值上下波动的，但是该均值是有偏的，但是同样会随着samples的增多而收敛到正确的均值，也就是最优v值。</p><p>在实际应用中，“每访”的效果更佳，但是”每访“情况下，ordinary和weighted都是有偏的，但是都会随着samples的增加而趋于正确的均值。</p><p>注：infinite variance</p><p>当MDP中出现了闭环，那么会导致无限方差的情况，这种情况下，随着sample增加到很大，可能也不能很好的收敛到正确值，具体例子看P107页例。</p><h3 id="Incremental-Implementation-on-Monte-carlo-sampling"><a href="#Incremental-Implementation-on-Monte-carlo-sampling" class="headerlink" title="Incremental Implementation on Monte carlo sampling"></a>Incremental Implementation on Monte carlo sampling</h3><p>根据前面提到的Incremental Implementation 方法来用于有重要性采样的Monte carlo问题中。</p><p>对于ordinary importance sampling，直接将采样公式变换成Incremental Implementation形式就行。</p><p>对于weighted 采样，需要做一点改变</p><script type="math/tex; mode=display">V_{n+1} = V_n + \frac{W_n}{C_n}[G_n -V_n]\\C_{n+1} = C_n + W_{n+1}</script><p>这个是”每访”下的算法，注意算法中的C和Q是两个列表，也就是说C和Q各维持了一个存放不同（S_t,A_t）的列表，每一轮episode来临时，都会更新列表中相应的状态动作对值，对于“初访”情形，需要设置一个条件来访问：</p><p>‘’’’’’——————————————————————————————</p><p>​    $G\larr\gamma G+R_{t+1}$</p><p>​        unless the Pair ($S_t,A_t$) appear in $S_0,A_0,S_1,A_1,…S_{t-1},A_{t-1}$</p><p>​            $C(S_t,A_t)\larr C(S_t,A_t)+W$</p><p>​            $Q(S_t,A_t)\larr Q(S_t,A_t)+ \frac{W}{C(S_t,A_t)}[G-Q(S_t,A_t)]$</p><p>​    $W \larr W\frac{\pi(A_t|S_t)}{b(A_t|S_t)}$</p><p>‘’’————————————————————————————————</p><p>最后一行，由于使用的是greedy策略，所以$\pi(a|s)= 1或0$,注意倒数第二句，如果$A_t \neq\pi(S_t)$程序就会退出，此时$\pi(A_t|S_t) = 0 $.</p><p><strong>当episode中大部分动作是non-greedy，尤其靠前部分是Non-greedy的时候，这个算法收敛将变得十分缓慢。</strong></p><p>出现这样的现象是直观的，因为这个算法倒数第二行设置了退出条件，由于算法是从尾部遍历到头部，所以当尾部出现了non-greedy的动作，那么就会退出内循环，开始下一个episode，这样就会造成该non-greedy动作之前的所有episode报废。</p><h3 id="Timporal-Difference-Learning"><a href="#Timporal-Difference-Learning" class="headerlink" title="Timporal-Difference Learning"></a>Timporal-Difference Learning</h3><p>TD是DP和Monte carlo采样的结合，因为在更新过程中，它既对$\pi$进行了采样，又使用了bootstrap，这里的bootstrap和DP中的不同，在DP中使用的expected return 和expected value（即根据分布得到的return 和value均值），而TD在更新时，需要根据一步采样，得到$R_{t+1}$和$S’$，使用$R_{t+1}$+$\gamma V(S’)$来更新，这里的$R_{t+1}$是采样值，这里的$V（S’）$是估计值。</p><p>无论是Mento carlo 还是TD，它们都是通过”error”来更新的，并且它们之间存在关系如下：</p><script type="math/tex; mode=display">G_t - V(S_t) = R_{t+1} + \gamma G_{t+1} - V（S_t）-\gamma V(S_{t+1})\\=\delta_t +\gamma (G_{t+1}-V(S_{t+1}))\\=\delta_t + \gamma \delta_{t+1}+ \gamma^2（G_{t+2}-V（S_{t+2}))\\=\delta_t+\gamma\delta_{t+1}+\gamma^2\delta_{t+2}+...+\gamma^{T-t-1}\delta_{T-1}+\gamma^{T-1}(G_T-V(S_T))\\=\delta_t + \gamma\delta_{t+1}+\gamma^2\delta_{t+2}+...+\gamma^{T-t-1}\delta_{T-1}+\gamma^{T-t}(0-0)\\=\sum_{k=t}^{T-1}\gamma^{k-t}\delta_k</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Incremental-Implementation&quot;&gt;&lt;a href=&quot;#Incremental-Implementation&quot; class=&quot;headerlink&quot; title=&quot;Incremental Implementation&quot;&gt;&lt;/a&gt;Incremen
      
    
    </summary>
    
    
      <category term="Reinforcement Learning" scheme="https://qingfengbangzuo.github.io/categories/Reinforcement-Learning/"/>
    
    
      <category term="RL" scheme="https://qingfengbangzuo.github.io/tags/RL/"/>
    
  </entry>
  
  <entry>
    <title>决策树</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A0%91%E7%B1%BB%E6%A8%A1%E5%9E%8B/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A0%91%E7%B1%BB%E6%A8%A1%E5%9E%8B/%E5%86%B3%E7%AD%96%E6%A0%91/</id>
    <published>2020-06-11T16:00:00.000Z</published>
    <updated>2020-06-12T10:53:46.127Z</updated>
    
    <content type="html"><![CDATA[<p>决策树</p><h3 id="信息熵的定义"><a href="#信息熵的定义" class="headerlink" title="信息熵的定义"></a>信息熵的定义</h3><ul><li><p>下面是一位大神从编码的角度考虑信息熵的定义</p><p>假如有ABCD四种答案，且每一种答案的概率均为四分之一。那么编码这个答案的所需要的位数为2（基于二进制编码，二进制编码会带来诸多好处）。用数学语言描述就是需要</p><script type="math/tex; mode=display">n = log_2N</script><p>N是事件不同情况的取值,这里是四。下面做一个变换，将对数的变量改为概率：</p><script type="math/tex; mode=display">log_2（4）=log_2(\frac{1}{1/4})=-log_2(1/4) = -log_2(p)</script><p>这里进行了泛化，但在逻辑上并不严谨，因为假设是所有情况出现的概率相等。</p><p>信息熵的定义： </p></li></ul><script type="math/tex; mode=display">H(X) = E[-log(P(X))]= - \sum_{a\in D}P(X)log_2(P(X))</script><p>​    将上面问题的答案带入后会发现$H(X)$和$n$是相等的。所以熵又叫做平均编码长度。</p><p>​    将假设推广之后就是信息熵的正式定义了。但上述的推导是不严谨的，仅限于有助于理解。</p><p>​    当答案出现的的概率不相等时，比如</p><script type="math/tex; mode=display">P(A) = 1/4\quad P(B)=1/8\quad P(C)=1/,2\quad P(D)=1/8</script><p>​    那么编码A,B,C,D所需要的位数会变为：2, 3，1, 3</p><p>​    那么平均编码长度为（按照熵的定义） </p><script type="math/tex; mode=display">H(X) = \frac{1}{4}\times 2+\frac{1}{8}\times3+\frac{1}{2}\times1+\frac{1}{8}\times3 = 1.75</script><p>​    这就是压缩编码。换一个角度来考虑，事件的不确定性降低（C出现的概率最大），对应的熵也    会跟着降低。</p><hr><p>YJango视屏中对熵的又一个解释：</p><ul><li><p>当一个事件 有多种情况时，这件事对观察者来讲具体是某种情况的不确定性叫做熵。</p></li><li><p>而能够消除观察这对这件事情不确定性的事物叫做信息。</p><ol><li>调整概率可以减小不确定性。</li><li>能够排除干扰</li><li>确定情况</li></ol></li></ul><p>信息是相对的，不同的信息对与不同的观察者来讲意义不同，如果小红知道会这道题，不管告不告诉小红正确答案，小红对这到题的熵都为0比特。小名不会这到题，那么小名对这道题的熵为2比特。</p><p>由于事件的不确定性是指数性的，而不是线性的（千克），因此不能用简单的除法，而要用对数，</p><p>参照物是2也就是底。如果事件发生的概率相等，也就是服从均匀分布，那么采用</p><script type="math/tex; mode=display">n = log_2N</script><p>就能计算熵，但是如果概率不相等时，怎么办呢，我们平均的思想来计算</p><script type="math/tex; mode=display">H(X) = E[-log(P(X))]= - \sum_{a\in D}P(X)log_2(P(X))</script><h3 id="Gini指数"><a href="#Gini指数" class="headerlink" title="Gini指数"></a>Gini指数</h3><p>基尼指数反应的也是事件的不确定性，只不过它是从抽样概率的角度来解释的：</p><script type="math/tex; mode=display">Gini（D） = \sum_{x=1}\sum_{y\ne x}P(X_i)P(X_y) = 1-\sum_{x=1}^{|Y|}p_x^2</script><p>基尼指数反应了从数据集中随机抽取两个样本，其类别标记不一致的概率。因此，基尼指数越小，则数据集D的纯度越高。</p><h2 id="ID3、C4-5、CART"><a href="#ID3、C4-5、CART" class="headerlink" title="ID3、C4.5、CART"></a>ID3、C4.5、CART</h2><p>ID3使用的是信息增益准则，即：</p><script type="math/tex; mode=display">a_*=argmax_{a\in A}Gain(D,a)\\Gain(D,a) = Ent(D) - \sum_{v=1}^V\frac{|D^v|}{|D|}Ent(D^v)</script><p>$D^v$是属性$a$上的第$v$个分支结果中包含了D中所有在属性$a$上取值为$a^v$的样本。直观上的理解就是未分支时的熵减去以某个属性为根节点分支后的熵。</p><p><strong>信息增益至少说明了两件事，一件是这个过程是个提取属性的过程，提取属性意味着总体事件取值的种类减少，事实也确实如此，每一次分支，我们都是相当于给定某一些属性变量的确定值的前提下计算熵的。所以总熵必定减小，因为引入了有效信息，这就是信息增益。另一件事是每个属性对于整体的熵贡献不同，属性多的熵贡献程度大，这十分符合我们的常识，我们常说的复杂刻画的就是变量取值太多而造成的熵巨大的情况。</strong></p><p><strong>那么使用信息增益来构建决策树的思想就很清晰了，我们本着一个原则“树的深度最小”，然后逐层熵减，直至熵为0未知，也就是系统中不存在不确定性。那么，为了迎合这个前提，我们减熵的过程就需要按照属性对熵的贡献程度来分支啦。</strong></p><p>ID3存在对多取值属性有偏好的问题，因此 C4.5弥补了这种不足。</p><p>C4.5采用增益率来作为分支决策：</p><script type="math/tex; mode=display">Gain_ratio(D,a) = \frac{Gain(D,a)}{IV(a)}\\其中 \quad IV(a) = -\sum_{v=1}^V\frac{|D^v|}{|D|}log_2 \frac{|D^v|}{|D|}</script><p>其中的$IV(a)$是节点自身的熵。</p><p>CART 是基于Gini指数来进行分支决策的一类决策树。它采用下面的准则来生成树</p><script type="math/tex; mode=display">Gini\_index(D,a) = \sum_{v=1}^V\frac{|D^v|}{|D|}Gini(D^v)</script><p>《统计学习原理》从概率角度给出了决策树的另一个解释。</p><p>决策树本质上是基于条件概率模型的算法。结社X为表示特征变量的随机变量，Y为表示类的随机变量，那么这个条件概率分布可以表示为$P(Y|X)$。X取值于给定划分下单元的集合，Y取值于类的集合，各叶子节点上的条件概率往往偏向与某一个类，即属于某一类的概率比较大。决策树分类时将该节点强行分到概率大的那一类去。那从这个角度来看，决策树的目的就是寻找一组有效的条件$(x_1,x_2,…x_n)$，使得$P(Y|(x_1,x_2,…x_n))$最大，那么如果新样本符合条件(x_1,x_2,…x_n），那么根据条件概率，我们就可以预测它的类别。</p><p>如果任由树形算法生长，那么最终会生成一个一个小单元，也就是叶子节点，每个叶子节点依据上述的的条件概率大小来判断样本的分类。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;决策树&lt;/p&gt;
&lt;h3 id=&quot;信息熵的定义&quot;&gt;&lt;a href=&quot;#信息熵的定义&quot; class=&quot;headerlink&quot; title=&quot;信息熵的定义&quot;&gt;&lt;/a&gt;信息熵的定义&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;下面是一位大神从编码的角度考虑信息熵的定义&lt;/p&gt;
&lt;p&gt;假如有AB
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/"/>
    
      <category term="树类算法" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="ML" scheme="https://qingfengbangzuo.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>降维算法与度量学习</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-06-11T16:00:00.000Z</published>
    <updated>2020-06-12T11:03:59.955Z</updated>
    
    <content type="html"><![CDATA[<ul><li><h3 id="KNN（K-nestest-Neighbor）"><a href="#KNN（K-nestest-Neighbor）" class="headerlink" title="KNN（K-nestest Neighbor）"></a>KNN（K-nestest Neighbor）</h3><p>KNN算法的思想十分简单，给定一个测试样本，基于某种距离度量找出训练集中与其最靠近的K个训练样本，然后基于这K个“邻居”的信息来进行预测。通常，在类任务中使用投票法，即选择这K个邻居的出现最多的类别标记作为预测结果。在回归任务中，选择平均法，即选择这个K个样本中出现的实值输出标记的平均值作为预测结果。还可以基于距离远近进行加权平均或投票处理，距离越近权重越大。</p></li></ul><p>  KNN学习有两个关键点，一个是K值的选择，另一个是距离的计算方式。</p><p>  不同的K值包含了不同的邻居，K值是一个距离，表示的是在这个距离内，有多少相邻样本，相邻样本的多少决定了该预测样本的预测结果，例如，K=1内有3个样本，一个正例，两个反例，那么预测样本的结果走向将偏向于反例，而K=1.5内有5个样本，3个正例，2个反例那么预测结果的走向又会被矫正过来，所以K值的选择是决定预测值走向的一个比较重要的参数。</p><p>  “如果选择较小的K值，就相当于用较小的邻域中的训练实例进行预测，”学习“的近似误差会减小，只有与输入实例较近的训练实例才会对预测的结果起作用，但缺点是学习的估计误差会增大，预测结果对邻近点非常敏感，如果邻近点的实例恰巧是噪声，预测就会出错，换句话说，k值的减小就意味这整体模型变得复杂，容易发生过拟合。“</p><p>  ”如果选择较大的K值，就相当于用较大邻域中的训练实例进行预测额，其有点是可以减小学习的估计误差，但缺点是学习的近似误差会增大，这时与输入实例较远的训练实例也会对预测器作用，使预测发生错误，K值的增大就意味着整体的模型变得简单。“</p><p>  一般选择用交叉验证来确定k的取值。</p><p>  不同的测距方式侧重的方面不同，但总体上都是反映数据间的相似程度，常见的测距方式有欧氏距离，曼哈顿距离等。</p><p>  西瓜书上给出了一个简单的 证明，结果显示KNN算法的错误率较贝叶斯最优分类器的结果有：</p><script type="math/tex; mode=display">  \begin{align}  P(err) &= 1- \sum_{\varepsilon\in Y}P(c|x)P(c|z)\\   &=1-\sum_{\varepsilon\in Y}P^2(c|x)\\   &\leq 1-P^2(c^*|x)\\   &=(1+P(c^*|x))(1-P(c^*|x))\\   &\leq 2(1-P(c^*|x))  \end{align}</script><p>  KNN三要素：距离度量，K值选择和分类决策规则。常用的距离度量是欧式距离以及更一般的$L_p$距离。K值越小模型越复杂，K值越大模型越简单。K值的选择反应了对近似误差与估计误差之间的权衡，通常由交叉验证选择最优的K，常用的分类决策规则是多数表决，对应于经验风险最小化（误分率最小等同于经验风险最小）。</p><h5 id="Kd树"><a href="#Kd树" class="headerlink" title="Kd树"></a>Kd树</h5><p>​    kd树是二叉树，是对K维数据空间的一个划分。构造kd树相当与不断的用垂直于坐标轴的超平面将k为空间切分，构成一系列的K维超巨型区域，kd树的每个节点对应一个k维超矩形区域。</p><p>​    <strong>构造kd树：</strong></p><p>输入：k维空间数据集$T={x_1,x_2,…,x_N}$</p><p>​        其中$x_i=(x_i^{(1)},x_i^{(2)},…x_i^{(k)})^T,i=1,2,…,N$</p><p>输出：kd树</p><p>开始：构造根节点，根节点对应于包含T的k维空间的超矩形区域。</p><p>​    选择$x^{(i)}$为坐标轴，以T中所有实例的$x^{(i)}$坐标的中位数为切分点，将根节点对应的超矩形区域切分为两个子区域，切分由通过切分点并与坐标轴$x^{(i)}$垂直的超平面实现。由根节点生成深度为1的左、右子节点，左子节点对应坐标$x^{(1)}$小于切分点的子区域，右子节点对应于坐标$x^{(1)}$大于切分点的子区域。将落在切分超平面上的实例点保存在根节点。</p><p>重复：对深度为j的节点，选择$x^{(l)}$为切分的坐标轴，$l=j(mod k)+1$,以该节点的区域中所有实例的$x^{(l)}$坐标的中位数为切分点，将该节点对应的超矩形区域切分为两个子区域，切分由通过切分点并与坐标轴$x^{(l)}$垂直的超平面实现。</p><p>​    由该节点生成深度为j+1的左、右子节点，左子节点对应坐标$x^{(l)}$小于切分点的子区域，右子节点对应的坐标$x^{(l)}$大于切分点的子区域。降落在切分超平面上的实例点保存在该节点。</p><p>​    知道两个子区域没有实例存在时停止，从而形成kd树的区域划分。</p><p><strong>搜索kd树</strong></p><p>输入：已构造的kd树，目标点x</p><p>输出：x的最近邻</p><p>（1）在kd树中找出包含目标点x的叶节点：从根节点出发，递归地向下访问kd树，若目标点x当前维的坐标小于切分点的坐标，则移动到左子节点，否则移动到右子节点，直到子节点为叶子节点为止。</p><p>（2）以此叶节点为“当前最近点”。</p><p>（3）递归地向上回退，在每个节点进行以下操作：</p><p>(a)如果该节点保存的实例点比当前最近点距离目标点近，则以该十里店为“当前最近点”。</p><p>(b)当前最近点一定存在于该节点一个子节点对应的区域，检查该子节点的父节点的另一个节点对应的区域是否有更近的点，具体地，检查另一子节点对应的区域是否与以目标点为球心，以目标点与“当前最近点”间的距离为半径的超球体相交。</p><p>​    如果相交，可能在另一个子节点对应的区域内存在距目标点更近的点，移动到另一个子节点，接着，递归地进行最近邻搜索。</p><p>​    如果不相交，向上回退。</p><p>（4）当会退到根节点时，搜索结束，最后的当前最近点，即为x的最近邻点。</p><p>kd树搜索的平均计算复杂度是$O(logN)$,这里N是训练实例数，kd数更适用于训练实例数远大于空间维数时的k近邻搜索，当空间维数接近训练实例数时，它的效率会迅速下降，几乎接近线性扫描。</p><ul><li><h3 id="维数灾难（curse-of-dimensionality）"><a href="#维数灾难（curse-of-dimensionality）" class="headerlink" title="维数灾难（curse of dimensionality）"></a>维数灾难（curse of dimensionality）</h3><p>如果需要达到密采样的效果，那么随着样本维度的上升，所需要的数据会越来越多，有一个计算公式：</p><script type="math/tex; mode=display">(\frac{1}{\delta})^n = samples\\  例如：\quad(10^3)^{20} =10^{60}</script><p>高维情况下，数据样本稀疏，距离计算困难，这被称为“维数灾难”。</p></li><li><h3 id="降维算法"><a href="#降维算法" class="headerlink" title="降维算法"></a>降维算法</h3><p>为什么要降维？</p><ul><li><p>随着数据维度不断降低，数据存储所需的空间也会随之减少。</p></li><li><p>低维数据有助于减少计算/训练用时。</p></li><li><p>一些算法在高维度数据上容易表现不佳，降维可提高算法可用性。</p></li><li><p>降维可以用删除冗余特征解决多重共线性问题。比如我们有两个变量：“一段时间内在跑步机上的耗时”和“卡路里消耗量”。这两个变量高度相关，在跑步机上花的时间越长，燃烧的卡路里自然就越多。因此，同时存储这两个数据意义不大，只需一个就够了。</p></li><li><p>降维有助于数据可视化。如前所述，如果数据维度很高，可视化会变得相当困难，而绘制二维三维数据的图表非常简单。</p></li></ul></li></ul><p>  数据维度降低有两种方法：</p><ul><li>仅保留原始数据汇总最相关的变量（特征选择）</li><li><p>寻找一组较小的变量，其中每个变量都会输入变量的组合，包含与输入变量基本相同的信息（降维）</p><h4 id="多维缩放（MDS）"><a href="#多维缩放（MDS）" class="headerlink" title="多维缩放（MDS）"></a>多维缩放（MDS）</h4></li></ul><hr><p>  输入：距离矩阵$D\in \mathbb{R}^{m*m}$,其元素$dist_ji$为样本$x_i$到$x_j$的距离；</p><p>  ​            低维空间维数$d^,$.</p><p>  过程：</p><p>  ​    1： 根据下式计算$dist_{i·}^2,dist_{·j}^2,dist_{··}^2$；</p><p>  ​    2：根据式子计算矩阵B</p><p>  ​    3：对矩阵B做特征值分解；</p><p>  ​    4：取$\tilde{\Lambda}$为$d^{,}$个最大特征值所构成的对角矩阵，$\tilde{V}$为相应的特征向量矩阵。</p><p>  输出：矩阵$\tilde{V} \tilde{\Lambda}^{\frac{1}{2}} \in \mathbb{R}^{m*d^，}$,每一行是一个样本的低维坐标。</p><script type="math/tex; mode=display">\begin{align}dist_{i·}^2 &= \frac{1}{m}\sum_{j=1}^mdist_{ij}^2\\dist_{·j}^2 &= \frac{1}{m}\sum_{i=1}^mdist_{ij}^2\\dist_{··}^2 &= \frac{1}{m^2}\sum_{i=1}^m\sum_{j=1}^mdist_{ij}^2\\b_{ij}&= -\frac{1}{2}(dist_{ij}^2-dist_{i·}^2-dist_{·j}^2+dist_{··}^2) \\B &= V \Lambda V^T  \\\end{align}</script><h4 id="主成分分析（PCA）"><a href="#主成分分析（PCA）" class="headerlink" title="主成分分析（PCA）"></a>主成分分析（PCA）</h4><p>经过线性变换，高维空间中的数据样本可以映射为低维数据，$X = {x_1,x_2,x_3…x_m}\in \mathbb{R}^{d*m}$,变换之后得到$d’ \leq d$维空间样本</p><script type="math/tex; mode=display">X=W^TX</script><p>$W \in \mathbb{R}^{d<em>d’}$是变换矩阵，$Z \in \mathbb{R}^{d‘</em>m}$是样本在新空间中的表达。</p><p>更一般的，如果W是一组基正交基向量，那么数据X就完全被降到了一个以W各属性为轴的低维线性空间。若要求低维子空间对样本具有最大可分性，则将得到一种极为常用的线性降维方法。</p><hr><p>输入：样本集D = {x_1,x_2,x_3,…x_m};</p><p>​    低空间维数$d’$</p><p>过程：</p><p>1：对所有的样本进行预处理（zero means   and unit variance）；</p><p>2：计算样本的协方差矩阵$XX^T$;</p><p>3：对协方差矩阵$XX^T$做特征值解；</p><p>4：去除最大的$d’$个特征值多对应的特征向量$w_1,w_2,…w_{d’}$</p><p>输出 ：投影矩阵$W* = (w_1,w_2,…w_{d’})$</p><hr><p>算法的结果是输出是一个投影矩阵，若要得到降维之后的数据需要进行投影计算：$X’=W^TX$</p><p>。</p><p>降维算法有多种理解和推导方式，西瓜书上提到了两种角度去推导PCA，一种是从重构角度，即样本点到这个超平面的距离最远，另一种是从数据间隔角度，即样本点在这个超平面上的投影尽可能分开。</p><p>​    </p><p>降维后的空间的维数d’通常是由用户事先指定，或者通过在d’值同步的低维空间中对k邻近分类器（或其他开销较小的学习器）进行交叉验证来选取较好的d’值。对PCA，还可从重构的角度设置一个重构阈值，例如t = 95%,然后选取使下式成立的最小d’值：</p><script type="math/tex; mode=display">\frac{\sum_{i=1}^d' \lambda_i}{\sum_{i=1}^d \lambda_i}\geq t</script><p>PCA降维的的效果是d-d’维的数据被过滤掉了，舍弃掉这部分信息是必要的，一方面舍弃掉这部分信息后能够使得样本的采样密度变大，另一方面最小特征值对应的特征销量往往与噪声有关。</p><h3 id="核化线性降维（KPCA）"><a href="#核化线性降维（KPCA）" class="headerlink" title="核化线性降维（KPCA）"></a>核化线性降维（KPCA）</h3><p>​         核化线性降维是在PCA的预处理阶段使用核化将数据映射到高维可分空间，然后再采用线性映射。</p><p>​        假定$z_i$是由原始属性空间中的样本点$x_i$通过映射$\phi$产生，即$z_i=\phi(x_i),i=1,2,3…,m.$若$\phi$能被显示地        表达出来，则通过它将样本映射至高维特征空间，再在特征空间中实施PCA即可，</p><script type="math/tex; mode=display">(\sum_{i=1}^m\phi(x_i)\phi(x_i)^T)w_j = \lambda_jw_j\\</script><script type="math/tex; mode=display">\begin{align}(\sum_{i=1}^mz_iz_i^T)w_j&=\lambda_jw_j\\w_j=\frac{1}{\lambda_j}(\sum_{i=1}^mz_iz_i^T)w_j &=\sum_{i=1}^mz_i\frac{z_i^T w_j}{\lambda_j}\\&=\sum_{i=1}^mz_ia_i^j\end{align}</script><p>​        可以得到：</p><script type="math/tex; mode=display">w_j = \sum_{i=1}^m\phi(x_i)a_i^j</script><p>​        引入核函数</p><script type="math/tex; mode=display">k(x_i,x_j)=\phi(x_i)^T\phi(x_j)</script><p>​        将（19）he (18)带入（14）化简后得：</p><script type="math/tex; mode=display">K \mathbf{\alpha}^j = \lambda_j\alpha^j</script><p>其中K为核矩阵，$(K)_ij=k(x_i,x_j),\alpha ^j= (\alpha_1^j;\alpha_2^j;…;\alpha_m^j)$.显然，上式是特征值分解问题，取K的d’个最大特征值对应的特征向量即可。</p><p>对新样本x，其投影后的第j（1,2……,d’）维坐标为</p><script type="math/tex; mode=display">z_j=w_j^T\phi(x)=\sum_{i=1}^m\alpha_i^j\phi(x_i)^T\phi(x)\\=\sum_{i=1}^m\alpha_i^jk(x_i,x)</script><h3 id="独立成分分析（ICA）"><a href="#独立成分分析（ICA）" class="headerlink" title="独立成分分析（ICA）"></a>独立成分分析（ICA）</h3><hr><h4 id="线性无关和独立"><a href="#线性无关和独立" class="headerlink" title="线性无关和独立"></a>线性无关和独立</h4><p>这两个概念在定义上的区别是明显的，假设存在变量X,Y</p><p>独立：$F(X,Y)=F(X)F(Y)$</p><p>不相关：$Cov(X,Y)=E(XY)-E(X)E(Y)=0$</p><p>这里要明确一点，我们这里定义的相关性仅仅是指线性的，有很多的相关不是线性的，比如：$Cov(X,X^2)=0$这两个变量虽然是线性无关的，但是它们仍然是相关的，这种相关是平方相关，即非线性相关。所以它们仍然不能称之为独立。</p><p>这也就是说为什么独立是比不相关更大的一个概念。在期望存在的情况下（某些分布期望不存在），两个变量相互独立，那么它们一定线性无关，但是如果它们是线性无关，却不一定相互独立。因为还存在非线性相关的可能。</p><hr><ol><li>主成分分析假设源信号间彼此非相关，独立成分分析假设源信号间彼此独立。</li><li>主成分分析认为主元之间彼此正交，样本呈高斯分布；独立成分分析则不要求样本呈高斯分布。</li></ol><p>在利用最大化信息熵的方法进行独立成分分析的时候，需要为源信号假定一个概率密度分布函数g’，进而找出使得g(Y)=g(Wx)的<strong>信息熵</strong>最大的变换W，即有Y=s。  </p><p><strong>不管是PCA还是ICA，都不需要你对源信号的分布做具体的假设；</strong>如果观察到的信号为高斯，那么源信号也为高斯，此时PCA和ICA等价</p><p>ICA认为一个信号可以被分解成若干个统计独立的分量的线性组合，而后者携带更多的信息。我们可以证明，只要源信号非高斯，那么这种分解是唯一的。若源信号为高斯的话，那么显然可能有无穷多这样的分解。</p><p>先谈谈个人对这个的理解，首先有中心极限定理可知，n个独立变量的线性组合会收敛于一个高斯分布。所以对于一个非高斯随机变量，ICA认为可以将它分解为若干独立变量的线性组合，且这个分解唯一。</p><p>这个算法的根本是根据这样一个定理。</p><p>定理（Pierre Comon, 1994）假设随机信号z服从模型z=Bs, 其中s的分量相互独立，且其中至多可以有一个为高斯；B为满秩方阵。那么若z的分量相互独立当且仅当B=PD，其中P为排列矩阵(permutation matrix)，D为对角矩阵。</p><p>看了别人的解释，大致归纳如下，对观测到的变量x（样本），对该变量做线性变换<strong>z=Qx</strong>,若z的分量线性无关，那么z的分量$z_i$一定对应这某个信号源$s_i$乘以一个系数。也就是说可以通过某种方式将观测变量（也就是样本）分解为若干源信号$s_i$的线性组合。下面把别人的一个解释附上：</p><p>具备相同的统计特征的可能来自两个不同的系统，这意味着只观察x我们不可能知道它来自哪个一个，从而我们就不可能推断出源信号s的强度（方差）。为了在技术上消除这种不确定性，人们干脆约定源信号s的方差为1,。有了这个约定，再通过数据预处理的方法，我们可以把原混合矩阵A化为了一个自由度更高的正交矩阵。</p><script type="math/tex; mode=display">z = C^{-1/2}As = (AA^T)^{-1/2}As</script><p>取$D=(AA^T)^{-1/2}A$ ,则它可以看做一个新的混合矩阵，容易看出这是一个正交矩阵，它仅有$n(n-1)/2$个自由度，而混合矩阵一般有$n^2$个自由度。 </p><p>ICA需要满足的一些条件;</p><p>1) 大多数ICA的算法需要进行“数据预处理”（data preprocessing）：</p><p>先用PCA得到y，再把y的各个分量标准化（即让各分量除以自身的标准差）得到z。预处理后得到的z满足下面性质：</p><ul><li>z的各个分量不相关；</li><li>z的各个分量的方差都为1。</li></ul><p>-</p><p>这个人总结了PCA和ICA的差异：</p><hr><h2 id="与PCA区别"><a href="#与PCA区别" class="headerlink" title="与PCA区别"></a>与PCA区别</h2><ul><li>PCA是一种数据降维的方法，但是只对符合高斯分布的样本点比较有效</li><li>ICA认为观测信号是若干个统计独立的分量的线性组合，ICA要做的是一个解混过程。而PCA是一个信息提取的过程，将原始数据降维，现已成为ICA将数据标准化的预处理步骤。</li></ul><p>1） 可以感性上对比下ICA和PCA的区别， </p><p>　一方面，PCA是将原始数据降维并提取出不相关的属性，而ICA是将原始数据降维并提取出相互独立的属性。 　另一方面，PCA目的是找到这样一组分量表示，使得重构误差最小，即最能代表原事物的特征。ICA的目的是找到这样一组分量表示，使得每个分量最大化独立，能够发现一些隐藏因素。由此可见，ICA的条件比PCA更强些。</p><p>2）　ICA要求找到最大独立的方向，各个成分是独立的；PCA要求找到最大方差的方向，各个成分是正交的。 </p><p>3）　总的来说，ICA认为观测信号是若干个统计独立的分量的线性组合，ICA要做的是一个解混过程。而PCA是一个信息提取的过程，将原始数据降维，现已成为ICA将数据标准化的预处理步骤。</p><h3 id="等度量映射（Isometric-Mappig-Isomap）"><a href="#等度量映射（Isometric-Mappig-Isomap）" class="headerlink" title="等度量映射（Isometric Mappig , Isomap）"></a>等度量映射（Isometric Mappig , Isomap）</h3><p>​    该算法利用流形在局部上与欧式空间同胚这个性质，对每个点基于欧式距离找出其近邻点，然后就能建立一个近邻连接图，图中紧邻点之间存在连接，而非近邻点之间不存在连接，于是，计算两点之间测地线距离的问题，就 转变为了计算近邻连接图上两点之间的最短路径问题，，基于近邻距离逼近能够获得低维流形上测地线距离的近似。</p><p>​    在近邻连接图上计算两点间的最短路径，可采用著名的Dijkstra算法或Floyd算法，在得到任意两点的距离之后，就可通过MDS方法来获得样本点在低维空间中的坐标，</p><hr><p>输入： 样本集$D={x_1,x_2,…x_m}$;</p><p>​         近邻参数k;</p><p>​         低维空间维数d’</p><p>过程：</p><p>​    1. for i = 1,2,…,m do</p><p>​        确定$x_i$的k近邻</p><p>​        $x_i$与k近邻点之间的距离设置为欧式距离，与其他点的距离设置为无穷大，</p><p>​    end for</p><p>​    2. 调用最短路劲该算法计算任意连样本之间的距离$dist(x_i,x_j);$</p><p>​    3. 将$dis(x_i,x_j)$作为MDS的算法的输入；</p><p>​    4. return MDS算法的输出。</p><p>输出：样本集D在低维空间的投影$Z = {z_1,z_2,…z_m}$</p><hr><p>Isomap仅是得到了训练样本在低维空间的坐标，对于新样本，如何将其映射到低维空间？</p><p>这个问题的常用结局放啊，是将训练样本的高维空间坐标作为输入，低维空间坐标作为输出，训练一个回归学习器来对新样本的低维空间坐标进行预测，这显然仅是一个权宜之计。</p><p>对近邻图的构建通常有两种法法，一种是指定近邻点的个数，例如欧式距离最近的k个点为近邻点，这样得到的近邻图称为k紧邻图，另一种是指定阈值$\epsilon$，距离$\epsilon$的点被认为是近邻点。范围过大过小都会有不足。</p><h3 id="局部线性嵌入（Locally-Linear-Embedding，LLE）"><a href="#局部线性嵌入（Locally-Linear-Embedding，LLE）" class="headerlink" title="局部线性嵌入（Locally Linear Embedding，LLE）"></a>局部线性嵌入（Locally Linear Embedding，LLE）</h3><p>局部线性嵌入试图保持邻域内样本之间的线性关系，假定样本点$x_i$的坐标能够通过它的邻域样本$x_j,x_k,x_l$的坐标通过线性组合而重构出来，即</p><script type="math/tex; mode=display">x_i = w_{ij}x_j+w_{ik}x_k+w_{il}x_l</script><p>LLE希望上式的关系在低维空间中得以保持。</p><p>LLE先为每个样本$x_i$找到其近邻下标集合$Q_i$,然后计算出基于$Q_i$中的样本点对$x_i$进行线性 重构的系数$w_i$；</p><script type="math/tex; mode=display">min_{w_1,w_2,...w_m}\sum_{i=1}^m||x_i-\sum_{j \in Q_i}w_{ij}x_j||_2^2\\s.t. \sum _{j \in Q_i}w_{ij}=1</script><p>上式通过经验误差最小化训练的到一组参数$w_{ij}$，使得$x_i$可以通过局部的其他样本点线性表出。</p><p>令$C_{ij}=(x_i-x_j)^T(x_i-x_k)$,$w_{ij}$有闭式解：</p><script type="math/tex; mode=display">w_{ij}=\frac{\sum_{k \in Q_i}C_{jk}^{-1}}{\sum_{l,s \in Q_i}C_{ls}^{-1}}</script><p>LLE在低维空间中爆出$w_i$不变，于是$x_i$对应的低维空间坐标可通过下式求解：</p><script type="math/tex; mode=display">min_{z_1,z_2,...z_m}\sum_{i=1}^m||z_i-\sum_{j\in Q_i}w_{ij}z_j||_2^2</script><p>上面两个式子同形，只是求解的变量不一样，令$Z=(z_1,z_2,z_3,…,z_m)\in \mathbb{R}^{d’*m},(w)_{ij}=w_{ij}$,</p><script type="math/tex; mode=display">M=(I-W)^T(I-W)</script><p>则式（25）可重写为：</p><script type="math/tex; mode=display">min_Z tr(ZMZ^T),\\s.t. \quad ZZ^T =I</script><p>上式可通过特征值求解，M最小的d’个特征值对应的特征向量组成的矩阵记为$Z^T$</p><h3 id="线性映射和非线性映射的区别？分别在哪些场景下使用？"><a href="#线性映射和非线性映射的区别？分别在哪些场景下使用？" class="headerlink" title="线性映射和非线性映射的区别？分别在哪些场景下使用？"></a>线性映射和非线性映射的区别？分别在哪些场景下使用？</h3><p> 线性映射是通过一个线性映射矩阵，将高维向量映射为低维向量，之所以称它们为线性映射，是因为它们符合这样一种矩阵乘法：</p><script type="math/tex; mode=display">X^{(i)'}=W^TX^{(i)}</script><p>这是一种典型的线性变换。而更有意思的是，对于映射矩阵W，有下面结论：</p><script type="math/tex; mode=display">\begin{align}(\sum_{i=1}^mz_iz_i^T)w_j&=\lambda_jw_j\\w_j=\frac{1}{\lambda_j}(\sum_{i=1}^mz_iz_i^T)w_j &=\sum_{i=1}^mz_i\frac{z_i^T w_j}{\lambda_j}\\&=\sum_{i=1}^mz_ia_i^j\end{align}</script><p>$a_i^j$是样本点$z_i$在低维空间的轴$w_j$上的映射距离除以协方差矩阵在$w_j$的特征值，可见，$w_j$是样本点$z_i$的线性组合。</p><p>非线性映射，没有上述性质，映射过程是非线性的，即低维数据无法通过映射矩阵和原样本点相乘得到。这也就意味着需要曲线救国，另辟蹊径来达到降维的效果。比如将低维样本核化到高维空间再进行PCA，或者使用其他流派，比如isometric mapping，umap等等。</p><h3 id="什么是线性数据，什么是非线性数据？"><a href="#什么是线性数据，什么是非线性数据？" class="headerlink" title="什么是线性数据，什么是非线性数据？"></a>什么是线性数据，什么是非线性数据？</h3><p>个人理解，线性数据和非线性数据指的是数据本身在空间中的分布类型，如果数据本身称线性分布，那么该数据就是线性数据，可以通过PCA处理，如果数据本身在空间中是以非线性分布存在，那么使用非线性降维方式更佳。</p><p>还有一种解释是从距离度量的角度来分析，“低维流型嵌入到高维空间后，直接在高维空间中计算直线距离具有误导性，因为高维空间中的直线距离在的低维嵌入流型上是不可达的。想象从三维空间观察蚂蚁从一点爬到另一点，它无法脱离曲面行走。”这样的数据测量无法直接使用欧式距离。</p><h2 id="连续和离散的理解"><a href="#连续和离散的理解" class="headerlink" title="连续和离散的理解"></a>连续和离散的理解</h2><p>就概率角度来讲，离散的的意义是随机变量只能取有限的几个点，连续的意义是，随机变量可以取到定义域内任意一个点。对离散变量来说P（x） = $\phi$,对连续变量，P(x$\leq$X) = $\phi$.  因此对连续变量谈论某点的取值是无意义的，因为它永远为0.</p><p>概率密度函数是针对连续型随机变量来讲的，它是分布函数的导数，它解释了变量的特性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;h3 id=&quot;KNN（K-nestest-Neighbor）&quot;&gt;&lt;a href=&quot;#KNN（K-nestest-Neighbor）&quot; class=&quot;headerlink&quot; title=&quot;KNN（K-nestest Neighbor）&quot;&gt;&lt;/a&gt;KNN（K-ne
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/"/>
    
      <category term="降维算法" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="ML" scheme="https://qingfengbangzuo.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>生成模型与判别模型</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%94%9F%E6%88%90%E3%80%81%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%94%9F%E6%88%90%E3%80%81%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B/</id>
    <published>2020-06-11T16:00:00.000Z</published>
    <updated>2020-06-12T10:56:00.164Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一句话概括机器学习"><a href="#一句话概括机器学习" class="headerlink" title="一句话概括机器学习"></a>一句话概括机器学习</h3><p>从数据出发，假设存在一个映射f（x） = y，学习器的任务就是从样本的假设空间里面找到一个h来逼近f。</p><p> 机器学习三要素：模型、策略、算法。模型决定了要学什么，对应的是<script type="math/tex">h(x)</script>；策略决定了怎么学，对应于损失函数；算法决定了具体的学习步骤；                                                   ——————by  李航</p><h3 id="感知机（Perceptron-Linear-Algorithm-PLA）"><a href="#感知机（Perceptron-Linear-Algorithm-PLA）" class="headerlink" title="感知机（Perceptron Linear Algorithm,PLA）"></a>感知机（Perceptron Linear Algorithm,PLA）</h3><p>感知机算法的基本思想：</p><script type="math/tex; mode=display">For \quad \mathbf{x} = (x_1,x_2,...,x_d),计算一个权重和(weight_score) :\\\begin{align}approve\quad &if \quad &\sum_{i=1}^d w_ix_i>threshold.\\deny  \quad &if       &\sum_{i=1}^d w_ix_i<threshold.\\ \end{align}</script><p>$\mathbf{y}:{+1(approve),-1(deny)}$，存在$h\in \mathbf{H}$(假设空间)</p><script type="math/tex; mode=display">h(x) = sign((\sum_{i=1}^d w_ix_i)-threshold)</script><p>sign是一类符号函数。</p><p><strong>注意：</strong>1.如果刚好在threhold上，那么根据需要把该样本归类为两类中任何一类。</p><p>​            2.除了数据之外，决定感知机算法的是两个量<strong>权重</strong>和<strong>门限值</strong>。</p><p>下面对公式做一些变形，将threshold放到累和公式内部。</p><script type="math/tex; mode=display">\begin{align*}h(x) &= sign((\sum_{i=1}^d w_ix_i)-threshold)\\     &=sign((\sum_{i=1}^d w_ix_i)+(-threshold)·(+1))\\令w_0 = -threshold, x_0 = 1 \\\\    & = sign(\sum_{\mathbf{i=0}}^d w_ix_i)\\    & = sign(\mathbf{W^Tx})\end{align*}</script><p>请记住我们的终极目的是得到一个最优的<script type="math/tex">h(x)</script>,但是假设空间那么大， 如何判断哪一个$h$最好呢？这是贯穿机器学习始终的一个问题，现实中我们评价一个学生的学习好，一般是依据他的成绩来下论断的，那么我们自然而然地会想到是不是也可以找到一个打分标准来反应$h(x)$的好坏呢？答案是肯定的，那就是损失函数。这个东西的具体形式多种多样，不过它的功能是一样的，就是给每个$h(x)$打分。</p><p>引入了损失函数，我们就可以反过来想，如果我希望知道我们班学习最好的人是谁，那么我只需要查看谁的分数最高就行了，同样地，如果我希望得到一个最好的$h(x)$，通过最小化损失函数不就ok了吗？那么我们就得到了优化目标。</p><script type="math/tex; mode=display">argmin_h \quad O(x)</script><p>再来，有了训练模型的公式<strong>h(x)</strong>和损失函数$O(x)$，以及一堆数据,我们依然不知道该如何下手，回想所有的启发式优化方法，我们似乎应该明确地抛给训练器一些$w$的一些初值，这样就会产生一个初始的$h(x)$，有了初始值事情就好办了。</p><p>回想控制论里面的负反馈回路，并与这里进行对比，数据$x$是输入，$h(x)$代表训练器，y是输出，$O(x)$是反馈回路，$y^l$是标签，$O(x)$就像是一个门卫一样，一旦我们训练出来的$h(x)$的损失不够小，就会被打回去，并连损失一块反馈回去再造，这个再造的过程就是算法的训练过程。但是我们的目的是得到一个最优的$h(x)$，$O(x)$的设定是模糊的，到底多小才算最小，当然损失为0最好，但这是理想情况下，事实上，$O(x)$很可能存在一个下限，但是我们并不知道。鉴于此，我们必定需要设定一个停止条件，让它在尽量满足我们的$O(x)$最小的情况下适时地停下来，这个条件一般是达到某个训练轮数或者$O(x)$的变化小到某个范围。</p><p>这大概就是一个机器学习的流程，这个流程中需要注意几点：</p><ol><li><p>损失函数的构造</p><p>损失函数并不是只有误差损失函数一种，这只是最常见的一种，好的损失函数可以提高训练速度。</p></li><li><p>改进过程</p><p>注意到上面的描述，机器学习过程分为了两个过程，一个是训练，一个是改进，训练过程比较简单，因为有公式$h(x)$的存在，改进过程一般比较困难，改进策略也有很多。</p><p>感知机算法这里给出了一种：</p><script type="math/tex; mode=display">\begin{align}&当\quad sign(\mathbf{W_t^Tx_{n(t)}}) \neq y_n(t)\\\\做以下修正：\\\\&\mathbf{W_{t+1}} \larr \mathbf{W_t} + y_{n(t)}\mathbf{x_{n(t)}}\end{align}</script><p>有一个有意思的现象是</p><script type="math/tex; mode=display">y_n \mathbf{W_{t+1}^Tx_n}\geq y_n\mathbf{W_t^Tx_n}</script><p>这个式子是恒成立的，这个式子反应的是改进过程。$y_n\in \{-1,1\}$, 这个式子反应的意思是改进以后的离$y_n$更近了。我们知道如果更新之前wx与$y_n$异号，那么更新的方向就是朝着同号的方向更新，可能在这次更新之后依旧没有同号，但至少离那条线更近了。</p></li></ol><ol><li><p>初始值的给定</p><p>初始值的设的好也可以提高训练速度，如果初始值设在了距离最小值很近的地方，那么目标函数就会很快地收敛到极值。这是影响收敛速度的一个因素。</p></li><li><p>停止条件的设定</p><p>停止条件的设定一般为训练次数达到了某个要求，但是往往这个要求也是很模糊的，设的大了影响性能，设的小了，收敛不够。有些估计方法可以估计出来这个训练次数。</p><p>一般当$O(x)$变化很小的时候，可以说明已经收敛到了某个极值点，注意是极值点，不是最小值。因为存在局部最优的情况。</p><p>还有其他的停止条件。</p><p>对感知机等线性分类模型来讲，如果数据集是线性可分的，由其收敛性可得当其损失函数为0时，算法会停止。</p></li><li><p>如何避免陷入局部最优</p></li><li><p>如何提高训练速度</p><p>影响训练速度的几个因素：数据的好坏、初值的设定、梯度下降的快慢（损失函数的设置）</p></li></ol><h4 id="PLA算法训练次数的界"><a href="#PLA算法训练次数的界" class="headerlink" title="PLA算法训练次数的界"></a>PLA算法训练次数的界</h4><p>前提假设:训练数据集线性可分。</p><p>由前提假设我们可知存在一个超平面将数据集线性可分$\mathbf{W_o^Tx=0}$($b=w_o,x_0 = 1$),$\mathbf{W_o}$是该平面的法向量，那么对于任何一个样本，有如下关系：</p><script type="math/tex; mode=display">y_i(\mathbf{W_o^Tx_i}) = y_i(\mathbf{W_ox_i}+b_o) \geq \gamma</script><p>令$R = max_{1\leq i\leq N}||x_i||$,则感知机算法在训练数据集上的误分类次数满足不等式</p><script type="math/tex; mode=display">k\leq (\frac{R}{\gamma})^2</script><p>注意到李航书中的一句话：</p><p><strong>当训练数据集线性可分时，感知机学习算法存在无穷多个解，其解由于不同的初值或不同的迭代顺序而可能有所不同。</strong></p><p>初值的不同意味这误分类点的集合不同，这样经过的迭代次数也会不同（因为感知机的更新机制为逢错才更新），导致最终得到的解不同。</p><p>迭代顺序不同也会影响迭代的次数，根据式子$k\leq (\frac{R}{\gamma})^2$,我们知道迭代是缓慢变化的，如果相邻两次更新变化过大，则会使得误分类点集合也发生变化，有些已经纠正过的误分类点又会回到误分类集合中。</p><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>从模型的功能来讲，机器学习分为预测模型与分类模型，从标签的角度考虑，又分为监督学习和无监督学习。根据模型的数据原理，又分为线性模型、神经网络、概率统计模型等等。可见分类指标的不同，对机器学习算法分类结果就会不同。</p><p>感知机算法与线性回归都属于线性模型，也就是说，他们的模型在表达形式上都包含线性项$W^TX$。相应的将线性模型扩展到广义概念，产生广义线性模型（generalized linear model）。它有如下形式：</p><script type="math/tex; mode=display">y = g^{-1}(W^Tx + b)</script><p>$g^{-1}$称为链接函数（link function），显然线性回归是最初始的线性模型，而</p><script type="math/tex; mode=display">lny = w^Tx+b</script><p>被称作对数线性回归。</p><p>无论是感知机还是线性回归，其实有一个隐含条件，那就是变量x都是连续的。</p><p>那么除了模型的任务不同以外，他们之间的联系是什么？如何由感知机推出线性模型？</p><p>所有的线性模型的结果都是得到一组$(W,b)$构成一个超平面。对于线性分类来讲，是找到一个超平面将数据分割开来，而线性回归则是找到一个超平面囊括所有样本。</p><p>也就是说，对于线性分类，要求不同类别的数据与分割面满足：</p><script type="math/tex; mode=display">y_i(\mathbf{W_ox_i}+b_o) \geq \gamma</script><p>所有的点离分割面越远越好。</p><p>而线性回归，则是要求数据点尽量靠近靠近平面，最好能找到一个平面包含所有数据点：</p><script type="math/tex; mode=display">y_i(\mathbf{W_ox_i}+b_o) \leq \gamma</script><p>当等号成立时为理想情况，也就是所有点都位于该平面上。</p><p>在感知机中，我们使用的损失函数为</p><script type="math/tex; mode=display">min-\frac{1}{||W||_2}y_i\sum_i^d(\mathbf{W^Tx_i})</script><p>$x_i\in R$, $R$为误分类点集合，$||W||_2 = 1$。</p><p>而在线性回归中我们使用均方误差作为损失函数</p><script type="math/tex; mode=display">min \sum_i^d (f(x_i)-y_i)^2 = min \sum_i^d(\mathbf{W^Tx_i}-y_i)^2</script><p>对于均方误差有固定的求解方式，那就是最小二乘法。这大大方便了我们的训练过程，因为有现成的公式直接套用就可以了。这也是线性回归模型训练时间短的原因之一。</p><script type="math/tex; mode=display">w = \frac{\sum_{i=1}^m y_i(x_i-\bar{x})}{\sum_{i=1}^mx_i^2-\frac{1}{m}(\sum_{i=1}^mx_i)^2}  \\b = \frac{1}{m}\sum_{i=1}^m(y_i-wx_i) \\向量形式：   \mathbf{W = (X^TX)^{-1}X^Ty}</script><p>但是使用最小二乘需要满足$X^TX$满秩，但显示任务中我们会遇到大量的变量，其数目甚至超过样例数目，导致$X$的列数多于行数，$X^TX$显然不满秩。此时可以求出多个$W$,他们都能使均方误差最小化，但是选择哪一个作为输出呢？</p><h3 id="不使用最小二乘的原因"><a href="#不使用最小二乘的原因" class="headerlink" title="不使用最小二乘的原因"></a>不使用最小二乘的原因</h3><p>1、最小二乘估计器虽然是无偏估计，但是拥有巨大的方差，这样会造成模型的不稳定，预测精度下降。预测精度可以通过shrink一些参数（包括稀疏为0）来提高，虽然这样会造成一些偏差，但是大幅度降低了方差，是一种变差换方差的方法。</p><p>2、可解释性不高。当变量达到成千上万的级别时，倾向于使用那些有较大影响的子集作为估计器的变量，而那些影响不大的变量，我们希望忽略掉</p><p>（下面是自己加的）</p><p>3、最小二乘的前提是$X^TX$满秩，当不满秩时会产生多个解，这时候需要采取某种策略来选取较好的模型。</p><p>解决上述问题有两种思路，一种是特征选择，筛选影响较大的特征。另一种是shrink参数。</p><h4 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h4><p><strong>正则化的作用是模型选择，另外一种模型选择的工具是交叉验证。</strong>也就是在众多的模型中选择出某个复杂度适当的模型达到避免过拟合的目的。产生过拟合的原因是估计器的高方差，而正则化的作用就是通过偏差换方差。</p><p>正则化项可以取不同的形式，在回归问题，损失函数是平方损失，正则化项可以是参数向量的L1或者L2范数</p><p>L2正则化：</p><script type="math/tex; mode=display">L(w) = \frac{1}{N}\sum_{i=1}^N(f(x_i;w)-y_i)^2+\frac{\lambda}{2}||w||^2</script><p>作用：</p><ol><li><p>权重衰减。</p><p>使用正则化后的更新公式变为：</p><script type="math/tex; mode=display">w_{k+1} = (1-\eta\lambda)w_k - \eta y_ix_i</script><p>可见，通过更新，参数衰减的更快了。</p></li><li><p>限制参数的大小。</p><p>假设我给了一个大的$\lambda$，那么为了使得整体最小化，我必须使得后面这样一项最小，要想使得后面的一项不太大，方法只能是让$\sum_{i=1}^N||w||^2$不太大，以此来削弱后一项的权重。这样通过控制$\lambda$就能把参数控制在一个不大的范围里面。</p></li></ol><p>参数较小意味着模型的抗干扰能力强，因为较小的参数对数据差异化做出的反应不会很大。另一方面，对于多项式模型，小的参数会削弱高次项带来的影响，使得模型更简单更趋于线性。</p><p>L1正则化：</p><script type="math/tex; mode=display">L(w) = \frac{1}{N}\sum_{i=1}^N(f(x_i;w)-y_i)^2 + \lambda||w||1</script><p>L1正则化是通过加上或减去一个常量$\eta\lambda$，让w向0靠近。当$|w|$很大时，L2对权重的衰减速度比L1大的多，当|w|很小时，L1对权重的缩小比L2快的多。这是由于L2是比例缩小，而L1是减去固定值，这也解释了为什么L1正则可以让模型变得稀疏，L1对于小权重减小地很快，对大权重减小地较慢，因此模型主要集中在那些重要度高的特征上，对于不重要的特征，权重会很快地趋近于0.所以最终权重w会变得稀疏。</p><p>Lasso回归更新每个变量通过减去一个固定的因子，在零处截断，这被称作’soft threshold’，而特征选择是删除所有系数小于某个阈值的变量，这是一种’hard threshold’。</p><p><strong>Ridge回归和Lasso回归都是有偏的。</strong></p><p>优缺点：</p><div class="table-container"><table><thead><tr><th></th><th>岭回归</th><th style="text-align:left">Lasso回归</th></tr></thead><tbody><tr><td>优</td><td>可以有效控制方差，达到避免过拟合的效果。在有相关性的变量上表现比较好。</td><td style="text-align:left">通过收缩系数，可以产生稀疏矩阵，达到筛选变量的目的</td></tr><tr><td>缺</td><td>模型结果中包含了所有的变量系数，如果变量过多会导致模型的结果不够精确，对数据的干扰没有Lasso好。</td><td style="text-align:left">当变量数目大于样本数目的时候，Lasso只能得到min(N，p)个变量，由于稀疏了大量变量，所以会导致模型不够精确。如果预测变量具有群组效应，则用Lasso回 归时，只能选出其中的一个预测变量．对于通常的N&gt;PN&gt;P的情形，如果预测变量中 存在很强的共线性，Lasso的预测表现受控于岭回 归．即在具有相关性的预测变量上表现不好。</td></tr></tbody></table></div><p>因此2005年有人提出了 弹性网回归方法 （elastic net Regression）</p><p>正则项</p><script type="math/tex; mode=display">\lambda \sum_{j=1}^p(\alpha \beta_j^2+(1-\alpha|\beta_j|))</script><p>损失函数为</p><script type="math/tex; mode=display">L(w) = \frac{1}{N}\sum_{i=1}^N(f(x_i;w)-y_i)^2 +\lambda_1\sum_{i=1}^N|w_i|+\lambda_2 \sum_{i=1}^Nw_i^2</script><p>令$\lambda = \lambda_1+\lambda_2$, $a = \frac{\lambda_1}{\lambda_1+\lambda_2}$</p><script type="math/tex; mode=display">L(w) = \frac{1}{N}\sum_{i=1}^N(f(x_i;w)-y_i)^2 +\lambda \sum_{j=1}^p(\alpha \beta_j^2+(1-\alpha|\beta_j|))</script><p>对于正则化通式</p><script type="math/tex; mode=display">argmin_w (\frac{1}{N}\sum_{i=1}^N(f(x_i;w)-y_i)^2+ \lambda\sum_{i=1}^N|w_i|^q)</script><p><strong>subset selection、lasso、ridge都是可以视为估计器的贝叶斯先验分布，但是请注意他们是作为后验模式导出的，即后验最大化，一般的，我们更希望使用贝叶斯估计器的后验分布的均值，而岭回归是后验平均，而lasso和subset selection不是</strong></p><p>但为什么不可以使得q小于1，或者使得q大于2呢？为什么恰好是$1\leq q \leq2$呢？</p><p>观察一下，不同q值下情况，当小于1时，先验分布不为uiform，且当为q&gt;= 1时，约束区域刚好为凸的，而非凸优化问题使得优化问题更难。</p><p>当q&gt;2时，会发现图形是越来越向矩形变化的，使用高于2的正则化项，按照书中的说法</p><p>“our experience is that it is not worth the effort for the extra variance incurred”</p><p>我理解的意思是一味地的追去限制方差是不值得的，因为随着越来越紧地限制方差，参数会逐渐地偏离0，就是说我们得到的最终模型，那些无关紧要的变量的参数再也不是趋于零了。</p><p>但是我们十分希望既获得lasso将无关紧要参数设为0的能力，也希望将方差限制的更紧一点（偏好是尽量选择后验平均）。</p><p>因此提出了弹性网，来平衡这两点原因.</p><p>总之，elastic-net的优点如下</p><p>“The elastic-net selects variables like the lasso, and shrinks together the coefficients of correlated predictors like ridge.”</p><p>在变量选择上表现像lasso，在相关性变量上的表现像ridge。</p><p>subset selection方法有：best subset selection (指定阈值)、forward stepwise 、forward stagewise </p><p>shrinking method : ridge、lasso、PCR(principal component regression) 、PLS(partial Least squares)。</p><p>PLS和PCR用来处理数据变量之间的强相关问题。他们的思想是通过在原数据上进行线性组合构成新的预测变量。</p><p>下面是对这几种策略的一个总结。</p><p>“It is interesting to compare the shrinkage behavior of these different<br>methods. Recall that ridge regression shrinks all directions, but shrinks<br>low-variance directions more. Principal components regression leaves M<br>high-variance directions alone, and discards the rest. Interestingly, it can<br>be shown that partial least squares also tends to shrink the low-variance<br>directions, but can actually inflate some of the higher variance directions.<br>This can make PLS a little unstable, and cause it to have slightly higher<br>prediction error compared to ridge regression. A full study is given in Frank<br>and Friedman (1993). These authors conclude that for minimizing prediction<br>error, ridge regression is generally preferable to variable subset selection,<br>principal components regression and partial least squares. However<br>the improvement over the latter two methods was only slight.</p><p>To summarize, PLS, PCR and ridge regression tend to behave similarly.<br>Ridge regression may be preferred because it shrinks smoothly, rather than<br>in discrete steps. Lasso falls somewhere between ridge regression and best<br>subset regression, and enjoys some of the properties of each.”</p><p>ridge 回归是在所有方向上进行shrink，且在low_variance的方向上做的更多。PCR是选择留下M个high-variance的方向，其余的全部抛弃。而PLS虽然也倾向于shrink low_variance方向，但是会使得高high-variance方向的有些膨胀（应该是参数值会显得较大），这会使得PLS显得有些不稳定（这是因为低方差的参数集合使得模型更稳定）。且相对于ridge会多产生轻微的预测误差。Frank and Friedman认为在最小化预测误差上问题上，ridge比subset selection、PCR、PLS都表现地更好，不过相比后面两种只有轻微的优势。</p><p>总结来说，PLS、PCR、和ridge都表现地很接近，但ridge表现的更加平滑，而PLS和PCR由于过程是离散的，所以表现欠佳。lasso的效果介于ridge和subset selection之间，兼具两者的优点（压缩参数和稀疏解）。</p><h3 id="从概率角度理解线性回归"><a href="#从概率角度理解线性回归" class="headerlink" title="从概率角度理解线性回归"></a>从概率角度理解线性回归</h3><p>首先，我们可以假设目标变量 t（就是标签y’）有下面的形式构成:</p><script type="math/tex; mode=display">t = y(x,w)+\epsilon</script><p>即数据标签有决策函数加随机误差构成。一般假设这个偏差服从零一高斯分布，由一个精度变量$\beta$控制。</p><p>那么由于误差服从高斯分布，决策函数是线性的（也有可能使用了basis函数，这时候就不是线性的了，但无论是否线性，这里的决策函数只改变标签分布的均值），标签的分布就可以写成：（单一参数呈高斯分布）</p><script type="math/tex; mode=display">p(t|x,w,\beta) = N(t|y(x,w),\beta^{-1})</script><p>这个结果是直观的，因为当我们认为误差是高斯的时候，就是相当于在决策值上下进行高斯波动。</p><p>也有下面的式子：</p><script type="math/tex; mode=display">E[t|x] = \int tp(t|x)dt = y(x,w)</script><p>因为误差服从的是0-1分布。 </p><p>至此，将标签扩展到更大的数据集，我们可以写出最大似然函数，<strong>最大似然的前提是各变量间相互独立、</strong>（所有参数和标签的似然估计）</p><script type="math/tex; mode=display">p(\mathbf{t}|\mathbf{X,w},\beta) = \prod_{n=1}^NN(t_n|\mathbf{w^T}\phi(x_n),\beta^{-1})</script><p>对数似然：</p><script type="math/tex; mode=display">\begin{align}lnp(\mathbf{t}|w,\beta) &= \sum_{n=1}^Nln N(t_n|\mathbf{w^T}\phi(x_n),\beta^{-1}) \\& = \frac{N}{2}ln \beta - \frac{N}{2}ln(2\pi)-\beta E_D(\mathbf{w})\end{align}</script><p>接下来就是见证奇迹的时刻</p><script type="math/tex; mode=display">E_D(\mathbf{w}) = \frac{1}{2}\sum_{n=1}^N\{t_n -\mathbf{w^T}\phi(x_n)\}^2</script><p>这就是我们平时使用的sum-of-squares error项。</p><p>对数似然取梯度有：</p><script type="math/tex; mode=display">\nabla lnp(\mathbf{t|w},\beta) = \sum_{n=1}^N\{t_n -\mathbf{w^T}\phi(x_n)\}\phi(x_n)^T</script><p>令梯度为0 可得最小二乘解</p><script type="math/tex; mode=display">w_{ML} = \mathbf{(\phi^T\phi)^{-1}\phi^T t}\\w_0 = \bar{t} - \sum_{n=1}^{M-1} w_j\bar{\phi_j}</script><p>$w_0  = \frac{1}{N}\sum_{n=1}^N t_n$,               $\bar{\phi_j}= \frac{1}{N}\sum_{n=1}^N\phi_j(x_n)$</p><p>这样就从贝叶斯角度把线性回归给串起来了。</p><p>下面再讨论几个分布：</p><h4 id="参数分布"><a href="#参数分布" class="headerlink" title="参数分布"></a>参数分布</h4><p>先假设参数先验分布服从 <script type="math/tex">p(w) = N(w|m_0,S_0)</script>.</p><p>有贝叶斯后验关系得到</p><script type="math/tex; mode=display">p(w|t) = \frac{p(t|w)p(w)}{p(t)}</script><p>p(t|w)是似然函数，p(w)是w的先验分布（假设为高斯），p(t)是标签的先验分布。原话是这样说的：</p><p>“which is proportional to the product of the likelihood function and the prior。Due to the choice of a conjugate Gaussian prior distribution, the posterior will also be Gaussian”</p><p>这里不是很清楚。</p><p>然后，p(w|t)就是一高斯分布$p(w|t) = N(w|m_N.S_N)$</p><script type="math/tex; mode=display">\mathbf{m_N} = S_N(S_0^{-1}m_0+\beta\Phi^T\mathbf{t}) \\\mathbf{S_N^{-1}} = S_0^{-1} + \beta\Phi^T\Phi</script><p>可见，当取$W_{MAP} = m_N$,我们就可以得到最大权重向量。</p><p>注意上述的式子，当w的先验分布的方差为无限情况时，有$S_0^{-1}$ = 0，$m_N$等于最大似然估计。而当N=0时，此时相当于没有数据信息，此时后验分布相当于先验，有$m_N = m_0$。</p><p>下面考虑一种特殊情况，假设w服从zero-mean isotropic高斯分布，由一精度参数$\alpha$控制</p><script type="math/tex; mode=display">p(w|\alpha) = N(w|0,\alpha^{-1}\mathbf{I})</script><p>有</p><script type="math/tex; mode=display">m_N = \beta S_N\Phi^T\mathbf{t}\\S_N^{-1} = \alpha I + \beta\Phi^T\Phi</script><p>似然函数</p><script type="math/tex; mode=display">lnp(w|\mathbf{t}) = -\frac{\beta}{2} \sum_{n=1}^N\{t_n - \mathbf{w}^T\phi(x_n)\}^2 - \frac{\alpha}{2}\mathbf{w^Tw}+const</script><p>这和我们的正则化函数非常像。我们可以近似地认为加了正则项的函数得到的参数是服从均值为0的高斯分布，这也就是为什么加了正则化以后，参数都会变得比较小。这就相当于我们假设了，参数的先验分布服从均值为0的高斯分布。这是从贝叶斯角度出发来解释正则化。</p><h4 id="预测值分布"><a href="#预测值分布" class="headerlink" title="预测值分布"></a>预测值分布</h4><p>预测值分布的定义：</p><script type="math/tex; mode=display">p(t|x,t,\alpha,\beta)  = N(t|\mathbf{m_N^T}\phi(x),\delta^2_N(x))</script><p>方差</p><script type="math/tex; mode=display">\delta^2_N(x) = \frac{1}{\beta}+\phi(x)^TS_N\phi(x)</script><p>预测值的分布由误差和参数的波动共同决定，当数据点越来越多的时候，方差$\delta_N^2$会越来越小，因为数据点的增长，不断缩小着参数的取值范围，当数据点（采样得到的）达到一定数目趋近于无穷大时，方差的第二项会为0。</p><h3 id="线性分类问题"><a href="#线性分类问题" class="headerlink" title="线性分类问题"></a>线性分类问题</h3><script type="math/tex; mode=display">y(x) = \mathbf{wx}+w_0</script><p>对于如上的线性函数，为了方便理解，我们总希望把它放到一个空间里来解释，我们考虑一个二维或者三维的空间，上述方程对应的就是一条线或者是一个平面，$\mathbf{w}$就是它的法向量，决定该决策边界的方向，其实当决策边界是线性的时候，应当立即想到该决策边界是一条线或平面，当决策边界是非线性的时候，应当立即想到是一条曲线或者曲面。$w_0$表示该平面的位移，用来决定该平面的位置。当提到决策边界的时候，应当立即想到，所有在决策边界上的点到给决策边界的距离为0，而其他没有在决策边界上的点到决策边界的绝对值距离都大于0.前面提到，回归与分类都是找到一个决策边界，回归是寻找一个决策边界将所有点都拟合，而分类是寻找一个决策边界将所有点都分开。</p><p>多分类的思路：</p><p>one versus rest：就是找到k-1个分类器，每个分类器的作用是将k类中的某一类与剩余的其他类分开。这样最终会出现k-1个分类器。这样，当出现一个新数据点的时候，穷尽这k-1个分类器就可以找到它合适的类别。</p><p>缺点：1、可能会出现一个数据属于多个类的情况。</p><p>​            2、数据点不平衡。就是比方说，属于类K1的数据点只有10%，而反例占到了90%.这样的数据胡影响结果。</p><p>one versus one：这种方法是找到k(k-1)/2个分类器，每个分类器的作用是将两两对应的类别分开，也就是说每个分类器只负责将其相邻的两类分开，但是这引入了一个问题，就是“模糊区域”。</p><p>解决这个问题的方法是改变决策函数的定义方式：</p><script type="math/tex; mode=display">\mathbf{(w_k-w_j)^Tx}+(w_{k0}-w_{j0}) = 0</script><p>$\mathbf{w_k、w_j}$是one-vs-rest分类器，这样定义出来的决策边界相当于从这些$w_k,w_J$相交的线段夹角的中心分离出一条线，这些分离出来的线段顶端会交于一点，所以就避免了“模糊区域”的产生。</p><p>优点：可以视为多个模型投票的结果。比较健壮。</p><p>将线性回归用于分类问题，有一个显著的问题。当分类标签大于3的时候，而输入空间只有2维时，会出现某个标签被其他标签覆盖（masked）问题。</p><p>解决这种问题的方法是扩展输入空间为多项式空间，就是在原数据的基础上增加高次幂的多项式和多项式的內积，比如将（$x_1,x_2$）扩展为($x_1,x_2,x_1x_2,x_1^2,x_2^2$).这样就将线性回归转变为了quadratic 拟合，也就是曲线拟合。可以想象一个曲线分割面可以将三类数据很好的分割开来。那么可以想象，当数据有4类的时候，就需要cubic 拟合，即扩展到更高维的输入空间。</p><p><strong>一个常用的技巧是当K&gt;3类时，就需要扩展多项式到K-1次幂的级别，加上cross-products 即內积项，总共要扩展$O(p^{k-1})$项。</strong></p><p>对于线性回归，只要当问题有一个大的类别，却有一个小维度的输入空间时，就可能会发生上述的覆盖问题。</p><p>以上是线性回归用作分类时存在的弊端，书中的意思是使用线性判别方法可以避免这种现象。</p><h4 id="生成类模型对数几率版本"><a href="#生成类模型对数几率版本" class="headerlink" title="生成类模型对数几率版本"></a>生成类模型对数几率版本</h4><p>一个重要的发现是，无论是从线性回归出发的逻辑回归还是从线性判别出发的LDA，都涉及到了对数几率：</p><p>Logistic regression:</p><script type="math/tex; mode=display">log\frac{y}{1-y} =  \mathbf{w^Tx}+b\\这里 \quad y  = \frac{1}{1+e^{-wx+b}}</script><p>LDA:</p><script type="math/tex; mode=display">log\frac{P(G=k|X=x)}{P(G=l|X=x)} = log\frac{f_k(x)}{f_l(x)}+log\frac{\pi_k}{\pi_l}\\=log\frac{\pi_k}{\pi_l} -\frac{1}{2}(\mu_k+\mu_l)^T\Sigma^{-1}(\mu_K-\mu_l)+x^T\Sigma^{-1}(\mu_k-\mu_l)\\ f_k(x) = P(X=x|G=k)      是当G=k类时X的概率密度函数，有等式\\P(G=k|X=x) = \frac{f_k(x)\pi_k}{\sum_{l=1}^Kf_l(x)\pi_l}</script><p>上面和标准的条件分布有些许不同，这里是使用概率密度代替了概率。</p><p>在周志华的书中，是直接给了我们sigmod函数，原因是我们需要找到一个函数将输出空间映射到一个（0，1）范围内，然后推出了对数几率。下面从概率角度再次进行强化：</p><script type="math/tex; mode=display">p(G1|x) = \frac{p(x|G1)p(G1)}{p(x|G1)p(G1)+p(x|G2)p(G2)}</script><p>上面是贝叶斯公式，从输出来看，也就是等号左边是一个概率值，我们要建立这样一个思想，sigmod函数的重要性在于它能把一个输入映射到（0，1）的空间内，所以，上述贝叶斯的输出空间就相当于一个sigmod函数的输出空间。因为我们把上述形式转换成sigmod函数形式</p><script type="math/tex; mode=display">\begin{align}p(G1|x) &= \frac{p(x|G1)p(G1)}{p(x|G1)p(G1)+p(x|G2)p(G2)}\\        &= \frac{1}{1-exp(-a)}=\sigma(a)\end{align}</script><p>这里的$a = ln\frac{p(x|G1)p(G1)}{p(x|G2)p(G2)}$,因此有</p><script type="math/tex; mode=display">a = ln(\frac{\sigma}{1-\sigma})</script><p><strong>而无论是逻辑回归还是LDA，在假设$p(x|G=k)$分布是高斯的情况下，都可以得出对数几率是线性的这样的结论，当后验概率相等，也就是对数几率为0的时候，误分类率降到最低。</strong></p><p>且有：</p><script type="math/tex; mode=display">\begin{align}\mathbf{w} &= \mathbf{\Sigma^{-1}(u_1-u_2)}\\w_0  &= -\frac{1}{2}\mathbf{u_1^T\Sigma^{-1}u_1+\frac{1}{2}u_2^T\Sigma^{-1}u_2+ln\frac{p(G1)}{p(G2)}}\end{align}</script><h4 id="放宽假设带来的后果"><a href="#放宽假设带来的后果" class="headerlink" title="放宽假设带来的后果"></a>放宽假设带来的后果</h4><p>在上面的结果中还有一个重要的假设是假设所有的$p(x|G=k)$都有一个共享的协方差矩阵(‘shared covariance matrix’)，才可以实现约分。这里我的理解是，每个类的数据点的分散情况都差不多，大家都是以相同的协方差拥簇在均值周围。当然这是理想情况，事实上，类的数据点的分布未必有相同的协方差，这时候我们就需要放宽假设条件了，让每个$p(x|G=k)$都拥有各自的方差。</p><p>这样带来的后果是什么呢？这样带来的最重要的后果就是决策边界不是线性的啦，是quadratic decision boundaries。因为不能共享一个协方差矩阵，所以不能实现约分，会留下2次项。</p><h4 id="最大似然版本"><a href="#最大似然版本" class="headerlink" title="最大似然版本"></a>最大似然版本</h4><p>由贝叶斯公式：</p><script type="math/tex; mode=display">p(G1|x) = p(G1)p(x|G1) = \pi N(x_n|u_1,\Sigma)\\p(G2|x) = p(G2)p(x|G2) = (1-\pi) N(x_n|u_2,\Sigma)</script><p>假设二分类，且$y \in {0,1}$，有$p(y_i|x_i;w,b) = y_ip(G1|x)+(1-y_i)p(G2|x)$或者$p(y_i|x_i;w,b) = p(G1|x)^{t_i}·p(G2|x)^{1-t_i}$</p><p>最大似然函数</p><script type="math/tex; mode=display">L = \prod_{i=1}^N p(y_i|x_i;w,b)</script><p>带入$p(y_i|x_i;w,b)$然后取对数可得对数似然估计函数。</p><p><strong>注意一点，对数似然不仅可以用来估计w,还可以用来估计$\pi$。事实上，我们直接将$\pi_1$（类的先验分布）视为$\frac{N_1}{N_1+N_2}$就是通过对数似然函数对$\pi$求导得来的。</strong></p><p>事实上，所有的参数$u_1、u_2、\Sigma$都可以通过对数似然函数得出，结果如下</p><script type="math/tex; mode=display">\begin{align}u_1 &= \frac{1}{N_1}\sum_{n=1}^N t_nx_n\\u_2 &= \frac{1}{N_2}\sum_{n=1}^N(1-t_n)x_n \\\Sigma  &= S = \frac{N_1}{N}S_1+\frac{N_2}{N}S_2 \\S1 &= \frac{1}{N_1}\sum_{n\in G1} (x_n-u_1)(x_n-u_1)^T \\S2 &= \frac{1}{N_2}\sum_{n\in G2} (x_n - u_2)(x_n - u_2)^T\end{align}</script><p>对于K类中的任何一类，有如下决策函数</p><script type="math/tex; mode=display">a_k(x) = \mathbf{w}_k^Tx + w_{k0}\\\quad \\\mathbf{w} = \Sigma^{-1} u_k\\w_{k0} = -\frac{1}{2}u_k^T\Sigma^{-1}u_k + ln p(C_k)</script><p>而两类之间的决策边界由如下公式得到</p><script type="math/tex; mode=display">\begin{align}\mathbf{w} &= \mathbf{\Sigma^{-1}(u_1-u_2)}\\w_0  &= -\frac{1}{2}\mathbf{u_1^T\Sigma^{-1}u_1+\frac{1}{2}u_2^T\Sigma^{-1}u_2+ln\frac{p(G1)}{p(G2)}}\end{align}</script><p>最后，给出一个新样本x，如何确定它的类别呢，根据贝叶斯决策论可知要找到x的类别，就需要最大化后验概率</p><script type="math/tex; mode=display">argmax_y \quad p(y|x) = argmax_y \quad \frac{p(x|y)p(y) }{p(x)} = argmax_y \quad p(x|y)p(y)</script><p>即找到使得上述后验概率最大的y。</p><h3 id="什么是贝叶斯决策论"><a href="#什么是贝叶斯决策论" class="headerlink" title="什么是贝叶斯决策论"></a>什么是贝叶斯决策论</h3><p>贝叶斯决策论是一个使用贝叶斯回归和分类的基础理论，它就强调了一件事，<strong>“要想获得最小的误分类率就需要选择能使得后验概率p(c|x)最大的类别标记”。</strong></p><p>定义一个条件风险：</p><script type="math/tex; mode=display">R(c_{i}|x) = \sum_{i=1}^N\lambda_{ij}P(c_j|x)</script><p>条件风险表明了在样本x上选择类别$c_i$的风险，$\lambda_{ij}$是风险因子。我们的目标是寻找一个判定准则$h:x\rarr y$最小总体条件风险</p><script type="math/tex; mode=display">R(h) = \mathbf{E}_x[R(h(x)|x)]</script><p>那么我们就得到了一个最优分类器</p><script type="math/tex; mode=display">h^*(x) = argmin_{c\in y} R(c|x)</script><p>以上呢，$R(h)$称为贝叶斯风险，$1-R(h^*)$反应了分类器所能达到的最优性能，即理论模型的精度上限。</p><p>一般令</p><script type="math/tex; mode=display">\lambda_{ij} = 0 \quad if \quad i=j \\\lambda_{ij} = 1 \quad if \quad otherwise</script><p>此时条件风险就变为了</p><script type="math/tex; mode=display">R(c|x) = 1-P(c|x)</script><p>于是最小化分类错误率的贝叶斯最优分类器为</p><script type="math/tex; mode=display">h^*(x) = argmax_{c \in y}P(c|x)</script><p>于是得到了最初的结论，贝叶斯决策论的核心就是给最大化后验概率这一损失函数提供理论支持。</p><p>但是直接得到后验分布往往是不现实的，比较好的方法是通过贝叶斯理论用先验概率和类条件概率来替代后验概率，这样就可以把后验概率表示出来了，然后再通过最大似然估计分别把参数求出来，这是一整套贝叶斯生成方法的基本逻辑。</p><h3 id="逻辑回归的损失函数"><a href="#逻辑回归的损失函数" class="headerlink" title="逻辑回归的损失函数"></a>逻辑回归的损失函数</h3><p>像逻辑回归这种用到了贝叶斯决策论的算法，它的损失函数是类似的。其实贝叶斯决策论已经告诉了我们损失函数</p><p>就是这个</p><script type="math/tex; mode=display">R(c_{i}|x) = \sum_{i=1}^N\lambda_{ij}P(c_j|x)</script><p>$\lambda_{ij}$是惩罚因子，这就是训练数据集上的损失函数。</p><p>在二分类情况中，我们定义$\lambda_{ij}$只取1，这样损失函数的大小就由类后验概率决定了，对于逻辑回归就是由下面的后验概率决定</p><script type="math/tex; mode=display">L（t_n,y_n) = -t_nlog(y_n)- (1-t_n)log(1-y_n)</script><p>我们这里使用的是对数损失。正好是对数似然的负数。</p><h3 id="生成模型之Naive-Bayes"><a href="#生成模型之Naive-Bayes" class="headerlink" title="生成模型之Naive Bayes"></a>生成模型之Naive Bayes</h3><p>朴素贝叶斯是针对离散变量的，而高斯判别针对的是连续变量。</p><p>朴素贝叶斯在文本识别类问题中有较好的效果，以垃圾邮件分类为例。</p><p>显然这是一个二分类问题，我们定义一个垃圾邮件字典，该字典中包含了50000个垃圾邮件中的常见单词，我们把这50000个单词作为我们的特征，令$x_i\in \{0,1\}$. 这样$x \in \{0,1\}^{50000}$, $y \in \{0,1\}$。显然$p(x_i|y)$和$p(y)$均服从二阶伯努利分布。那么类条件概率</p><script type="math/tex; mode=display">p(x|y) = p(x_1,x_2,...,x_{50000}|y) =p(x_1|y,x_2,x_3,...,x_{50000})p(x_2|y,x_3,x_4,...,x_{50000})...p(x_{50000}|y)</script><p><strong>假设，特征之间相互独立</strong>，上式可变为</p><script type="math/tex; mode=display">p(x|y) = \prod_{i=1}^{50000}p(x_i|y)</script><p>由于$p(x_i|y)$和$p(y)$均服从二阶伯努利分布，那么极大似然函数为</p><script type="math/tex; mode=display">p(y|x) = \prod_{n=1}^M [\prod_{i=1}^{50000}p(x_i|y)]·p(y)</script><p>根据上面的似然函数，我们可以得到一些参数，比如p(x_i|y)和p(y)等等，</p><script type="math/tex; mode=display">p(x_i|y=1) = \frac{\sum_{n=1}^{M}\mathbf{1}\{x_i =1,y=1\}}{\sum_{n=1}^M\mathbf{1}\{y=1\}}</script><script type="math/tex; mode=display">p(y=1) = \frac{\sum_{n=1}^M \mathbf{1}\{y=1\}}{M}</script><p>NB的决策函数和高斯判别一样，给定一个新样本，选取使得后验概率最大的那个类：</p><script type="math/tex; mode=display">argmax_y \quad p(x_{new}|y)p(y)</script><p>有一个问题，当训练数据中没有出现某个特征的样本时，比方说$x_{3000}$这个属性在训练数据集中没有出现，那么经过最大似然估计得出的$p(x_{3000}|y)$就为0.显然这是不合常理的，仅仅是因为训练数据中没有出现该属性就判定给属性出现的概率为0 显然不合适。为了解决这个问题，就需要引入拉普拉斯平滑，令N表示训练集D中可能的类别数，$N_i$表示第i个属性可能的取值数相应的变化为</p><script type="math/tex; mode=display">p(x_i|y=1) = \frac{\sum_{n=1}^{M}\mathbf{1}\{x_i =1,y=1\}+1}{\sum_{n=1}^M\mathbf{1}\{y=1\}+N_i}</script><script type="math/tex; mode=display">p(y=1) = \frac{\sum_{n=1}^M \mathbf{1}\{y=1\}+1}{M+N}</script><p>需要注意的几点，最重要的是朴素贝叶斯的假设是个属性变量之间相互独立，这个条件是苛刻的，但是即使在这个苛刻的前提下，NB的表现经常能取得不错的效果。</p><p>第二个需要注意的地方是使用拉普拉斯平滑的原因是因为训练数据中未出现相应的属性样本。</p><p>第三个需要注意的是NB有连续输入的版本，即将P(x|y)假设为服从高斯分布，其他的步骤相似，不再展开。</p><h3 id="对朴素贝叶斯的进行扩展"><a href="#对朴素贝叶斯的进行扩展" class="headerlink" title="对朴素贝叶斯的进行扩展"></a>对朴素贝叶斯的进行扩展</h3><p>上述的NB算法，我们假设$x_i\in\{0,1\}$，但在实际中，$x_i$的取值往往有多个，比如说，对年龄变量进行离散后，我们可能得到了多个区间，每个区间对应一个取值（0，18]，（19,30],（31,50]，(51,80]像这样，我们记录了多个取值。显然上述的NB算法不能需要扩展为多项式。</p><p>更改假设$x_i \in \{0,1,…,k\}$。那么$p(x_i|y)$服从的就不是二阶伯努利分布，而是多项式分布。</p><script type="math/tex; mode=display">P(X_1=n_1,X_2=n_2，...,X_k = n_k) =\{\begin{array}  \quad n!\prod_{i=1}^K\frac{p_i^{n_i}}{n_i!},\quad \sum_{i=1}^Kn_i=n \\  0 \quad otherwise\end{array}</script><p>那么</p><script type="math/tex; mode=display">p(x|y) = \prod_{i=1}^{50000}p(x_i|y)</script><p>另外，我们改变特征向量的形式：之前是固定了特征向量为我们的字典长度，现在特征向量变为邮件的长度。比如邮件中有300个单词，那么每个单词就是一个特征，取值为字典中相应单词的索引，比如我么的字典依旧为50000长度，然后每个特征$x_i$的取值就是[0,49999]。</p><script type="math/tex; mode=display">p(x_1,x_2,...x_{300} | y) = \prod_{i=1}^{300}p(x_i=k|y) \quad and \quad k \in [0,49999]</script><p>即p(x|y)服从多项式分布，似然函数为</p><script type="math/tex; mode=display">\prod_{n=1}^M [\prod_{i=1}^{300}p(x_i=k|y)]·p(y)</script><p>有似然函数得到的参数为(经过拉普拉斯平滑)</p><script type="math/tex; mode=display">p(x=k|y=1) = \frac{\sum_{n=0}^M\mathbf{1}\{y=1\}\sum_{j=1}^{n_i}\mathbf{1}\{x_j = k\}+1}{\sum_{n=1}^M\mathbf{1}\{y = 1\}·n_i+k}</script><p>p(x=k|y=0)可仿照上面得出，p(y)和朴素贝叶斯计算方式一样。</p><p>得出这些参数以后，利用决策函数就可以进行判断了</p><script type="math/tex; mode=display">argmax_y \quad p(x_{new}|y)p(y)</script><p>在文档分类问题中，扩展的NB模型的表现总是比NB要好一点，关于其中的具体原因，目前也没有一个明确的解释，一个可能的原因是多项式事件模型比NB多考虑了词出现的次数。</p><p>值得注意到的是，向NB或者多项式事件模型以及高斯判别模型这类生成模型，由于其假设p(x|y)均为指数分布簇，利用前面的结论，所有的指数分布簇函数均可推导出logistic后验分布，可知，这一一类的模型最终得到的决策边界均是线性的，也即是说这些分类器均是线性的。</p><h3 id="判别类模型之逻辑回归"><a href="#判别类模型之逻辑回归" class="headerlink" title="判别类模型之逻辑回归"></a>判别类模型之逻辑回归</h3><p>生成模型和判别模型的主要区别是，生成模型是使用类条件概率和类先验概率来近似后验概率，核心是贝叶斯决策论。判别类模型不使用先验分布，因此它的假设条件比较松，判别类模型焦点集中在数据本身。</p><p>从我自己的观点来看，两类模型的区别就是使用类先验分布和不使用类先验分布的区别，表现在似然函数上的不同</p><p>生成模型的似然函数</p><script type="math/tex; mode=display">p(t|x_i;w,\pi,u,\Sigma) = \prod_{i=1}^N \pi_1N(u_1,\Sigma)^{t_i}·\pi_2N(u_2,\Sigma)^{1-t_2}</script><p>判别模型的似然函数</p><script type="math/tex; mode=display">p(t|w) = \prod_{i=1}^N y_i^{t_i}·(1-y_i)^{1-t_i}</script><p>这里的$y_i = \sigma(wx)$.</p><p>这里无论是生成类模型也好，判别类模型也好，其中都包含参数$w$，也就是说，通过最大似然估计，两个其实都可以估计出合适的参数w. 上面已经介绍了生成类模型的参数计算方法。下面介绍判别类参数计算法方法，以逻辑回归为例</p><script type="math/tex; mode=display">\begin{align}p(t|w) &= \prod_{i=1}^N y_i^{t_i}·(1-y_i)^{1-t_i} \\ E(w) &= \sum_{i=1}^N t_iln(y_i)+(1-t_i)ln(1-y_i)\end{align}</script><p>对于$\sigma（a）$函数有这样的性质</p><script type="math/tex; mode=display">\frac{d\sigma}{da} = \sigma(1-\sigma)</script><p>对上述$E(w)$求梯度可得</p><script type="math/tex; mode=display">\nabla E(w) = \sum_{i=1}^N (y_i - t_i)x</script><p>这里得出了逻辑回归似然函数的一阶梯度公式，使用梯度下降和牛顿法都可以进行求解。</p><h4 id="逻辑回归多分类情况"><a href="#逻辑回归多分类情况" class="headerlink" title="逻辑回归多分类情况"></a>逻辑回归多分类情况</h4><p>对于多分类情况，后验概率为,注意到这里$y_k(\phi)$的 变化。</p><script type="math/tex; mode=display">p(G_k|\phi) = y_k(\phi) =  \frac{exp(a_k)}{\sum_jexp(a_j)}</script><p>这里的$a_k = w_k^T\phi$.这种叫做soft-max方式。</p><p>偏导公式</p><script type="math/tex; mode=display">\frac{dy_k}{da_j} = y_k(I_{kj}-y_j)</script><p>最大似然函数</p><script type="math/tex; mode=display">p(T|w_1,w_2,w_3,...w_k) = \prod_{n=1}^N\prod_{k=1}^K p(c_k|\phi)^{t_{nk}} = \prod_{n=1}^N\prod_{k=1}^K y_{nk}^{t_nk}</script><p>误差函数由最大似然函数取负对数组成</p><script type="math/tex; mode=display">E(w_1,w_2,...,w_k) = -lnp(T|w_1,w_2,...,w_k) = -\sum_{n=1}^N\sum_{k=1}^K t_{nk}ln(y_{nk})</script><p>一阶梯度有</p><script type="math/tex; mode=display">\nabla_{w_j}E(w_1,w_2,...,w_k) = \sum_{n=1}^N(y_{nj}-t_{nj})\phi_n</script><p>同样使用牛顿法可以求解w值。</p><h3 id="生成类模型和判别类模型的区别"><a href="#生成类模型和判别类模型的区别" class="headerlink" title="生成类模型和判别类模型的区别"></a>生成类模型和判别类模型的区别</h3><p>从算法思想来看，生成类模型和判别类模型的构造思想不一样，生成类模型的构造思想是通过标签学习特征，注重的是当前类下存在哪些特征，也就是说，我想达到一个效果，就是给我一个标签，我能知道这个类下大致有哪几类特征，当我做判断的时候，如果数据符合这几类特征，那么八成就是该类了，也就是说这些特征是我学到的东西。而判别类模型，不聚焦于这些特征，它只有一个目的，就是让我的误判损失最小就可以了，对当前数据来讲，让它归于哪一类可以使误判损失最小，那就把它归到哪一类。</p><p>从理论上来讲，两个的终极目的都是使得误判损失最小化，也都拥有最大似然版本，但两个版本的不同点在于，生成类似然函数中使用到了类先验概率和类条件概率，也就是通过这两个概率，让我们学到了一些特征。而判别类似然版本相对显得简单粗暴，它直接用数据估计使得误判损失最小的参数w。关于这一点，更正确的解释是，我们在判别类模型中使用的似然函数是joint liklihood(p(x,y)=p(x|y)p(y)),而在判别类模型中，我们使用到的确实conditional -likeihood（p(y|x) = p(y|x;$\theta$)）. 另外，判别类模型需要给出后验分布的表达式（逻辑回归假设的是后验分布服从sigmod函数），而先验分布不需要。</p><p>生成模型的优点是可以学习到参数w以外的一些东西，缺点是需要对数据分布进行高斯假设，当真实数据分布和假设相似的时候，效果很好，但是当真实数据和假设不同的时候，效果不如判别类算法。判别模型的优点是假设较宽，但可解释性较差。还有一个显著的对比是，生成模型，比如高斯判别由于做出了更强的假设，通常需要更少的数据，而判别模型，例如逻辑回归虽然有较弱的假设，但是为了拟合模型通常需要更多的样本。也就是说，当数据样本较少时，生成模型的表现可能较判别模型较好。</p><h3 id="高斯判别（生成模型）和逻辑回归（判别模型）之间有趣的关系"><a href="#高斯判别（生成模型）和逻辑回归（判别模型）之间有趣的关系" class="headerlink" title="高斯判别（生成模型）和逻辑回归（判别模型）之间有趣的关系"></a>高斯判别（生成模型）和逻辑回归（判别模型）之间有趣的关系</h3><p>在吴恩达的课程中提到了一个有趣的关系，</p><p>1、给定训练集(x,t)使用高斯判别可以拟合出两个高斯模型p(x|t=0)和p(x|t=1)，大致图形就是两个均值不同的鈡型曲线曲线相交</p><p>2、如果我计算这些训练样本的p(y=1|x)值，并拟合出一条曲线，会发现该拟合出来的曲线和sigmod函数非常相似。（鉴于sigmod函数和正太分布的关系，这里的曲线貌似就是sigmod函数）</p><p>3、如果假设p(x|y)服从高斯分布$\rarr$logistic函数（对数据点求p(y=1|x)） 但是这个结论反向推导并不成立，也就是说从logistic后验分布，不能推导出p(x|y)服从高斯分布。因为当我们假设p(x|y)服从泊松分布，同样可以导出logistic后验分布。<strong>因此，假设p(x|y)服从高斯分布是一个比假设logistic后验分布更强的假设。事实上只要是指数分布簇函数都可推导出logistic后验分布，从这个角度讲，充分体现了logistic后验分布假设的鲁棒性，因为所有的指数分布簇函数都包含了该假设</strong></p><p>关于最大似然估计</p><p>最大似然估计对于线性模型相当于一个soft constrain，它要求所拟合的直线越靠近数据点越好。</p><hr><h3 id="核策略"><a href="#核策略" class="headerlink" title="核策略"></a>核策略</h3><p>什么是核函数？</p><script type="math/tex; mode=display">k(x,x') = \phi(x)^T\phi(x')</script><p>上面是核函数的定义。$\phi(x)$是基函数（basis function ）。</p><p>通俗理解就是定义了这样的一组两个基函数的內积，<strong>核函数的类型以及是否线性取决于基函数的形式</strong>，比如当$\phi(x) = x$时，它就是一线性核，此时的核函数就是$k(x,x’) = x^Tx’$.而当基函数是其他形式的时候 ，情况就不同了。当基函数是高斯基函数的时候，得到的就是一个高斯核。另外定义两个类型的核函数：</p><p>静态核函数：当$k(x,x’)= k(x-x’)$是这种形式时，通过核函数映射不改变它的输入空间，这样的核函数叫做静态核函数。</p><p>径向基函数（radial basis function）：当$k(x,x’) = k(||x-x’||)$是种形式时，即核函数之和两个变量之间的距离有关，这样的核函数称为径向基函数。</p><p>我们来简单讨论一下为什么一个线性决策函数能够转化为核函数。</p><p>对于一个最简单的线性决策函数</p><script type="math/tex; mode=display">y(x) = w\phi(x)</script><p>w是我们待求的参数向量，但是根据最小二乘所求的参数表示</p><script type="math/tex; mode=display">w = (\phi(x)^T\phi(x))^{-1}\phi(x)^Ty</script><p>可以w是一个只跟$\phi(x)$和target有关的向量。按照我们定义的核函数的形式，既然w就是一个基函数和标签的表示，我们可以想象，我们是否可以将我们的w用我们定义的核函数形式来替换表示呢?经过一系列的论证，发现这个是可以做到的，也就是说我们可以将一个以w为待求参数的决策函数转变为一个没有参数变量的决策函数，或者说参数变量的本质就存在与我们的训练数据之中，我们只是用数值向量的形式把它表示出来了而已，如果我们溯本清源，将参数变量仍有训练数据表示，那么就可以得到一个由我们定义的核函数来表示的这样一个决策函数，这个决策函数最大的特征就是用到了所有的训练数据，这是一种算法思想上的变化，因为之前我们的方法是用训练数据求出一个具体的参数，然后就把训练数据丢了。</p><h4 id="核函数的优点："><a href="#核函数的优点：" class="headerlink" title="核函数的优点："></a>核函数的优点：</h4><p>“However, the advantage of the dual formulation, as we shall see, is that it is expressed entirely in terms of the kernel function k(x, x). We can therefore work directly in terms of kernels and avoid the explicit introduction of the feature vector φ(x), which allows us implicitly to use feature spaces of high, even infinite, dimensionality</p><p>”</p><p>我们可以避开特征空间的限制，直接使用核函数，也就是说无论原始的特征空间是多大，都没关系，我们可以通过一个核函数将其甚至映射到无限大的特征空间，都不会改变我们的结果。</p><h4 id="构建一个核函数需要注意那些地方"><a href="#构建一个核函数需要注意那些地方" class="headerlink" title="构建一个核函数需要注意那些地方"></a>构建一个核函数需要注意那些地方</h4><p>1、一个核函数$k(x,x’)$是关于x和x’的函数，这样的函数有个特性，就是可以通过变化转换成基函数映射的形式,也就是$k(x,x’) = \phi(x)^T\phi(x)$的形式，$\phi(x)$本质是一个映射函数，就是将x映射到更高维度的与x相关的空间比方说$(x,x^2,x^3)$. 总之一句话，我们构建的核函数一定要能转化成经基函数映射后的內积形式。</p><p>2、要满足上述的要求，有一个替代检测方法，就是检查格拉姆矩阵$K$是否半正定。$K$是一个由元素$k(x_m.x_m)$构成的向量。</p><p>3、可以在一些核函数的基础上进行扩展，比如k1和k2是两个有效的核函数，那么有以下的一些性质可以利用</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一句话概括机器学习&quot;&gt;&lt;a href=&quot;#一句话概括机器学习&quot; class=&quot;headerlink&quot; title=&quot;一句话概括机器学习&quot;&gt;&lt;/a&gt;一句话概括机器学习&lt;/h3&gt;&lt;p&gt;从数据出发，假设存在一个映射f（x） = y，学习器的任务就是从样本的假设空间里面找
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/"/>
    
      <category term="线性模型" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
    
      <category term="ML" scheme="https://qingfengbangzuo.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>EM算法的理解</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/EM%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB/EM%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC/</id>
    <published>2020-06-11T16:00:00.000Z</published>
    <updated>2020-06-12T10:56:56.465Z</updated>
    
    <content type="html"><![CDATA[<p>EM算法推导：</p><script type="math/tex; mode=display">\begin{align}&if \quad f''(x)>0\quad (f是严格凸的)\\&then \quad E[f(x)]=f(Ex)   <==>x = Ex\\&if \quad f(Ex)\geq E[f(x)]\end{align}</script><p>有Jensen不等式：</p><p>f是凸函数，令x为随机变量，有</p><script type="math/tex; mode=display">f(Ex)\leq E[f(x)]</script><p>假设拥有模型$P(x,z;\theta)$, 和数据集$D=\{x_1,x_2…x_m\}$,目标是最大化对数似然：</p><script type="math/tex; mode=display">\begin{align}L(\theta)=&\sum_{i=1}^m logP(x^{(i)};\theta)=\sum_{i=1}^m log\sum_{z^{(i)}}P(x^{(i)},z^{(i)};\theta)\\=&\sum_{i=1}^m log\sum_{z^{(i)}}[Q(z^{(i)})\frac{P(x^{(i)},z^{(i)};\theta)}{Q(z^{(i)})}]\\=&\sum_{i=1}^mlogE[\frac{P(x^{(i)},z^{(i)};\theta)}{Q(z^{(i)})}]\\\geq& \sum_{i=1}^mE[log\frac{P(x^{(i)},z^{(i)};\theta)}{Q(z^{(i)}}]\\=&\sum_{i=1}^m\sum_{z^{(i)}}Q(z^{(i)})log\frac{P(x^{(i)},z^{(i)};\theta)}{Q(z^{(i)})}\end{align}</script><p>我们希望找到一个$z^{(i)}$的分布函数$Q（z^{(i)}）$使得$\frac{P(x^{(i)},z^{(i)};\theta)}{Q(z^{(i)})}$为一个常数，且$\sum_{i=1}^mQ(z^{(i)})=1$.</p><p>我们令$Q(z^{(i)}=\frac{P(x^{(i)},z^{(i)};\theta)}{\sum_{z^{(i)}}P(x^{(i)},z^{(i)};\theta)}=\frac{P(x^{(i)},z^{(i)};\theta)}{P(x^{(i)};\theta)}=P(z^{(i)}|x^{(i)};\theta)$.就得到了我们的EM算法。</p><p>算法的第一步：令</p><script type="math/tex; mode=display">Q(z^{(i)}=\frac{P(x^{(i)},z^{(i)};\theta)}{\sum_{z^{(i)}}P(x^{(i)},z^{(i)};\theta)}=\frac{P(x^{(i)},z^{(i)};\theta)}{P(x^{(i)};\theta)}=P(z^{(i)}|x^{(i)};\theta)</script><p>第二步：</p><p>$\theta := argmax_{\theta}\sum_i\sum_{z^{(i)}}Q(z^{(i)})log\frac{P(x^{(i)},z^{(i)};\theta)}{Q(z^{(i)})}$.</p><p>以上就是EM算法的一般形式。</p><p>另一种理解EM算法的方式：</p><script type="math/tex; mode=display">J(\mathbf{\theta},Q) = \sum_i \sum_{(z^{(i)})}Q(z^{(i)})log\frac{P(x^{(i)},z^{(i)},\theta)}{Q(z^{(i)})}\\L(\theta)\geq J(\theta,Q)</script><p>EM:</p><p>E-step:   maximize    wt   Q</p><p>M-step:   maximize      wt   $\theta$</p><p>这是为什么$J(\theta,Q)$函数会收敛到的原因。</p><ul><li><h2 id="将EM算法用到混合高斯分布"><a href="#将EM算法用到混合高斯分布" class="headerlink" title="将EM算法用到混合高斯分布"></a>将EM算法用到混合高斯分布</h2></li></ul><p>  对于混合高斯分布，</p><script type="math/tex; mode=display">  PM(x) =  \sum_{(i=1)}^ka_i·p(x|\mu_i,\Sigma_i)\\  p(x|\mu_i,\Sigma_i) = \frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}e^{-\frac{1}{2}(x-\mu)^T \Sigma^{-1}(x-\mu)}</script><p>  由EM算法可知：</p><p>  E-step:</p><script type="math/tex; mode=display">  w_{ji}=Q(z^{(i)}=j)=p(z^{(i)}=j|x^{(i)},\phi,\mu,\Sigma)\\  =\frac{p(x^{(i)}|z^{(i)}=j)p(z^{(i)}=j)}{\sum_{j}^kp(x^{(i)}|z^{(i)}=j)p(z^{(i)}=j)}\\  =\frac{p(x^{(i)}|\mu_i,\Sigma_i)p(z^{(i)})}{PM(x^{(i)})}</script><p>  M-step:</p><script type="math/tex; mode=display">  max_{\phi,\mu,\Sigma}\sum_i\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{p(x^{(i)},z^{(i)},\phi,\mu,\Sigma)}{Q_i(z^{(i)})}\\</script><p>  将高斯分布和$w_ji$带入且对这个似然函数求导置零，可得各变量等式。</p><script type="math/tex; mode=display">  \mu_i = \frac{\sum_{j=1}^mw_{ji}x_j}{\sum_{j=1}^mw_{ji}}\\  \Sigma_i= \frac{\sum_{j=1}^mw_{ji}(x_j-\mu_i)(x_j-u_i)^T}{\sum_{j=1}^mw_{ji}}\\  a_i = \frac{1}{m}\sum_{j=1}^mw_{ji}</script><p>  即每个高斯成分的混合系数由样本属于该成分的平均后验概率确定。</p><ul><li><h2 id="将EM运用到混合纯贝叶斯"><a href="#将EM运用到混合纯贝叶斯" class="headerlink" title="将EM运用到混合纯贝叶斯"></a>将EM运用到混合纯贝叶斯</h2><p>以文本处理为例</p><p>规定样本$x_j^{(i)} \in \{0,1\}$,表示单词$x_i$是否出现在邮件中，隐含随机变量$z_i \in \{0,1\}$表示样本的类别，很明显$z^{(i)} \sim Bornulli（\phi）$</p></li></ul><script type="math/tex; mode=display">\begin{align}P(x^{(i)}|z^{(i)}) &= \prod_{i=1}^nP(x_j^{(i)}|z_i)\\P(x_j^{(i)}|z^{(i)}=1)&=\phi_{j|z}\\P(z^{(i)}=1)&=\phi\end{align}</script><p>在EM算法的第一步：</p><script type="math/tex; mode=display">\begin{align}w^{(i)} = P(z^{(i)}|x^{(i)},\phi_{j|z},\phi)\end{align}</script><p>M-step:</p><script type="math/tex; mode=display">\begin{align}\phi_{j|z=1} &= \frac{\sum_{i=1}^m w^{(i)})\mathbf{1}\{x_j^{(i)}=1\}}{\sum_{i=1}^m w^{(i)}}\\\phi_{j|z=0}&=\frac{\sum_{i=1}^m (1-w^{(i)})\mathbf{1}\{x_j^{(i)}=1\}}{\sum_{i=1}^m(1-w^{(i)}) }\\\phi_z&=\frac{\sum_i^m w^{(i)}}{m}\end{align}</script><p>以上两个例子都显示出，隐含随机变量 $z^{(i)}$的先验分布等于其后验分布的均值。</p><p>EM算法是一种常用的估计参数隐变量的算法，是一种非梯度优化的方法。当只有观测变量没有隐变量的时候，直接用最大似然估计就可以了，当估计函数中存在隐变量的时候，可以考虑使用EM算法。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;EM算法推导：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\begin{align}
&amp;if \quad f&#39;&#39;(x)&gt;0\quad (f是严格凸的)\\
&amp;then \quad E[f(x)]=f(Ex)   &lt;==&gt;x = E
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/"/>
    
      <category term="概率统计模型" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B/"/>
    
    
      <category term="ML" scheme="https://qingfengbangzuo.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>Adaboost</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/Adaboost/AdaBoost/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/Adaboost/AdaBoost/</id>
    <published>2020-06-11T16:00:00.000Z</published>
    <updated>2020-06-12T10:54:27.471Z</updated>
    
    <content type="html"><![CDATA[<p>周志华关于AdaBoost的讲座对理解AdaBoost的前世今生很有帮助。B站上可以搜到相关视屏。</p><p>AdaBoost 源于Kearns 和 Valiant的一个提问，强可学习 是否等价于  弱可学习 ？</p><p>在概率近似正确（Probably Approximately correct ,PAC）的框架下，一个概念如果存在一个多项式的学习算法能够学习它，并且正确率很高，那么就称这个概念是强可学习的，若果存在一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测略好，那么就成这个概念是弱可学习的。</p><p>Schapire证明强可学习与弱可学习是等价的，也即是说，在PAC学习的框架下，一个概念是强可学习的充分必要条件是这个概念是弱可学习的。这是一个非常有启发的证明，并且据周志华介绍，当时Schapire不仅给出了理论证明，也指出了具体的实现思路。因为，一般来讲，得到一个弱学习器的代价是相比较小的，由于上面理论的成立，我们可以根据某种方式，将弱学习提升称为强学习器，因为他们是等价的。</p><p>在这个理论成立的前提下，Freund和Schapire于1995年提出AdaBoost.提升树由Friedman于2000年提出。</p><h3 id="常见损失函数"><a href="#常见损失函数" class="headerlink" title="常见损失函数"></a>常见损失函数</h3><p>对于机器学习爱好者，一定要知道这几种损失函数是什么</p><ol><li><p>0-1损失函数</p><script type="math/tex; mode=display">L(y, f(x)) = \begin{cases} 1, &  {y \neq f(x) } \\ 0, & {y = f(x)} \end{cases}</script></li><li><p>平方损失函数</p><script type="math/tex; mode=display">L(y, f(x)) = (y - f(x))^2</script></li><li><p>对数损失函数</p><script type="math/tex; mode=display">L(y, p(y|x)) = - \log p(y|x)</script></li><li><p>绝对值损失函数</p><script type="math/tex; mode=display">L(y, f(x)) = | y -f(x) |</script></li><li><p>Hinge loss</p><script type="math/tex; mode=display">L(w,b) = max \{0, 1-yf(x) \}</script><p>当SVM使用线性核的时候，使用该损失函数。 </p></li></ol><h3 id="AdaBoost-M1"><a href="#AdaBoost-M1" class="headerlink" title="AdaBoost M1"></a>AdaBoost M1</h3><hr><ol><li><p>Initializa the observation weights $w_i = 1/N, i =1,2,…,N.$</p></li><li><p>For $m=1$to M:</p><p>(a) Fit a classifier $G_m(x)$ to the training data using weights $w_i$. </p><p>(b) Compute</p><script type="math/tex; mode=display">err_m = \frac{\sum_{i=1}^Nw_i\mathbf{I}(y_i\ne G_m(x_i))}{\sum_{i=1}^Nw_i}</script><p>(c) Compute $a_m = log((1-err_m)/err_mm)$.</p><p>(d) Set $w_i &lt;- w_i<em>exp[a_m</em>\mathbf{I}(y_i \ne G_m(x_i))],i= 1,2,…,N$</p></li><li><p>Output $G(x) = sign[\sum_{m=1}^Ma_mG_m(x)]$.</p></li></ol><hr><p>以上就是1997年 Freund 和Schapire提出的AdaBoost M1算法。可以看得出该算法精简巧妙，令人惊叹。</p><p>但是学术界对该算法有多种推导方式，其中被广泛接受的是Friedman于2000年提出的AdaBoost是一种 <strong>”基于加性模型的最小化指数损失函数的前向分布算法”</strong>。</p><p>西瓜书和李航书给出的AdaBoost具体算法为</p><hr><p>输入： 训练数据集$ D = \{(x_1,y_1),(x_2,y_2),…,(x_m,y_m)\}$</p><p>​         基学习算法G；</p><p>​         训练轮数T。</p><p>过程：</p><ol><li><p>$D_1(x) = \frac{1}{m}$</p></li><li><p>for t = 1,2,…T do</p><p>$h_t = G(D,D_t)$</p><p>$\varepsilon_t = P_{x~D_t}(h_t(x)\ne f(x))$</p><p>if $\varepsilon &gt; 0.5$ then break</p><p>$a_t = \frac{1}{2}ln(\frac{1-\varepsilon_t}{\varepsilon})$;</p><p>$D_{t+1}(x) = \frac{D_t(x)}{Z_t}* \begin{cases} exp(-a_t), &amp; if \quad h_t(x) = f(x) \\ exp(a_t), &amp; if \quad  h_t(x)\ne f(x) \end{cases}$</p><p>​                = $\frac{D_t(x)exp(-a_tf(x)h_t(x))}{Z_t}$</p><ol><li>end for</li></ol></li></ol><p>输出:  $H(x) = sign(\sum_{t=1}^Ta_th_t(x))$</p><hr><p>上述两种算法是等价的。</p><p>Boosting的核心理念是先从初始训练集训练出一个基学习器，然后根据基学习器的表现对数据分布进行调整，使得先前的基学习器做错的训练样本在后续收到更多关注，然后基于调整后的样本分布来训练下一个基学习器，如此重复进行，直至基学习器达到预先指定的某个指标，最终将这T个基学习器加权结合。</p><p>AdaBoot的基本思想和上面介绍的差不多。这类方法被称为串行提升，就像流水线一样是一个串一个地不断改进。</p><p>关于AdaBoost，需要解决两个问题，</p><p>第一：如何更新数据的分布，也就是样本的权重？</p><p>第二：如何确定基学习器结合的权重？</p><p>任何一本教材几乎都会给出AdaBoost详细的推导过程，M1版本的算法已经给出了更新公式。这里我想把这些思路理一理，祈求能够得到一条清楚的逻辑。</p><p>根据Friedman的解释，AdaBoost可以理解为一种<strong>以最小化指数损失函数的前向分布的加性模型。</strong>关于加性模型以及前向分布算法，下面的算法步骤大可帮助理解：</p><hr><p><strong>Forward Stagewise Additive Modeling</strong></p><ol><li><p>Initialize   $f_0(x) = 0$</p></li><li><p>For m =1 to M:</p><p>(a) Compute </p><script type="math/tex; mode=display">(\beta_m,\gamma_m) = argmin_{\beta,\gamma}\sum_{i=1}^NL(y_i,f_{m-1}(x_i)+\beta b(x_i;\gamma))</script><p>(b) Set $f_m(x) = f_{m-1}(x)+\beta b(x_i;\gamma))$</p></li></ol><hr><p>根据上面的模型，我们可以写出AdaBoost的优化目标，也就是最小化损失函数：</p><script type="math/tex; mode=display">min_{\{\beta_m,\gamma_m\}} \sum_{i=1}^NL(y_i.\sum_{m=1}^M\beta_m b(x_i;\gamma_m))</script><p>根据前向分布算法，$\sum_{m=1}^M\beta_m b(x_i;\gamma_m) = f_{m-1}(x_i)+\beta_m b(x_i;\gamma_m)$.</p><p>到这里只是形式化的表示出了损失函数，但并没有给出真正使用哪一种损失函数，常见的损失函数已经在上面列出。</p><p>那为什么就一定是指数损失函数呢？</p><script type="math/tex; mode=display">L(y,f(x)) = exp(-yf(x))</script><p>由于Friedman对算法给出了解释，大概是说假设采用指数损失函数，那么推导出来的权重更新公式正好和AdaBoost M1 差不多。由此可以认为损失函数是指数的。</p><p>下面我们来看一下，在指数损失函数这个假设下，都能得出一些什么有意思的结论。、</p><p>假设损失函数是指数损失，那么原优化目标为</p><script type="math/tex; mode=display">min_HL_{exp}(H|D) = \mathbb{E}_{x~D}[e^{-f(x)H(x)}]</script><p>考虑$L（H|D）$对$H(x)$的偏导得：</p><script type="math/tex; mode=display">H(x) = \frac{1}{2}ln\frac{P(f(x) = 1|x)}{p(f(x) = -1|x)}</script><p>到这里，我们得到了最优分类器为对数几率的一半。这个函数很眼熟，在逻辑回归也出现过。对它进行变形可能更好理解</p><script type="math/tex; mode=display">P(f(x)=1|x) = \frac{1}{1+e^{-2H(x)}}</script><p>这样的函数称为对数几率函数。</p><script type="math/tex; mode=display">sign(H(x)) = sign(\frac{1}{2}ln\frac{P(f(x )=1|x}{P(f(x)=-1|x)})\\=\begin{cases} 1 &P(f(x)=1|x )\\-1 &P(f(x)=-1|x)\end{cases}</script><p>也就是说，它分类错误率上，和逻辑回归一样，AdaBoost也能达到贝叶斯最优错误率。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;周志华关于AdaBoost的讲座对理解AdaBoost的前世今生很有帮助。B站上可以搜到相关视屏。&lt;/p&gt;
&lt;p&gt;AdaBoost 源于Kearns 和 Valiant的一个提问，强可学习 是否等价于  弱可学习 ？&lt;/p&gt;
&lt;p&gt;在概率近似正确（Probably Appr
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/"/>
    
      <category term="集成模型" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/%E9%9B%86%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
    
      <category term="ML" scheme="https://qingfengbangzuo.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>基于GBDT的算法</title>
    <link href="https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/xgboost,lightgbm%E5%92%8Ccatboost/"/>
    <id>https://qingfengbangzuo.github.io/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/xgboost,lightgbm%E5%92%8Ccatboost/</id>
    <published>2020-06-11T16:00:00.000Z</published>
    <updated>2020-06-22T12:24:52.914Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Xgboost"><a href="#Xgboost" class="headerlink" title="Xgboost"></a>Xgboost</h1><p>xgboost是在回归决策树的基础上经过boosting后的一种集成算法。</p><p>学习一个算法需要从以下几点入手：</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>xgboost是在原gbdt的损失函数基础上，进行了正则项加持和二次泰勒展开。</p><p>加性树：</p><script type="math/tex; mode=display">F^t(X) = \sum_{i=1}^t T_i(X) = F^{t-1}(X) + T_t(X)</script><p>前向分步算法：</p><script type="math/tex; mode=display">argmin_{T_t(X)} L(Y,F^{t-1}(X)+T_t(X))</script><p>GBDT目标函数：</p><p>​    定义回归树的数学形式，$c_m$是叶子节点的值，$R_m$是叶子节点的范围(属于该点的点的集合)。</p><script type="math/tex; mode=display">T(x_i) = \sum_{m} c_m\mathbf{1}\{x_i \in R_m\}</script><p>​    目标函数（j,s分别是最优特征和最优特征的最优分裂点）</p><script type="math/tex; mode=display">min_{j,s}  min_{c_m} [\frac{L(y_i,F^{t-1}(x_i))}{F^{t-1}(x_i)} -\sum_{m}c_m\mathbf{1}\{x_i \in R_m\}] \quad for i = 1,2,...,n(数据个数)</script><p>ＧＤＢＴ最大的特点就是利用一阶导数来近似前t-1颗树的误差，然后再用第t颗树来拟合该误差，直到达到停止条件。</p><ul><li><p>为什么要使用一阶导数来近似误差？</p><p>为了适应不同的损失函数。提升树利用加法模型和前向分布算法，当损失函数是平方损失和指数损失函数时，每一步优化是很简单的，但是对于一般损失函数而言，往往每一步优化并不那么容易。</p></li><li><p>为什么一阶负梯度可以用来近似误差？</p><p>对于任何损失函数$L(y_i,F^{t-1}(x_i)＋f_t(x_i))$，若将其视为一个关于$F^{t-1}(x_i)$的函数，我们的目标是最小化该损失函数。那么我们沿着该损失函数的梯度下降可能是一个不错的选择。我们所说的用第t颗树去拟合前t-1颗树的误差是在损失函数为rmse的语境下成立的，若果是其他的损失函数，用梯度来拟合误差不是很恰当，此时可以理解为采用梯度下降来最小化损失函数。</p></li><li><p>注意一点：引入梯度会造成累积误差。</p></li></ul><p>xgboost目标函数：</p><script type="math/tex; mode=display">\sum_{i=1}^nL(y_i,F^{t}(x_i)) + \sum_{k=1}^t \Omega(f_k) \\where \quad\Omega(f) = \gamma T+\frac{1}{2}\lambda||w||^2</script><p>前向分步版本：</p><script type="math/tex; mode=display">L^{(t)} = \sum_{i=1}^n L(y_i,F^{t-1}(x_i)+T_t(x_i))+\Omega(T_t)</script><p>进行２阶泰勒展开</p><script type="math/tex; mode=display">L^{(t)} \simeq \sum_{i=1}^n[L(y_i,F^{t-1}(x_i))+g_iT_t(x_i)+\frac{1}{2}h_iT_t^2(x_i)]+\Omega(T_t)</script><p>这里的g和h分别是损失函数对$F^{t-1}(x_i)$的一阶导和二阶导。</p><p>将树模型数学表达式和正则化项带入后可以得到：</p><script type="math/tex; mode=display">\tilde{L}^{t} =\sum_{i=1}^n[g_iT_t(x_i)+\frac{1}{2}h_iT_t^2(x_i)]+\gamma T+\frac{1}{2}\lambda\sum_{j=1}^Tw_j^2 \\=\sum_{j=1}^T[(\sum_{i\in I_j}g_i)w_j+\frac{1}{2}(\sum_{i\in I_j}h_i+\lambda )w_j^2]+\gamma T　＋const</script><p>$T$指的是共有多少个叶子节点，$I_j$指的是每个叶子节点的范围。这个式子的意思表达的是，将所有属于$I_i$叶子内的所有点的一阶梯度和二阶梯度都加起来，使得构成一个关于$w_j$的二次函数。</p><p>注意：上面的式子假设我们已经知道了第t颗树的结构。</p><p>当我们已知第t颗树的结构时，我们可以根据上面式子，求解最优的$w_j^*$</p><script type="math/tex; mode=display">w_j^* = -\frac{\sum_{i\in I_j}g_i}{\sum_{i \in I_j}h_i+\lambda}</script><p>带入原式子可以得到：</p><script type="math/tex; mode=display">\tilde{L}^{(t)}(q) = -\frac{1}{2}\sum_{j=1}^T\frac{(\sum_{i\in I_j}g_i)^2}{\sum_{i \in I_j}h_i+\lambda} + \gamma T</script><p>我们定义该式子为<strong>结构分</strong>。该式子可以用来计算任意叶子$i\in I_j$结构分.</p><p>那么分裂点的增益就可以通过结构分来计算了：</p><script type="math/tex; mode=display">\frac{1}{2}[\sum_{j=1}^T\frac{(\sum_{i\in I_L}g_i)^2}{\sum_{i \in I_L}h_i+\lambda} +\sum_{j=1}^T\frac{(\sum_{i\in I_R}g_i)^2}{\sum_{i \in I_R}h_i+\lambda}-\sum_{j=1}^T\frac{(\sum_{i\in I}g_i)^2}{\sum_{i \in I}h_i+\lambda}]- \gamma</script><p>至此，我们已经通过xgboost的目标函数得到了结构分，结构分的作用是计算分裂收益。注意得出结构分的前提依然是最小化目标函数，我们是在这个前提下推出结构分的，我们的目标依然是最小化目标函数，这点和GBDT一样，结构分只是告诉我们，当我们构建新树的时候，使用这样的结构分去构建，能够让目标函数下降的更快。</p><ul><li><p>怎样理解GBDT和xgboost目标函数的不同？</p><p>GBDT是利用变量沿梯度方向下降最快这个思想去最小化目标函数。是把$F^{t-1}＋T_t$当做一个变量，当这个变量沿着负梯度方向变化时，目标函数下降的最快。</p><p>xgboost对目标函数的解读方式不同，它将$T_t$视为一个变量，然后将目标函数进行泰勒展开。分析出了$T_t$进行怎么样的取值能够让目标函数最小。分析的结果其实挺简单，给我一个$T_t$值，我算出该值下的近似目标函数大小，然后比较哪个小，我就取哪个$T_t$，只不过变量$T_t$是一颗树，而不是一个单变量，因此需要进行分裂。</p><p>解读目标函数的方式不同。</p></li><li><p>为什么说GBDT树不如xgboost树好？</p><p>发生这种情况的原因之一是xgboost加了正则项。第二个原因是xgboost加入了列采样，三是使用了二阶导数信息。四是支持缺失值处理。五是并行支持效果要更好。</p><p>自己琢磨了两个原因：第一个还是对目标函数的解读。GBDT是用树去拟合一阶梯度。而xgboost是直接使用树取寻找使得目标函数最小的值，也就是说理想情况下xgboost的树能找到当前目标函数的近似最优点。而沿着梯度下降不一定。这个更好也表现在对树分裂时的约束更好。而且，假如每次迭代都是近似最优的树，那么第二种的收敛速度也更快。</p><p>第二个原因是受到了网上一篇帖子的启发。我们首先分清出目标函数和打分函数的区别，GBDT和xgboost的目标函数相差一个正则项，对于GBDT打分函数就是(g’-T)^2，而xgboost的打分函数是结构分（往上翻）。xgboost的打分函数使用了２阶信息，还是对树的约束比GBDT要好，因此收敛要快。</p><p>在catboost的论文中看到，无论是用使用一阶负梯度还是使用Newton method近似，原则都是某种梯度下降。从这个角度看，使用二阶梯度下降速度果然要快一点。</p></li></ul><h3 id="树分裂过程"><a href="#树分裂过程" class="headerlink" title="树分裂过程"></a>树分裂过程</h3><p><img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/xgboost,lightgbm%E5%92%8Ccatboost/2020-05-07 12-02-48屏幕截图.png" alt></p><p>xgboost给出的分裂方式为：笨方式，遍历所有特征的所有点，将分裂点依次设为某特征下的数据点，然后得出使得该特征收获最大分裂增益的分裂点。</p><p>较为好一点点的方法是事先对某特征下的数据分组（percentile分组），然后按组比较。这样的好处是加快了搜索的效率，而且可以部分避免过拟合。但是缺点是，效果不如笨办法精确。事实上在搜索效果上，远没有那么不堪。</p><p>分桶策略：</p><p>xgboost引入的分桶策略是这样的。</p><p>对数据集分配一个权重。该权重就是数据点的二阶导，对于第k个特征的排序数据集:$D_k = \{(x_{1,k},h_1),(x_{2,k},h_2),…,(x_{n,k},h_n)\}$.</p><p>定义一个rank函数：</p><script type="math/tex; mode=display">r_k(z) = \frac{1}{\sum_{(x,h)\in D_k}h} \sum_{(x,h)\in D_k,x<z} h</script><p>分裂点集合：$\{s_{k1},s_{k2},s_{k3},…s_{kl}\}$</p><script type="math/tex; mode=display">|r_k(s_{k,j} - r_k(s_{k,j+1}))|<\epsilon,s_{k1} = min_ix_{i,k},s_{k,l} = max_ix_{ik}</script><p>这意味这将有$1/\epsilon$个分裂点后选集。</p><p>给出的解释是：</p><p><img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/xgboost,lightgbm%E5%92%8Ccatboost/2020-05-07 12-28-23屏幕截图.png" alt></p><h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><p>xgboost支持对缺失值的处理，具体的处理思想就是将缺失值单独分一个类。具体的做法就是将除了缺失值以外的数据排序，将缺失值全部扔到右边或者左边，对应的是升序和降序操作。然后利用好排序的数据来计算分裂收益，自然分裂点也是在排好序的数据点中产生，最终的效果是将缺失值数据扔到了右边或者左边的叶子里面。</p><p>注意：这样处理其实存在一个漏洞，对于缺失值很多的特征，只用仅有的几个数据点来计算分裂收益，而忽略了大部分缺失值的贡献（缺失值没有参与到分裂过程），容易导致过拟合。catboost的做法是给缺失值赋予一个极值（9999，-9999），让缺失值也参与到分裂过程中来。这样的效果是把缺失值全部都赶到了一个叶子节点中，其余剩下的有值的数据点在一个叶子里面。这样的处理方法是将缺失值当做了单独的一个属性值，效果要稍微好点。</p><p><img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/xgboost,lightgbm%E5%92%8Ccatboost/2020-05-07 12-47-27屏幕截图.png" alt></p><ul><li><p>如何解释要从两边分别计算分割点？</p><p>从两边各走一遍，是为了决定把缺失值丢到哪边更合适一点。</p></li></ul><h3 id="防止过拟合措施"><a href="#防止过拟合措施" class="headerlink" title="防止过拟合措施"></a>防止过拟合措施</h3><p>1、shrinkage和column subsample　收缩因子和列采样。</p><p>​    收缩因子是指每一次迭代都给一个树系数，相当于学习率，避免学习太快。列采样（同样支持行采样）使用批量特征来避免过拟合。</p><p>２、剪枝策略。xgboost是先生成所有树枝，采用的是level-wise，就是每一层都并行进行分裂，生成一颗很宽的树，然后再进行自底向上剪枝。</p><p>３、经典的树避免拟合的参数都有。</p><p>４、支持不平衡的数据，通过给类别不同的权重得以实现，没有看出与其他boost方案的不同。</p><h3 id="其他的一些实现"><a href="#其他的一些实现" class="headerlink" title="其他的一些实现"></a>其他的一些实现</h3><p>Column Block for Parallel Learning</p><p>预排数据，由于需要经常排序，因此算法在训练之前就对数据进行预排，我理解的这个预排就是事先根据每个特征对数据进行排序，然后把排好序的索引存在一个block里面，然后只要涉及到排序的地方，就扫描这个block，不用重新排序。</p><p>Cache-aware Access</p><p>问题的由来：由于数据的存储不是线性的，这个主要原因是因为经常需要排序，所以读取数据的时候，磁针需要来回的挪动，导致命中率下降，这里提供了一种方案来提高磁针的命中率。</p><p>Blocks for Out-of-core Computation</p><p>当数据集超出内存大小的时候，也即是不能一次性读取进内存，设计了一种使用磁盘排序的方案。</p><h1 id="Lightgbm"><a href="#Lightgbm" class="headerlink" title="Lightgbm"></a>Lightgbm</h1><p>一开始以为lightgbm是照着xgboost去打的，看了论文以后发现并不是，论文里面只是强调了两种提升训练速度的方案: GOSS和EFB。</p><p>lightgbm和xgboost有哪些不同呢：</p><p><img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/xgboost,lightgbm%E5%92%8Ccatboost/2020-05-02 17-39-46屏幕截图.png" alt="2020-05-02 17-39-46屏幕截图"></p><p>这是lightgbm的作者给出的介绍。总体来说就是在速度以及存储量上均得到了提高。有两点不同需要引起注意：</p><ul><li><p>树生长策略的不同，xgboost的生长策略是level-wise而lightgbm的树生长策略是leaf-wise。level-wise是指在树分裂的时候每一层同时进行分裂，是以曾为主导。这样做的好处是方便并行化，应该是并行的通信开销比较小吧。毕竟彼此的分裂都是互不相干的。坏处是，对于那些分裂增益已经很小的叶子，在以层为主导的分裂策略下，也会跟着被分裂，最后再被剪枝，显然这样是低效率的。</p><p>leaf-wise的分裂方式是这样的，在每一次分裂的时候，比较当前所有叶子节点，选择能够使得分裂增益最大的那个叶子节点进行分裂。这样可以避免上述level-wise的缺点，提升效率。</p></li><li><p>histogram算法</p><p>这里对比的是xgboost的预排序算法。lightgbm的作者认为，由于xgboost的数据的存储方式是非线性的，即使进行了预排序，那么无论是在存储上还是在扫描效率上仍然是不尽人意的。histogram算法可以提升这方面的效率。<img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/xgboost,lightgbm%E5%92%8Ccatboost/2020-05-02 17-50-30屏幕截图.png" alt="2020-05-02 17-50-30屏幕截图"></p></li></ul><p>算法的思想大体如下：</p><p>１、遍历当前树的所有叶子节点。</p><p>２、遍历每个叶子节点的每个特征，对每个特征建立histogram.</p><p>3、分桶策略，通过超参数指定桶的个数，bin_max. min(bin_max,len(特征j))，当特征值的取值个数小于超参指定的值时,对每一个特征值进行分桶。分桶依据没看到，盲猜可能是xgboost的分桶标准（使用2阶导作为权重）。</p><p>４、把数据装桶（不需要排序），计算桶内的一阶导数和二阶导和。</p><p>５、以桶序号指代数据，然后遍历分桶，找到最佳的分裂点。</p><p>这里用到的主要思想是用histogram来代替原始数据，将原始数据的index映射到了相应的桶内，这样做的好处有几个：</p><p>​    - 避免了排序，这样读取数据的时候就是线性的了。</p><p>​    - 它将我们需要的梯度和单独保存了起来，单个hist所需要的空间用１个字节就可以了。（对比预排所需要的空间）减小了８倍</p><p>​    - 分裂搜索的时候用的是桶序，而不是原始数据序，因此搜索范围要小的多，速度提升。</p><p>​    - 分桶虽然可能会导致找到的分裂点不是最优的，但是理论和实际都表示分桶达到一定数量对性能的影响微乎其微。</p><ul><li><p>Need only <code>O(2 * #non_zero_data)</code> to construct histogram for sparse features</p></li><li><p>对于类别特征进行了优化</p><p>传统的对待类别特征的方法是进行one-hot编码，但是这样做对于树模型来讲有些缺点：</p><p>It is common to represent categorical features with one-hot encoding, but this approach is suboptimal for tree learners. Particularly for high-cardinality categorical features, a tree built on one-hot features tends to be unbalanced and needs to grow very deep to achieve good accuracy.</p><p>意思大致就是这个方案对于基数稍微高点的特征是不友好的，会造成数据不平衡并且会导致树越来越深。</p><p>lightgbm对此进行了优化，不再使用one-hot编码，而是对特征值进行排序，至于排序的标准则是(<code>sum_gradient / sum_hessian</code> ?)虽然不知道为什么要这样排，但是经过排序后的复杂度会变低（原最优分裂的时候是2^(k-1)-1,经过排序以后的复杂度变为了k*log(k)）。</p><p>The basic idea is to sort the categories according to the training objective at each split. More specifically, LightGBM sorts the histogram (for a categorical feature) according to its accumulated values (<code>sum_gradient / sum_hessian</code>) and then finds the best split on the sorted histogram. </p></li><li><p>再有一些优化就是并行方面的了：特征并行，数据并行，Voting Parallel。（看官方解读吧）</p></li></ul><h1 id="Catboost"><a href="#Catboost" class="headerlink" title="Catboost"></a>Catboost</h1><p>catboost完全指南  - 知乎（解读的不错） <a href="https://zhuanlan.zhihu.com/p/102570430" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/102570430</a>　</p><h3 id="对该基数类别特征的处理"><a href="#对该基数类别特征的处理" class="headerlink" title="对该基数类别特征的处理"></a>对该基数类别特征的处理</h3><p>这个写起来好长，不过当增强一遍记忆吧。</p><p><strong>Target statistics</strong></p><p>目标编码的思路很简单，就是将特征值映射为对应类别的期望。</p><script type="math/tex; mode=display">\hat{x}_K^i = E(y|x^i == x_k^i)</script><p>i表示第i个特征，k表示第k个特征值。</p><p>特别是对那些对应样本少的特征值不友好。</p><p><strong>Greedy　TS</strong></p><script type="math/tex; mode=display">\hat{x}_k^i = \frac{\sum_{j=1}^n \mathbf{1}\{x_j^i=x_k^i\}y_i+ap}{\sum_{j=1}^n \mathbf{1}\{x_j^i =x_k^i\}+a}</script><p>where a &gt; 0 is a parameter. A common setting for p is the average target value in the dataset. (对于二分类来说就是y先验)</p><p>这样编码容易发生leaky。</p><p><strong>Holdout TS</strong></p><p>思想就是将数据集进行分割，利用一部分数据集进行greedy TS编码，剩下的一部分用于训练，但这样会导致训练集不够用。</p><p><strong>Leave-one-out TS</strong></p><p>留一法编码。原文是这样说的</p><p>At first glance, a leave-one-out technique might work well: take $D _k = D/x_k$for training examples $x_k$  and $D_k = D$ for test ones.</p><p>翻译没错的话就是，利用x_k训练，其余为测试集。</p><script type="math/tex; mode=display">\bar{x}_k^i = \frac{n^+-y_k+\alpha p}{n-1+\alpha}</script><p>但这样仍然有问题，对于特征$x_k^i = A$ for all samples(这里想表达的意思是对于所有的样本，该特征取值都为Ａ)，$n^+$表示y=1的样本个数，那么$t=\frac{n^+-0.5+\alpha p}{n-1+\alpha}$,可以将其二分，所以依然存在泄露。</p><p><strong>Ordered TS</strong></p><p>ordered TS的思想是这样的，对样本进行n轮shuffle，对每一轮shuffle过得数据集，对于样本$x_i$，都用前$i-1$个样本进行TS.</p><p> <a href="https://zhuanlan.zhihu.com/p/102570430" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/102570430</a>　介绍的不错。</p><p><strong>怎么样去理解这个prediction shift？</strong></p><p>文章谈到，训练数据的$g^t(x_k,y)|x_k$偏移了$g^t(x,y)|x$.我理解的原因是，对于训练数据点$x_k$，这个梯度$g^t(x_k,y_k)$本身在训练的时候就已经利用了数据$x_k,y_k$的信息，因为每棵树的构建都使用了全部的数据。而对于测试集而言，对于数据点$x$，它的梯度$g^t(x,y)$在构建树的过程中没有用到数据点x。因此说产生了偏斜。并且作者也说了，对于ＴＳ这个偏斜产生的原因是数据泄露，正好吻合。</p><p>那么怎么去解决这个问题呢，如果构建树的过程中为了防止偏斜而不使用数据点,那么为了照顾每个数据点的偏斜，就没有数据点可用了。catboost提出了一种解决方法，大概意思就是说，对于数据点$x_k,y_k$,我使用在构建过程中使用一种替代方案。不使用点$x_k,y_k$的真实值，而是使用前k-1个数据点的对$x_k,y_k$ 的预测值.</p><p><img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/xgboost,lightgbm%E5%92%8Ccatboost/2020-05-07 18-32-27屏幕截图.png" alt="2020-05-07 18-32-27屏幕截图"></p><p>算法中的$m_i$是support function，作用是使用前i-1个样本用来预测样本$x_ｉ$的值，对于梯度boosting就是残差。对于不同的shuffle，对应了不同的$m_{r}(i)$，不过看到它的更新方式，我很怀疑他只是存储了每一轮关于样本$x_k$的残差值。注意下面算法的Model =Ordered部分。</p><p><img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/xgboost,lightgbm%E5%92%8Ccatboost/2020-05-08 09-50-23屏幕截图.png" alt="2020-05-08 09-50-23屏幕截图"></p><p>算法２是catboost树构建算法，使用的是对称树（关键词：obvious tree），这种树的特点就是树的同一层的分裂使用的是相同标准。</p><p>Term oblivious means that the same splitting criterion is used across an entire level of the　tree。</p><p><strong>如何计算最终模型的叶子节点值</strong></p><p>显然，boosting树的最终模型的叶子节点一般为</p><script type="math/tex; mode=display">\sum_{k=1}^I\sum_{j=1}^T \alpha b_j^k</script><p>$b_j^k$是叶子里面样本点的label的平均值。catboost也遵循了这样的形式，不同的是catboost在初始化的时候共shuffle了s+1次，训练的时候使用${r_1,r_2,r_3,…r_s}$，测试的时候使用$r_0$.就是说$b_{r_o,j}^k$的叶子节点是按照$r_0$序来计算的。并且对测试集类别特征编码的时候，我们使用的是全部数据集。</p><p><strong>类别特征的合并使用</strong></p><p>catboost引入了类别特征合并，而且合并方式采用greedy。特征合并就是指将特征两两合并，比方一个特征country: CN,US,UN。另一个特征music:pop,rock,rap.那么合并后就是new: CN_pop,US_rock,UN_rap.</p><p>greedy是指</p><p>Namely, for each split of atree, CatBoost combines (concatenates) all categorical features (and their combinations) already used<br>for previous splits in the current tree with all categorical features in the dataset. Combinations are　converted to TS on the fly.</p><p><strong>其他需要注意的地方</strong></p><p>使用了贝叶斯采样，避免过拟合。对于问题：对于每个shuffle靠前的几个样本，预测他们的时候由于使用的样本过少，容易产生高方差。解决方法是在计算损失的时候，倾向于丢掉前几个样本的梯度。</p><p>进行优化过得catboost算法以及buildtree</p><p><img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/xgboost,lightgbm%E5%92%8Ccatboost/2020-05-08 10-18-30屏幕截图.png" alt="2020-05-08 10-18-30屏幕截图"></p><p><img src="/2020/06/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/xgboost,lightgbm%E5%92%8Ccatboost/2020-05-08 10-18-43屏幕截图.png" alt="2020-05-08 10-18-43屏幕截图"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Xgboost&quot;&gt;&lt;a href=&quot;#Xgboost&quot; class=&quot;headerlink&quot; title=&quot;Xgboost&quot;&gt;&lt;/a&gt;Xgboost&lt;/h1&gt;&lt;p&gt;xgboost是在回归决策树的基础上经过boosting后的一种集成算法。&lt;/p&gt;
&lt;p&gt;学习一个算
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/"/>
    
      <category term="树类算法" scheme="https://qingfengbangzuo.github.io/categories/Machine-Learning/%E6%A0%91%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="ML" scheme="https://qingfengbangzuo.github.io/tags/ML/"/>
    
  </entry>
  
</feed>
