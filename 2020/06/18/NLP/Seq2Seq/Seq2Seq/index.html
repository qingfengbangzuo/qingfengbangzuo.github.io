<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="NLP," />





  <link rel="alternate" href="/atom.xml" title="Qingfengbangzuo" type="application/atom+xml" />






<meta name="description" content="序列生成模型一个序列生成模型一般要满足这样的假设： 当前值$t_i$的分布依赖于之前$1:t_{i-1}$个词。即$P(t_i|t_{1:i-1})$,在每一步中，得到当前值得分布，即得到$P(t_i&#x3D;k|t_{1:i-1})$的概率值，然后将当前值作为预测下一个值得已知条件。 RNN满足序列生成模型的形式：  当RNN作为transducer时，只需将时间步t时刻的输出连接到时间步t+1时的输入">
<meta property="og:type" content="article">
<meta property="og:title" content="Seq2Seq">
<meta property="og:url" content="https://qingfengbangzuo.github.io/2020/06/18/NLP/Seq2Seq/Seq2Seq/index.html">
<meta property="og:site_name" content="Qingfengbangzuo">
<meta property="og:description" content="序列生成模型一个序列生成模型一般要满足这样的假设： 当前值$t_i$的分布依赖于之前$1:t_{i-1}$个词。即$P(t_i|t_{1:i-1})$,在每一步中，得到当前值得分布，即得到$P(t_i&#x3D;k|t_{1:i-1})$的概率值，然后将当前值作为预测下一个值得已知条件。 RNN满足序列生成模型的形式：  当RNN作为transducer时，只需将时间步t时刻的输出连接到时间步t+1时的输入">
<meta property="og:image" content="https://qingfengbangzuo.github.io/2020/06/18/NLP/Seq2Seq/Seq2Seq/RNN_seqgenerate.PNG">
<meta property="og:image" content="https://qingfengbangzuo.github.io/2020/06/18/NLP/Seq2Seq/Seq2Seq/%E6%9D%A1%E4%BB%B6%E7%94%9F%E6%88%90%E6%A1%86%E6%9E%B6.PNG">
<meta property="og:image" content="https://qingfengbangzuo.github.io/2020/06/18/NLP/Seq2Seq/Seq2Seq/encoder-decoder.PNG">
<meta property="og:image" content="https://qingfengbangzuo.github.io/2020/06/18/NLP/Seq2Seq/Seq2Seq/encoder-decoder_loss.PNG">
<meta property="article:published_time" content="2020-06-17T16:00:00.000Z">
<meta property="article:modified_time" content="2020-06-30T01:39:30.565Z">
<meta property="article:author" content="qingfengbangzuo">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qingfengbangzuo.github.io/2020/06/18/NLP/Seq2Seq/Seq2Seq/RNN_seqgenerate.PNG">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":20,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://qingfengbangzuo.github.io/2020/06/18/NLP/Seq2Seq/Seq2Seq/"/>





  <title>Seq2Seq | Qingfengbangzuo</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    
    <a href="https://your-url" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Qingfengbangzuo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">私人博客</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://qingfengbangzuo.github.io/2020/06/18/NLP/Seq2Seq/Seq2Seq/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="qingfengbangzuo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qingfengbangzuo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Seq2Seq</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-06-18T00:00:00+08:00">
                2020-06-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  8
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="序列生成模型"><a href="#序列生成模型" class="headerlink" title="序列生成模型"></a>序列生成模型</h2><p>一个序列生成模型一般要满足这样的假设：</p>
<p>当前值$t_i$的分布依赖于之前$1:t_{i-1}$个词。即$P(t_i|t_{1:i-1})$,在每一步中，得到当前值得分布，即得到$P(t_i=k|t_{1:i-1})$的概率值，然后将当前值作为预测下一个值得已知条件。</p>
<p>RNN满足序列生成模型的形式：</p>
<p><img src="/2020/06/18/NLP/Seq2Seq/Seq2Seq/RNN_seqgenerate.PNG" alt="RNN_seqgenerate"></p>
<p>当RNN作为transducer时，只需将时间步t时刻的输出连接到时间步t+1时的输入即可。在训练过程中，每轮训练开始都给予一个初始字符$<s>$,遇到结束字符$</s>$时结束。在时间步$t$时，输入有$s_{t-1}$和$y_{t-1}$，$s_{t-1}$是之前$t-1$个词的编码，$y_{t-1}$是上一个时间步的预测值，$P(y_t|s_{t-1},y_{t-1})$近似于使用前$t-1$个词作为条件，等同于假设$P(t_i|t_{1:t-1})$。$y_i$的结果一般为一个词分布，大小为字典长度，采用softmax来转换概率。$s_0$初始化为0，但是decoder模型中，该值被初始化为$s_0 = \delta({VC})$.</p>
<p>注：当$y_{t-1}$被当做下一时刻的输入时，该值选用$y_{t-1}$分布中概率值最大的那个值。</p>
<p><strong>teacher-forcing: </strong>是另外一种训练方法，这种训练方法和上述最大的不同在于每个时间步输入$y_{t-1}$不再是模型上一个时间步的预测结果，而是训练序列中上一个时间步对应的值，是标签。这样会导致一个现象，就是对于时间步t，它的输入$y_{t-1}$（真是的标签）在上一个时间步的预测概率很小，但是由于它是真实的标签，因此在下一时间步被作为输入。这种方式导致的后果就是，在测试集中，会出现不可预知的结果。</p>
<h2 id="Conditioned-generation-framework"><a href="#Conditioned-generation-framework" class="headerlink" title="Conditioned generation framework"></a>Conditioned generation framework</h2><p>在条件生成框架下，下一个token的产生依赖于两个，一个是过去生成的token，另一个是上下文。</p>
<script type="math/tex; mode=display">
\tilde{t}_{j+1} \approx p(t_{j+1} = k|\tilde{t}_{1:j},c)</script><p>用RNN形式表示就是：</p>
<script type="math/tex; mode=display">
p(t_{j+1}=k|\tilde{t}_{1:j},c) = f(O(s_{j+1}))\\
s_{j+1} = R{s_j,[\tilde{t_j};c]}\\
\tilde{t}_j\approx p(t_i|\tilde{t}_{1:j-1},c)</script><p>这就是条件生成框架：</p>
<p><img src="/2020/06/18/NLP/Seq2Seq/Seq2Seq/条件生成框架.PNG" alt="条件生成框架"></p>
<p>关于上下文c的解释如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">What kind of information can be encoded in the context c? Pretty much any data we can put our hands on during training, and that we find useful. For example, if we have a large corpus of news items categorized into different topics, we can treat the topic as a conditioning context. Our language model will then be able to generate texts conditioned on the topic. If we are interested in movie reviews, we can condition the generation on the genre of</span></span><br><span class="line"><span class="string">the movie, the rating of the review, and perhaps the geographic region of the author. We can then control these aspects when generating text. We can also condition on inferred properties, that we automatically extract from the text. For example, we can derive heuristics to tell us if a given sentence is written in first person, if it contains a passive-voice construction, and the level of vocabulary used in it. We can then use these aspects as conditioning context for training, and, later, for text generation.</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<p>大体意思就是说，上下文C可以是一个类别信息，比方说电影的类别，文本的话题。或者我们抽象出来的内容，比如机器翻译中输入序列的编码。</p>
<h2 id="Encoder-Decoder"><a href="#Encoder-Decoder" class="headerlink" title="Encoder-Decoder"></a>Encoder-Decoder</h2><p>encode-decoder框架是针对Seq2Seq问题提出来的,Seq2Seq是指在机器翻译、语音识别等领域需要将任意长度的输入序列转换为任意长度的输出序列。</p>
<p>RNN（LSTM\GRU）的trasnducer模式本身是符合编码解码模式的，它的输入就是一段序列，输出也是一段序列，只不过在该框架下的输入输出是对称的。</p>
<p>为了解决输入输出不对称的问题，诞生了encode-decoder框架，这个框架依托于上述描述的条件生成框架。观察上述条件生成框架，我们发现该框架本质是一个序列生成模型，而解码器的功能就是产生一个基于输入序列的转换编码。因此，基于此框架作为解码器是合理的，而条件生成框架中存在一个关于上下文的输入，这个东西可以由输入序列的编码来代替。这样逻辑上是自恰的，给定一个输入序列，编码器将其转换为合适的编码，这个编码后信息可能是句子的主题、句子的语态等等（深度学习的不可知论），依据此编码作为上下文（也可以理解为这个编码内部包含了我们需要预测的句子的指示信息或者上下文，它用于指示我们的解码器需要生成的句子需要在什么样的上下文中）可以作为生成句子的条件（约束）。</p>
<p><img src="/2020/06/18/NLP/Seq2Seq/Seq2Seq/encoder-decoder.PNG" alt="encoder-decoder"></p>
<p>编码器和解码器被绑定在一起训练，但是标签只作用于解码器，但是梯度可以经过解码器被传播回编码器。</p>
<p><img src="/2020/06/18/NLP/Seq2Seq/Seq2Seq/encoder-decoder_loss.PNG" alt="encoder-decoder_loss"></p>
<p>基本的训练框架就是上图表示的这样，编码器为一个RNN网络比如说LSTM或者GRU。</p>
<p>解码器也为一个RNN网络（LSTM、GRU、BiRNN、CNN）。</p>
<h2 id="数学解释"><a href="#数学解释" class="headerlink" title="数学解释"></a>数学解释</h2><p>对Seq2Seq建模：</p>
<script type="math/tex; mode=display">
P(Y|X) = P(y_1,y_2,y_3,...y_t|X)</script><p>$X$为输入序列，$Y$为输出序列。问题的表述为给定任意长度的输入序列，预测出一个概率最大的输出序列。</p>
<script type="math/tex; mode=display">
argmax_Y log(P(Y|X)) = argmax_Ylog(\prod_{i=1}^tP(y_i|y_{i-1},y_{i-2},...,y_1;X))\\
=argmax_Y\sum_{i=1}^tlog(P(y_i|y_{i-1},y_{i-2},...,y_1;X))</script><p>观察$P(y_i|y_{i-1},y_{i-2},…,y_1;X)$,$X$为原文输入序列，对于encoder-decoder来说，$X$可以被编码器转化为全局编码$C$.</p>
<script type="math/tex; mode=display">
C = ENC(X)</script><p>ENC为编码器，假设编码器采用LSTM，那么编码流程：</p>
<script type="math/tex; mode=display">
\begin{align}
&s_{t-1} = [c_{t-1};h_{t-1}]\\
&i_t = \delta(w^{hi}h_{t-1}+w^{x_i}x_{t})\\
&f_t = \delta(w^{hf}h_{t-1}+w^{xf}x_t)\\
&o_t = \delta(w^{ho}h_{t-1}+w^{xo}x_t)\\
&g_t = tanh(w^{hg}h_{t-1}+w^{xg}x_t)\\
& c_t = f_t \odot c_{t-1}+i_t \odot g_t\\
&h_t = o_t \odot tanh(c_t)
\end{align}</script><p>注意上面过程中的两个tanh函数的位置。</p>
<p>当遍历完整个输入序列后，得到全局编码$h_T$.此时不能将全局编码$H_T$直接扔进解码器，需要做一步转换。</p>
<script type="math/tex; mode=display">
C  = tanh(V·h_T+b_c)</script><p>这里的激活函数是tanh，有几个作用，一个作用是激活，另一个作用是将编码的值映射到x轴的两侧，这样做可以加速梯度下降，还有一个作用就是维度变换，将向量$h_T$变换成我们需要的维度。</p>
<p>此时得到的$C$可以作为上下文输入解码器了。对于解码过程</p>
<script type="math/tex; mode=display">
h_t = R(h_{t-1},y_{t-1},C)\\
y_t = softmax(O(h_t,y_{t-1},C))</script><p>另外，对于$h_0$的初始化：</p>
<script type="math/tex; mode=display">
h_0 = tanh(V^{ch}C)</script><p>这里原文是采用双向的GRU，因此对于初始状态的定义为：</p>
<script type="math/tex; mode=display">
h_0 = tanh(W_sh^b_1)</script><p>这样就可以将解码过程与序列生成模型连接起来了。</p>
<p>局限性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">encoder-decoder模型虽然非常经典，但是局限性也非常大。最大的局限性就在于编码和解码之间的唯一联系就是一个固定长度的语义向量C。也就是说，编码器要将整个序列的信息压缩进一个固定长度的向量中去。但是这样做有两个弊端，一是语义向量无法完全表示整个序列的信息，还有就是先输入的内容携带的信息会被后输入的信息稀释掉，或者说，被覆盖了。输入序列越长，这个现象就越严重。这就使得在解码的时候一开始就没有获得输入序列足够的信息， 那么解码的准确度自然也就要打个折扣了.</span></span><br><span class="line"><span class="string">https://zhuanlan.zhihu.com/p/48648001</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<h3 id="一个值得思考的问题"><a href="#一个值得思考的问题" class="headerlink" title="一个值得思考的问题"></a>一个值得思考的问题</h3><p>面对不同语言之间的语义不同的问题，模型是如何解决的？模型真的可以自动学到不同语言之间的特性么？直到目前为止，所有基于词向量的模型的特征抽取本质上都是对token统计特征的抽取，这是否是最好的词表示方式？</p>

      
    </div>
    
    
    
    
    <div>
      
        
      
    </div>

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/NLP/" rel="tag"><i class="fa fa-tag"></i>NLP</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/06/16/NLP/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/RNN%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/" rel="next" title="RNN的基本结构">
                <i class="fa fa-chevron-left"></i> RNN的基本结构
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/06/20/NLP/Seq2Seq/Attention/" rel="prev" title="Attention Mechanism">
                Attention Mechanism <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">qingfengbangzuo</p>
              <p class="site-description motion-element" itemprop="description">世界上只有一种英雄主义，那就是看清生活的真相之后依然热爱生活。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives%7C%7Carchive">
              
                  <span class="site-state-item-count">30</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/qingfengbangzuo" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-globe"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="cqupt_lixz@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-globe"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                推荐阅读
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://ife.baidu.com/" title="百度前端技术学院" target="_blank">百度前端技术学院</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#序列生成模型"><span class="nav-number">1.</span> <span class="nav-text">序列生成模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conditioned-generation-framework"><span class="nav-number">2.</span> <span class="nav-text">Conditioned generation framework</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Encoder-Decoder"><span class="nav-number">3.</span> <span class="nav-text">Encoder-Decoder</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数学解释"><span class="nav-number">4.</span> <span class="nav-text">数学解释</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#一个值得思考的问题"><span class="nav-number">4.1.</span> <span class="nav-text">一个值得思考的问题</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">qingfengbangzuo</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">59.4k</span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  





  
  



  
  



  



  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="https://github.com/jjandxa/canvas_sphere"></script>
  

  
  
    <script type="text/javascript" src="https://github.com/zproo/canvas-ribbon"></script>
  

  
  
    <script id="ribbon" type="text/javascript" size="300" alpha="0.6"  zIndex="-1" src="https://github.com/ethantw/Han"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


  
  <script src="/live2d-widget/autoload.js"></script>
  
</body>
</html>
